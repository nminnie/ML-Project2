{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nr_pRkcIco0T"
   },
   "outputs": [],
   "source": [
    "from data_loader import load_data\n",
    "from naive_bayes import BernoulliNaiveBayes\n",
    "from nlp_processing import LemmaCountVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy.stats import randint, norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nh7ku4LNwl5-"
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# # taken from https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184\n",
    "# REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\")\n",
    "# REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "# def preprocess_reviews(reviews):\n",
    "#     reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "#     reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "#     return \"\".join(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1549494432579,
     "user": {
      "displayName": "FRANCISCO XAVIER SUMBA TORAL",
      "photoUrl": "",
      "userId": "11128736706802637809"
     },
     "user_tz": 300
    },
    "id": "rKbl5m-gLme3",
    "outputId": "fa417ed1-ac49-41c6-9c1c-801dae469916"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train(X-(25000,), y-(25000,)), Test(X-(25000,))'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "train, test = load_data()\n",
    "# full_text = list(train.iloc[:, 1].values) + list(test.iloc[:, 1].values)\n",
    "# raw training and test data\n",
    "X_train = train.iloc[:,1].values\n",
    "X_test = test.iloc[:,1].values\n",
    "y = train.iloc[:,2].values.astype(int)\n",
    "\n",
    "\"Train(X-%s, y-%s), Test(X-%s)\"%(X_train.shape, y.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "Are most ocurrent words important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zzzz:73286',\n",
       " 'zzzzz:75997',\n",
       " 'zzzzzzzz:93976',\n",
       " 'zzzzzzzzzzzz:96467',\n",
       " 'zzzzzzzzzzzzz:101871',\n",
       " 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz:107331',\n",
       " 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz:135724',\n",
       " 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz:145864',\n",
       " 'æsthetic:164141',\n",
       " 'østbye:336748']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = LemmaCountVectorizer(strip_accents='unicode', stop_words=None, \n",
    "                                stem=True, ngram_range=(1, 1))\n",
    "data = vect.fit_transform(X_train)\n",
    "counts = np.ravel(data.sum(axis=0))\n",
    "idx_sort = np.argsort(counts)\n",
    "words = vect.get_feature_names()\n",
    "top = 10\n",
    "[\"{}:{}\".format(w,c) for c,w in zip(counts[idx_sort][-top:], words[-top:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['001']:[3]\",\n",
       " \"['10pm']:[3]\",\n",
       " \"['10x']:[3]\",\n",
       " \"['123']:[3]\",\n",
       " \"['125']:[3]\",\n",
       " \"['128']:[3]\",\n",
       " \"['12a']:[3]\",\n",
       " \"['131']:[3]\",\n",
       " \"['134']:[3]\",\n",
       " \"['136']:[3]\",\n",
       " \"['147']:[3]\",\n",
       " \"['1500']:[3]\",\n",
       " \"['15s']:[3]\",\n",
       " \"['1780s']:[3]\",\n",
       " \"['1798']:[3]\",\n",
       " \"['1820']:[3]\",\n",
       " \"['1824']:[3]\",\n",
       " \"['183']:[3]\",\n",
       " \"['1836']:[3]\",\n",
       " \"['1837']:[3]\",\n",
       " \"['1839']:[3]\",\n",
       " \"['1846']:[3]\",\n",
       " \"['1847']:[3]\",\n",
       " \"['1850']:[3]\",\n",
       " \"['1850s']:[3]\",\n",
       " \"['1853']:[3]\",\n",
       " \"['1863']:[3]\",\n",
       " \"['1865']:[3]\",\n",
       " \"['1881']:[3]\",\n",
       " \"['1888']:[3]\",\n",
       " \"['1892']:[3]\",\n",
       " \"['18a']:[3]\",\n",
       " \"['1903']:[3]\",\n",
       " \"['1911']:[3]\",\n",
       " \"['1h']:[3]\",\n",
       " \"['2012']:[3]\",\n",
       " \"['2200']:[3]\",\n",
       " \"['232']:[3]\",\n",
       " \"['24th']:[3]\",\n",
       " \"['2600']:[3]\",\n",
       " \"['26th']:[3]\",\n",
       " \"['270']:[3]\",\n",
       " \"['275']:[3]\",\n",
       " \"['27th']:[3]\",\n",
       " \"['28th']:[3]\",\n",
       " \"['2hrs']:[3]\",\n",
       " \"['30min']:[3]\",\n",
       " \"['30pm']:[3]\",\n",
       " \"['38th']:[3]\",\n",
       " \"['3p']:[3]\",\n",
       " \"['3rds']:[3]\",\n",
       " \"['451']:[3]\",\n",
       " \"['47s']:[3]\",\n",
       " \"['49th']:[3]\",\n",
       " \"['571']:[3]\",\n",
       " \"['6000']:[3]\",\n",
       " \"['607']:[3]\",\n",
       " \"['70mm']:[3]\",\n",
       " \"['70th']:[3]\",\n",
       " \"['90mins']:[3]\",\n",
       " \"['99p']:[3]\",\n",
       " \"['9mm']:[3]\",\n",
       " \"['____']:[3]\",\n",
       " \"['_atlantis_']:[3]\",\n",
       " \"['_is_']:[3]\",\n",
       " \"['aage']:[3]\",\n",
       " \"['abducting']:[3]\",\n",
       " \"['abdul']:[3]\",\n",
       " \"['abercrombie']:[3]\",\n",
       " \"['aberration']:[3]\",\n",
       " \"['abide']:[3]\",\n",
       " \"['ablaze']:[3]\",\n",
       " \"['abm']:[3]\",\n",
       " \"['abolition']:[3]\",\n",
       " \"['abominably']:[3]\",\n",
       " \"['abortive']:[3]\",\n",
       " \"['aborts']:[3]\",\n",
       " \"['abruptness']:[3]\",\n",
       " \"['absolve']:[3]\",\n",
       " \"['absolved']:[3]\",\n",
       " \"['abstinence']:[3]\",\n",
       " \"['accelerating']:[3]\",\n",
       " \"['accelerator']:[3]\",\n",
       " \"['accession']:[3]\",\n",
       " \"['accessories']:[3]\",\n",
       " \"['accommodating']:[3]\",\n",
       " \"['accommodation']:[3]\",\n",
       " \"['accommodations']:[3]\",\n",
       " \"['accordian']:[3]\",\n",
       " \"['accorsi']:[3]\",\n",
       " \"['accosts']:[3]\",\n",
       " \"['accountability']:[3]\",\n",
       " \"['accountants']:[3]\",\n",
       " \"['accumulates']:[3]\",\n",
       " \"['accuser']:[3]\",\n",
       " \"['ackerman']:[3]\",\n",
       " \"['acknowledgment']:[3]\",\n",
       " \"['acolyte']:[3]\",\n",
       " \"['acquittal']:[3]\",\n",
       " \"['acumen']:[3]\",\n",
       " \"['adamantium']:[3]\",\n",
       " \"['adaptable']:[3]\",\n",
       " \"['adaptions']:[3]\",\n",
       " \"['addams']:[3]\",\n",
       " \"['addicting']:[3]\",\n",
       " \"['adhd']:[3]\",\n",
       " \"['adherents']:[3]\",\n",
       " \"['adhering']:[3]\",\n",
       " \"['adios']:[3]\",\n",
       " \"['adjusts']:[3]\",\n",
       " \"['admonishing']:[3]\",\n",
       " \"['adobe']:[3]\",\n",
       " \"['adorably']:[3]\",\n",
       " \"['adoree']:[3]\",\n",
       " \"['adriano']:[3]\",\n",
       " \"['adroitly']:[3]\",\n",
       " \"['advices']:[3]\",\n",
       " \"['aerobicide']:[3]\",\n",
       " \"['aerosol']:[3]\",\n",
       " \"['aetheist']:[3]\",\n",
       " \"['affective']:[3]\",\n",
       " \"['afghans']:[3]\",\n",
       " \"['afield']:[3]\",\n",
       " \"['afrika']:[3]\",\n",
       " \"['agey']:[3]\",\n",
       " \"['aggravates']:[3]\",\n",
       " \"['aggressiveness']:[3]\",\n",
       " \"['agonies']:[3]\",\n",
       " \"['agriculture']:[3]\",\n",
       " \"['aguirre']:[3]\",\n",
       " \"['ahhhh']:[3]\",\n",
       " \"['aicha']:[3]\",\n",
       " \"['airball']:[3]\",\n",
       " \"['airbrushed']:[3]\",\n",
       " \"['airless']:[3]\",\n",
       " \"['airman']:[3]\",\n",
       " \"['airmen']:[3]\",\n",
       " \"['airports']:[3]\",\n",
       " \"['airship']:[3]\",\n",
       " \"['airtime']:[3]\",\n",
       " \"['aish']:[3]\",\n",
       " \"['aissa']:[3]\",\n",
       " \"['ajeeb']:[3]\",\n",
       " \"['ajnabi']:[3]\",\n",
       " \"['akosua']:[3]\",\n",
       " \"['akshey']:[3]\",\n",
       " \"['alahani']:[3]\",\n",
       " \"['alanis']:[3]\",\n",
       " \"['albans']:[3]\",\n",
       " \"['albertson']:[3]\",\n",
       " \"['aldolpho']:[3]\",\n",
       " \"['aleisa']:[3]\",\n",
       " \"['alejandra']:[3]\",\n",
       " \"['algerian']:[3]\",\n",
       " \"['algy']:[3]\",\n",
       " \"['aliases']:[3]\",\n",
       " \"['alisha']:[3]\",\n",
       " \"['alittle']:[3]\",\n",
       " \"['alix']:[3]\",\n",
       " \"['aloha']:[3]\",\n",
       " \"['alongwith']:[3]\",\n",
       " \"['alphaville']:[3]\",\n",
       " \"['als']:[3]\",\n",
       " \"['alsanjak']:[3]\",\n",
       " \"['altagracia']:[3]\",\n",
       " \"['alternated']:[3]\",\n",
       " \"['alvarez']:[3]\",\n",
       " \"['alwina']:[3]\",\n",
       " \"['alyce']:[3]\",\n",
       " \"['amassed']:[3]\",\n",
       " \"['amatuer']:[3]\",\n",
       " \"['amazonian']:[3]\",\n",
       " \"['ambience']:[3]\",\n",
       " \"['ambiguously']:[3]\",\n",
       " \"['ambles']:[3]\",\n",
       " \"['ambrose']:[3]\",\n",
       " \"['amenities']:[3]\",\n",
       " \"['americanised']:[3]\",\n",
       " \"['ames']:[3]\",\n",
       " \"['amiss']:[3]\",\n",
       " \"['amontillado']:[3]\",\n",
       " \"['amorphous']:[3]\",\n",
       " \"['amours']:[3]\",\n",
       " \"['amputation']:[3]\",\n",
       " \"['amuck']:[3]\",\n",
       " \"['anaesthetic']:[3]\",\n",
       " \"['analysing']:[3]\",\n",
       " \"['anarene']:[3]\",\n",
       " \"['anathema']:[3]\",\n",
       " \"['anchorwoman']:[3]\",\n",
       " \"['andalou']:[3]\",\n",
       " \"['andoheb']:[3]\",\n",
       " \"['andreeff']:[3]\",\n",
       " \"['anecdotal']:[3]\",\n",
       " \"['aneurysm']:[3]\",\n",
       " \"['angora']:[3]\",\n",
       " \"['angrier']:[3]\",\n",
       " \"['anguishing']:[3]\",\n",
       " \"['anhalt']:[3]\",\n",
       " \"['anjelica']:[3]\",\n",
       " \"['anjos']:[3]\",\n",
       " \"['annamarie']:[3]\",\n",
       " \"['annex']:[3]\",\n",
       " \"['annihilation']:[3]\",\n",
       " \"['anno']:[3]\",\n",
       " \"['annually']:[3]\",\n",
       " \"['antagonism']:[3]\",\n",
       " \"['antarctic']:[3]\",\n",
       " \"['antebellum']:[3]\",\n",
       " \"['antheil']:[3]\",\n",
       " \"['anthems']:[3]\",\n",
       " \"['anthrax']:[3]\",\n",
       " \"['anthropomorphic']:[3]\",\n",
       " \"['antiheroes']:[3]\",\n",
       " \"['antiseptic']:[3]\",\n",
       " \"['antonin']:[3]\",\n",
       " \"['anubis']:[3]\",\n",
       " \"['anvil']:[3]\",\n",
       " \"['anya']:[3]\",\n",
       " \"['anyday']:[3]\",\n",
       " \"['anywho']:[3]\",\n",
       " \"['aod']:[3]\",\n",
       " \"['ap3']:[3]\",\n",
       " \"['apiece']:[3]\",\n",
       " \"['apocryphal']:[3]\",\n",
       " \"['apologetic']:[3]\",\n",
       " \"['apotheosis']:[3]\",\n",
       " \"['app']:[3]\",\n",
       " \"['apparantly']:[3]\",\n",
       " \"['apparatchik']:[3]\",\n",
       " \"['appearence']:[3]\",\n",
       " \"['appendages']:[3]\",\n",
       " \"['appetizer']:[3]\",\n",
       " \"['appetizers']:[3]\",\n",
       " \"['applications']:[3]\",\n",
       " \"['appraisal']:[3]\",\n",
       " \"['approachable']:[3]\",\n",
       " \"['appropriation']:[3]\",\n",
       " \"['approving']:[3]\",\n",
       " \"['approximates']:[3]\",\n",
       " \"['aquafresh']:[3]\",\n",
       " \"['aquarius']:[3]\",\n",
       " \"['aramaic']:[3]\",\n",
       " \"['aranoa']:[3]\",\n",
       " \"['arbaaz']:[3]\",\n",
       " \"['arby']:[3]\",\n",
       " \"['archangel']:[3]\",\n",
       " \"['arched']:[3]\",\n",
       " \"['archenemy']:[3]\",\n",
       " \"['architects']:[3]\",\n",
       " \"['archived']:[3]\",\n",
       " \"['ardour']:[3]\",\n",
       " \"['arent']:[3]\",\n",
       " \"['aribert']:[3]\",\n",
       " \"['aristide']:[3]\",\n",
       " \"['armada']:[3]\",\n",
       " \"['armando']:[3]\",\n",
       " \"['arming']:[3]\",\n",
       " \"['armourae']:[3]\",\n",
       " \"['armoury']:[3]\",\n",
       " \"['arnett']:[3]\",\n",
       " \"['arrondissements']:[3]\",\n",
       " \"['arsenic']:[3]\",\n",
       " \"['arses']:[3]\",\n",
       " \"['artefact']:[3]\",\n",
       " \"['artemesia']:[3]\",\n",
       " \"['arthritis']:[3]\",\n",
       " \"['arthurian']:[3]\",\n",
       " \"['artimisia']:[3]\",\n",
       " \"['artiness']:[3]\",\n",
       " \"['arvanitis']:[3]\",\n",
       " \"['arwen']:[3]\",\n",
       " \"['aryana']:[3]\",\n",
       " \"['aryans']:[3]\",\n",
       " \"['asbestos']:[3]\",\n",
       " \"['ascend']:[3]\",\n",
       " \"['ascendancy']:[3]\",\n",
       " \"['ascends']:[3]\",\n",
       " \"['ascent']:[3]\",\n",
       " \"['ashame']:[3]\",\n",
       " \"['ashkenazi']:[3]\",\n",
       " \"['ashok']:[3]\",\n",
       " \"['ashram']:[3]\",\n",
       " \"['aspirant']:[3]\",\n",
       " \"['assante']:[3]\",\n",
       " \"['assassinations']:[3]\",\n",
       " \"['assembling']:[3]\",\n",
       " \"['assery']:[3]\",\n",
       " \"['assholes']:[3]\",\n",
       " \"['assignation']:[3]\",\n",
       " \"['assignations']:[3]\",\n",
       " \"['assigning']:[3]\",\n",
       " \"['assuredness']:[3]\",\n",
       " \"['assuring']:[3]\",\n",
       " \"['aster']:[3]\",\n",
       " \"['asteroid']:[3]\",\n",
       " \"['astree']:[3]\",\n",
       " \"['astrid']:[3]\",\n",
       " \"['astrological']:[3]\",\n",
       " \"['astronomically']:[3]\",\n",
       " \"['asuka']:[3]\",\n",
       " \"['aswell']:[3]\",\n",
       " \"['atenborough']:[3]\",\n",
       " \"['atheism']:[3]\",\n",
       " \"['athon']:[3]\",\n",
       " \"['atleast']:[3]\",\n",
       " \"['atoll']:[3]\",\n",
       " \"['atoms']:[3]\",\n",
       " \"['attendees']:[3]\",\n",
       " \"['attested']:[3]\",\n",
       " \"['attests']:[3]\",\n",
       " \"['attractiveness']:[3]\",\n",
       " \"['attributable']:[3]\",\n",
       " \"['auburn']:[3]\",\n",
       " \"['auctioned']:[3]\",\n",
       " \"['audley']:[3]\",\n",
       " \"['aug']:[3]\",\n",
       " \"['auggie']:[3]\",\n",
       " \"['augusten']:[3]\",\n",
       " \"['aumont']:[3]\",\n",
       " \"['auscrit']:[3]\",\n",
       " \"['auspices']:[3]\",\n",
       " \"['austerity']:[3]\",\n",
       " \"['autant']:[3]\",\n",
       " \"['authoress']:[3]\",\n",
       " \"['authorial']:[3]\",\n",
       " \"['authoritarianism']:[3]\",\n",
       " \"['authoritatively']:[3]\",\n",
       " \"['authorship']:[3]\",\n",
       " \"['autographs']:[3]\",\n",
       " \"['automated']:[3]\",\n",
       " \"['aux']:[3]\",\n",
       " \"['av']:[3]\",\n",
       " \"['avenet']:[3]\",\n",
       " \"['avenged']:[3]\",\n",
       " \"['averag']:[3]\",\n",
       " \"['averages']:[3]\",\n",
       " \"['averted']:[3]\",\n",
       " \"['aviator']:[3]\",\n",
       " \"['avon']:[3]\",\n",
       " \"['avonlea']:[3]\",\n",
       " \"['awa']:[3]\",\n",
       " \"['axes']:[3]\",\n",
       " \"['axton']:[3]\",\n",
       " \"['ayats']:[3]\",\n",
       " \"['aylmer']:[3]\",\n",
       " \"['ayurvedic']:[3]\",\n",
       " \"['az']:[3]\",\n",
       " \"['azkaban']:[3]\",\n",
       " \"['baaaaad']:[3]\",\n",
       " \"['baaad']:[3]\",\n",
       " \"['babyface']:[3]\",\n",
       " \"['backbiting']:[3]\",\n",
       " \"['backfired']:[3]\",\n",
       " \"['backlighting']:[3]\",\n",
       " \"['backpacking']:[3]\",\n",
       " \"['bade']:[3]\",\n",
       " \"['badguys']:[3]\",\n",
       " \"['bafflement']:[3]\",\n",
       " \"['bafflingly']:[3]\",\n",
       " \"['bagging']:[3]\",\n",
       " \"['baichwal']:[3]\",\n",
       " \"['bails']:[3]\",\n",
       " \"['baise']:[3]\",\n",
       " \"['baited']:[3]\",\n",
       " \"['baldwins']:[3]\",\n",
       " \"['bales']:[3]\",\n",
       " \"['ballets']:[3]\",\n",
       " \"['ballsy']:[3]\",\n",
       " \"['bally']:[3]\",\n",
       " \"['ballyhooed']:[3]\",\n",
       " \"['balm']:[3]\",\n",
       " \"['bandage']:[3]\",\n",
       " \"['banded']:[3]\",\n",
       " \"['bangers']:[3]\",\n",
       " \"['bankers']:[3]\",\n",
       " \"['bankole']:[3]\",\n",
       " \"['bankrolled']:[3]\",\n",
       " \"['banners']:[3]\",\n",
       " \"['bantam']:[3]\",\n",
       " \"['barabar']:[3]\",\n",
       " \"['barack']:[3]\",\n",
       " \"['barbarous']:[3]\",\n",
       " \"['barbour']:[3]\",\n",
       " \"['barfing']:[3]\",\n",
       " \"['barfly']:[3]\",\n",
       " \"['barging']:[3]\",\n",
       " \"['barmaid']:[3]\",\n",
       " \"['barmy']:[3]\",\n",
       " \"['barnum']:[3]\",\n",
       " \"['barometer']:[3]\",\n",
       " \"['barracuda']:[3]\",\n",
       " \"['barraged']:[3]\",\n",
       " \"['barris']:[3]\",\n",
       " \"['barrow']:[3]\",\n",
       " \"['barrows']:[3]\",\n",
       " \"['baryshnikov']:[3]\",\n",
       " \"['bas']:[3]\",\n",
       " \"['baser']:[3]\",\n",
       " \"['bashful']:[3]\",\n",
       " \"['basin']:[3]\",\n",
       " \"['bastedo']:[3]\",\n",
       " \"['bataan']:[3]\",\n",
       " \"['batali']:[3]\",\n",
       " \"['batchelor']:[3]\",\n",
       " \"['bathrooms']:[3]\",\n",
       " \"['battering']:[3]\",\n",
       " \"['battled']:[3]\",\n",
       " \"['baudelaire']:[3]\",\n",
       " \"['bawl']:[3]\",\n",
       " \"['baying']:[3]\",\n",
       " \"['bayldon']:[3]\",\n",
       " \"['bayonne']:[3]\",\n",
       " \"['bayreuth']:[3]\",\n",
       " \"['bazookas']:[3]\",\n",
       " \"['bbfc']:[3]\",\n",
       " \"['bdsm']:[3]\",\n",
       " \"['beached']:[3]\",\n",
       " \"['beamont']:[3]\",\n",
       " \"['beane']:[3]\",\n",
       " \"['beastie']:[3]\",\n",
       " \"['beasties']:[3]\",\n",
       " \"['beater']:[3]\",\n",
       " \"['beaty']:[3]\",\n",
       " \"['beaut']:[3]\",\n",
       " \"['beaux']:[3]\",\n",
       " \"['bechstein']:[3]\",\n",
       " \"['bedeviled']:[3]\",\n",
       " \"['bedfellows']:[3]\",\n",
       " \"['bedridden']:[3]\",\n",
       " \"['beehives']:[3]\",\n",
       " \"['beeps']:[3]\",\n",
       " \"['beesley']:[3]\",\n",
       " \"['befell']:[3]\",\n",
       " \"['befits']:[3]\",\n",
       " \"['beginner']:[3]\",\n",
       " \"['begrudge']:[3]\",\n",
       " \"['beguiles']:[3]\",\n",
       " \"['beheads']:[3]\",\n",
       " \"['beholden']:[3]\",\n",
       " \"['belabor']:[3]\",\n",
       " \"['beleive']:[3]\",\n",
       " \"['belgians']:[3]\",\n",
       " \"['belittled']:[3]\",\n",
       " \"['bellerophon']:[3]\",\n",
       " \"['bellhop']:[3]\",\n",
       " \"['bellucci']:[3]\",\n",
       " \"['belted']:[3]\",\n",
       " \"['bemoans']:[3]\",\n",
       " \"['benches']:[3]\",\n",
       " \"['bended']:[3]\",\n",
       " \"['bengal']:[3]\",\n",
       " \"['benita']:[3]\",\n",
       " \"['berardinelli']:[3]\",\n",
       " \"['beresford']:[3]\",\n",
       " \"['berg']:[3]\",\n",
       " \"['beringer']:[3]\",\n",
       " \"['berle']:[3]\",\n",
       " \"['berlinale']:[3]\",\n",
       " \"['bermuda']:[3]\",\n",
       " \"['bernson']:[3]\",\n",
       " \"['bertinelli']:[3]\",\n",
       " \"['berton']:[3]\",\n",
       " \"['bertram']:[3]\",\n",
       " \"['besser']:[3]\",\n",
       " \"['bested']:[3]\",\n",
       " \"['bestselling']:[3]\",\n",
       " \"['betamax']:[3]\",\n",
       " \"['bett']:[3]\",\n",
       " \"['betterment']:[3]\",\n",
       " \"['beurk']:[3]\",\n",
       " \"['bffs']:[3]\",\n",
       " \"['bharat']:[3]\",\n",
       " \"['bhatti']:[3]\",\n",
       " \"['bhave']:[3]\",\n",
       " \"['bhodi']:[3]\",\n",
       " \"['bhumika']:[3]\",\n",
       " \"['bi1']:[3]\",\n",
       " \"['bide']:[3]\",\n",
       " \"['biel']:[3]\",\n",
       " \"['bigg']:[3]\",\n",
       " \"['bigots']:[3]\",\n",
       " \"['bigtime']:[3]\",\n",
       " \"['bii']:[3]\",\n",
       " \"['biking']:[3]\",\n",
       " \"['bilcock']:[3]\",\n",
       " \"['biographer']:[3]\",\n",
       " \"['bionic']:[3]\",\n",
       " \"['biplane']:[3]\",\n",
       " \"['birdy']:[3]\",\n",
       " \"['biro']:[3]\",\n",
       " \"['birthdays']:[3]\",\n",
       " \"['births']:[3]\",\n",
       " \"['biscuits']:[3]\",\n",
       " \"['bishops']:[3]\",\n",
       " \"['bisset']:[3]\",\n",
       " \"['biswas']:[3]\",\n",
       " \"['bittersweetness']:[3]\",\n",
       " \"['bizzare']:[3]\",\n",
       " \"['blackballed']:[3]\",\n",
       " \"['blackbuster']:[3]\",\n",
       " \"['blackest']:[3]\",\n",
       " \"['blackjack']:[3]\",\n",
       " \"['blacklist']:[3]\",\n",
       " \"['blackly']:[3]\",\n",
       " \"['blacula']:[3]\",\n",
       " \"['bladed']:[3]\",\n",
       " \"['blaisdell']:[3]\",\n",
       " \"['blakely']:[3]\",\n",
       " \"['blameless']:[3]\",\n",
       " \"['blander']:[3]\",\n",
       " \"['blandick']:[3]\",\n",
       " \"['blankets']:[3]\",\n",
       " \"['blankfield']:[3]\",\n",
       " \"['blankly']:[3]\",\n",
       " \"['blasco']:[3]\",\n",
       " \"['blat']:[3]\",\n",
       " \"['bleakest']:[3]\",\n",
       " \"['bleh']:[3]\",\n",
       " \"['blemish']:[3]\",\n",
       " \"['blemishes']:[3]\",\n",
       " \"['blenheim']:[3]\",\n",
       " \"['blighted']:[3]\",\n",
       " \"['blighty']:[3]\",\n",
       " \"['blindfold']:[3]\",\n",
       " \"['blithering']:[3]\",\n",
       " \"['blitzstein']:[3]\",\n",
       " \"['blizzard']:[3]\",\n",
       " \"['bloodbaths']:[3]\",\n",
       " \"['bloodiest']:[3]\",\n",
       " \"['bloodline']:[3]\",\n",
       " \"['bloodsurfing']:[3]\",\n",
       " \"['bloomed']:[3]\",\n",
       " \"['bludgeon']:[3]\",\n",
       " \"['bludgeoned']:[3]\",\n",
       " \"['bluffs']:[3]\",\n",
       " \"['bluish']:[3]\",\n",
       " \"['bluntschli']:[3]\",\n",
       " \"['blurted']:[3]\",\n",
       " \"['bluto']:[3]\",\n",
       " \"['boardwalk']:[3]\",\n",
       " \"['boating']:[3]\",\n",
       " \"['bobbi']:[3]\",\n",
       " \"['bobbie']:[3]\",\n",
       " \"['boca']:[3]\",\n",
       " \"['bochner']:[3]\",\n",
       " \"['bodacious']:[3]\",\n",
       " \"['bodes']:[3]\",\n",
       " \"['bodybuilders']:[3]\",\n",
       " \"['bodyguards']:[3]\",\n",
       " \"['boerner']:[3]\",\n",
       " \"['bogdonavich']:[3]\",\n",
       " \"['bogdonovich']:[3]\",\n",
       " \"['bohemians']:[3]\",\n",
       " \"['bojangles']:[3]\",\n",
       " \"['bol']:[3]\",\n",
       " \"['bombadier']:[3]\",\n",
       " \"['bombadil']:[3]\",\n",
       " \"['bombast']:[3]\",\n",
       " \"['bonaparte']:[3]\",\n",
       " \"['boner']:[3]\",\n",
       " \"['bonesetter']:[3]\",\n",
       " \"['bonfires']:[3]\",\n",
       " \"['bong']:[3]\",\n",
       " \"['bongo']:[3]\",\n",
       " \"['boning']:[3]\",\n",
       " \"['bookcase']:[3]\",\n",
       " \"['booms']:[3]\",\n",
       " \"['boomslang']:[3]\",\n",
       " \"['boozer']:[3]\",\n",
       " \"['borefest']:[3]\",\n",
       " \"['boringness']:[3]\",\n",
       " \"['bosch']:[3]\",\n",
       " \"['bosnians']:[3]\",\n",
       " \"['bossman']:[3]\",\n",
       " \"['boswell']:[3]\",\n",
       " \"['botox']:[3]\",\n",
       " \"['botticelli']:[3]\",\n",
       " \"['bottomed']:[3]\",\n",
       " \"['boultings']:[3]\",\n",
       " \"['bouncer']:[3]\",\n",
       " \"['bounded']:[3]\",\n",
       " \"['bountiful']:[3]\",\n",
       " \"['bowers']:[3]\",\n",
       " \"['bowm']:[3]\",\n",
       " \"['brackets']:[3]\",\n",
       " \"['brackett']:[3]\",\n",
       " \"['brags']:[3]\",\n",
       " \"['braincells']:[3]\",\n",
       " \"['brandner']:[3]\",\n",
       " \"['brannon']:[3]\",\n",
       " \"['brassed']:[3]\",\n",
       " \"['brawn']:[3]\",\n",
       " \"['breakdance']:[3]\",\n",
       " \"['breakingly']:[3]\",\n",
       " \"['breather']:[3]\",\n",
       " \"['bree']:[3]\",\n",
       " \"['breeches']:[3]\",\n",
       " \"['breezes']:[3]\",\n",
       " \"['bremner']:[3]\",\n",
       " \"['brennen']:[3]\",\n",
       " \"['breslin']:[3]\",\n",
       " \"['bresslaw']:[3]\",\n",
       " \"['brewery']:[3]\",\n",
       " \"['briain']:[3]\",\n",
       " \"['bribing']:[3]\",\n",
       " \"['brickman']:[3]\",\n",
       " \"['bridgers']:[3]\",\n",
       " \"['brigands']:[3]\",\n",
       " \"['brimstone']:[3]\",\n",
       " \"['bringsværd']:[3]\",\n",
       " \"['brining']:[3]\",\n",
       " \"['brion']:[3]\",\n",
       " \"['britcoms']:[3]\",\n",
       " \"['britishness']:[3]\",\n",
       " \"['britt']:[3]\",\n",
       " \"['broached']:[3]\",\n",
       " \"['broadest']:[3]\",\n",
       " \"['broadhurst']:[3]\",\n",
       " \"['broads']:[3]\",\n",
       " \"['broadside']:[3]\",\n",
       " \"['broklynese']:[3]\",\n",
       " \"['brommell']:[3]\",\n",
       " \"['bronston']:[3]\",\n",
       " \"['broody']:[3]\",\n",
       " \"['brookmyre']:[3]\",\n",
       " \"['broth']:[3]\",\n",
       " \"['broughton']:[3]\",\n",
       " \"['brownish']:[3]\",\n",
       " \"['brull']:[3]\",\n",
       " \"['brunhilda']:[3]\",\n",
       " \"['brushing']:[3]\",\n",
       " \"['brusque']:[3]\",\n",
       " \"['brussels']:[3]\",\n",
       " \"['brutus']:[3]\",\n",
       " \"['bu']:[3]\",\n",
       " \"['bucke']:[3]\",\n",
       " \"['bucking']:[3]\",\n",
       " \"['buckner']:[3]\",\n",
       " \"['budd']:[3]\",\n",
       " \"['budge']:[3]\",\n",
       " \"['budgeting']:[3]\",\n",
       " \"['buena']:[3]\",\n",
       " \"['buick']:[3]\",\n",
       " \"['bukhanovsky']:[3]\",\n",
       " \"['bulbs']:[3]\",\n",
       " \"['bulge']:[3]\",\n",
       " \"['bulimics']:[3]\",\n",
       " \"['bulldozed']:[3]\",\n",
       " \"['bulletins']:[3]\",\n",
       " \"['bullfighter']:[3]\",\n",
       " \"['bullfighting']:[3]\",\n",
       " \"['bullfrogs']:[3]\",\n",
       " \"['bullion']:[3]\",\n",
       " \"['bumblers']:[3]\",\n",
       " \"['bun']:[3]\",\n",
       " \"['bundles']:[3]\",\n",
       " \"['burglarize']:[3]\",\n",
       " \"['burglars']:[3]\",\n",
       " \"['burma']:[3]\",\n",
       " \"['burnish']:[3]\",\n",
       " \"['burping']:[3]\",\n",
       " \"['bushel']:[3]\",\n",
       " \"['busia']:[3]\",\n",
       " \"['businesslike']:[3]\",\n",
       " \"['busters']:[3]\",\n",
       " \"['butchery']:[3]\",\n",
       " \"['buts']:[3]\",\n",
       " \"['butted']:[3]\",\n",
       " \"['butting']:[3]\",\n",
       " \"['bypassed']:[3]\",\n",
       " \"['byplay']:[3]\",\n",
       " \"['cacophonous']:[3]\",\n",
       " \"['caddy']:[3]\",\n",
       " \"['cads']:[3]\",\n",
       " \"['cajuns']:[3]\",\n",
       " \"['caked']:[3]\",\n",
       " \"['caldwell']:[3]\",\n",
       " \"['calender']:[3]\",\n",
       " \"['callarn']:[3]\",\n",
       " \"['callers']:[3]\",\n",
       " \"['calloused']:[3]\",\n",
       " \"['calloway']:[3]\",\n",
       " \"['calming']:[3]\",\n",
       " \"['calrissian']:[3]\",\n",
       " \"['camara']:[3]\",\n",
       " \"['cambpell']:[3]\",\n",
       " \"['cameroonian']:[3]\",\n",
       " \"['campaigning']:[3]\",\n",
       " \"['campell']:[3]\",\n",
       " \"['campesinos']:[3]\",\n",
       " \"['campos']:[3]\",\n",
       " \"['cams']:[3]\",\n",
       " \"['cancelling']:[3]\",\n",
       " \"['candidly']:[3]\",\n",
       " \"['candies']:[3]\",\n",
       " \"['canfield']:[3]\",\n",
       " \"['canisters']:[3]\",\n",
       " \"['cann']:[3]\",\n",
       " \"['cannell']:[3]\",\n",
       " \"['canning']:[3]\",\n",
       " \"['canoeing']:[3]\",\n",
       " \"['canton']:[3]\",\n",
       " \"['capacities']:[3]\",\n",
       " \"['capitalizing']:[3]\",\n",
       " \"['capo']:[3]\",\n",
       " \"['capomezza']:[3]\",\n",
       " \"['capper']:[3]\",\n",
       " \"['capping']:[3]\",\n",
       " \"['caprio']:[3]\",\n",
       " \"['capulet']:[3]\",\n",
       " \"['caracter']:[3]\",\n",
       " \"['caramel']:[3]\",\n",
       " \"['cardella']:[3]\",\n",
       " \"['cardiac']:[3]\",\n",
       " \"['careens']:[3]\",\n",
       " \"['carer']:[3]\",\n",
       " \"['carfax']:[3]\",\n",
       " \"['carly']:[3]\",\n",
       " \"['carmine']:[3]\",\n",
       " \"['carolingians']:[3]\",\n",
       " \"['carpathia']:[3]\",\n",
       " \"['carper']:[3]\",\n",
       " \"['carpets']:[3]\",\n",
       " \"['carribbean']:[3]\",\n",
       " \"['carridine']:[3]\",\n",
       " \"['carriere']:[3]\",\n",
       " \"['carrigan']:[3]\",\n",
       " \"['carrys']:[3]\",\n",
       " \"['carstone']:[3]\",\n",
       " \"['carthage']:[3]\",\n",
       " \"['cartouche']:[3]\",\n",
       " \"['casamajor']:[3]\",\n",
       " \"['cassanova']:[3]\",\n",
       " \"['cassell']:[3]\",\n",
       " \"['cassevetes']:[3]\",\n",
       " \"['cassi']:[3]\",\n",
       " \"['castaway']:[3]\",\n",
       " \"['castelnuovo']:[3]\",\n",
       " \"['catacombs']:[3]\",\n",
       " \"['catalogs']:[3]\",\n",
       " \"['catalunya']:[3]\",\n",
       " \"['catastrophes']:[3]\",\n",
       " \"['caterer']:[3]\",\n",
       " \"['cathie']:[3]\",\n",
       " \"['cathode']:[3]\",\n",
       " \"['cathrine']:[3]\",\n",
       " \"['causal']:[3]\",\n",
       " \"['caveats']:[3]\",\n",
       " \"['caved']:[3]\",\n",
       " \"['cavegirl']:[3]\",\n",
       " \"['cavernous']:[3]\",\n",
       " \"['caw']:[3]\",\n",
       " \"['cazale']:[3]\",\n",
       " \"['cc']:[3]\",\n",
       " \"['ce']:[3]\",\n",
       " \"['cecily']:[3]\",\n",
       " \"['ceded']:[3]\",\n",
       " \"['cel']:[3]\",\n",
       " \"['cele']:[3]\",\n",
       " \"['celebei']:[3]\",\n",
       " \"['cellular']:[3]\",\n",
       " \"['censure']:[3]\",\n",
       " \"['centeredness']:[3]\",\n",
       " \"['centralized']:[3]\",\n",
       " \"['centrepiece']:[3]\",\n",
       " \"['cerebrally']:[3]\",\n",
       " \"['cfto']:[3]\",\n",
       " \"['cgis']:[3]\",\n",
       " \"['chagos']:[3]\",\n",
       " \"['chakotay']:[3]\",\n",
       " \"['chaliya']:[3]\",\n",
       " \"['chandrasekhar']:[3]\",\n",
       " \"['chanteuse']:[3]\",\n",
       " \"['chapeau']:[3]\",\n",
       " \"['chapelle']:[3]\",\n",
       " \"['charactor']:[3]\",\n",
       " \"['charecters']:[3]\",\n",
       " \"['charing']:[3]\",\n",
       " \"['charlene']:[3]\",\n",
       " \"['charting']:[3]\",\n",
       " \"['chaste']:[3]\",\n",
       " \"['chastise']:[3]\",\n",
       " \"['chastised']:[3]\",\n",
       " \"['cheapjack']:[3]\",\n",
       " \"['cheep']:[3]\",\n",
       " \"['cheerleading']:[3]\",\n",
       " \"['chemotherapy']:[3]\",\n",
       " \"['cherbourg']:[3]\",\n",
       " \"['cherishing']:[3]\",\n",
       " \"['cherokee']:[3]\",\n",
       " \"['cherubic']:[3]\",\n",
       " \"['chessboard']:[3]\",\n",
       " \"['chevalier']:[3]\",\n",
       " \"['chia']:[3]\",\n",
       " \"['chica']:[3]\",\n",
       " \"['chicanery']:[3]\",\n",
       " \"['chided']:[3]\",\n",
       " \"['chides']:[3]\",\n",
       " \"['chiklis']:[3]\",\n",
       " \"['childishness']:[3]\",\n",
       " \"['childless']:[3]\",\n",
       " \"['childs']:[3]\",\n",
       " \"['chinnery']:[3]\",\n",
       " \"['chins']:[3]\",\n",
       " \"['chipmunk']:[3]\",\n",
       " \"['chirin']:[3]\",\n",
       " \"['choirs']:[3]\",\n",
       " \"['choisy']:[3]\",\n",
       " \"['chopin']:[3]\",\n",
       " \"['choreograph']:[3]\",\n",
       " \"['chorines']:[3]\",\n",
       " \"['chowder']:[3]\",\n",
       " \"['chri']:[3]\",\n",
       " \"['chrissie']:[3]\",\n",
       " \"['christa']:[3]\",\n",
       " \"['christened']:[3]\",\n",
       " \"['christmastime']:[3]\",\n",
       " \"['chromosomes']:[3]\",\n",
       " \"['chugs']:[3]\",\n",
       " \"['chun']:[3]\",\n",
       " \"['ciano']:[3]\",\n",
       " \"['ciao']:[3]\",\n",
       " \"['cinder']:[3]\",\n",
       " \"['cinderellas']:[3]\",\n",
       " \"['cinemaphotography']:[3]\",\n",
       " \"['ciphers']:[3]\",\n",
       " \"['circulate']:[3]\",\n",
       " \"['ciro']:[3]\",\n",
       " \"['citadel']:[3]\",\n",
       " \"['cites']:[3]\",\n",
       " \"['citroen']:[3]\",\n",
       " \"['clamoring']:[3]\",\n",
       " \"['clank']:[3]\",\n",
       " \"['clarice']:[3]\",\n",
       " \"['clarification']:[3]\",\n",
       " \"['clarks']:[3]\",\n",
       " \"['clarksberg']:[3]\",\n",
       " \"['classrooms']:[3]\",\n",
       " \"['claustrophobically']:[3]\",\n",
       " \"['clawed']:[3]\",\n",
       " \"['clayface']:[3]\",\n",
       " \"['cleanly']:[3]\",\n",
       " \"['cleansed']:[3]\",\n",
       " \"['clef']:[3]\",\n",
       " \"['clenteen']:[3]\",\n",
       " \"['cleverer']:[3]\",\n",
       " \"['cliffhanging']:[3]\",\n",
       " \"['climates']:[3]\",\n",
       " \"['clings']:[3]\",\n",
       " \"['clipping']:[3]\",\n",
       " \"['cliques']:[3]\",\n",
       " \"['cloned']:[3]\",\n",
       " \"['cloney']:[3]\",\n",
       " \"['clothesline']:[3]\",\n",
       " \"['clouzot']:[3]\",\n",
       " \"['clubhouse']:[3]\",\n",
       " \"['clued']:[3]\",\n",
       " \"['clunkiness']:[3]\",\n",
       " \"['clytemnestra']:[3]\",\n",
       " \"['cn']:[3]\",\n",
       " \"['coasted']:[3]\",\n",
       " \"['coasting']:[3]\",\n",
       " \"['coattails']:[3]\",\n",
       " \"['coaxes']:[3]\",\n",
       " \"['cockeyed']:[3]\",\n",
       " \"['cockiness']:[3]\",\n",
       " \"['cocoa']:[3]\",\n",
       " \"['coconut']:[3]\",\n",
       " \"['coeur']:[3]\",\n",
       " \"['coexistence']:[3]\",\n",
       " \"['coffeehouse']:[3]\",\n",
       " \"['coffers']:[3]\",\n",
       " \"['cogan']:[3]\",\n",
       " \"['cognoscenti']:[3]\",\n",
       " \"['cohan']:[3]\",\n",
       " \"['cohere']:[3]\",\n",
       " \"['coherently']:[3]\",\n",
       " \"['cohesiveness']:[3]\",\n",
       " \"['colder']:[3]\",\n",
       " \"['colette']:[3]\",\n",
       " \"['coliseum']:[3]\",\n",
       " \"['collaborating']:[3]\",\n",
       " \"['collectible']:[3]\",\n",
       " \"['collegiate']:[3]\",\n",
       " \"['colliding']:[3]\",\n",
       " \"['collin']:[3]\",\n",
       " \"['colloquial']:[3]\",\n",
       " \"['collusion']:[3]\",\n",
       " \"['cologne']:[3]\",\n",
       " \"['colonised']:[3]\",\n",
       " \"['colossus']:[3]\",\n",
       " \"['colouring']:[3]\",\n",
       " \"['columnists']:[3]\",\n",
       " \"['combating']:[3]\",\n",
       " \"['comedi']:[3]\",\n",
       " \"['comediennes']:[3]\",\n",
       " \"['comings']:[3]\",\n",
       " \"['commandeer']:[3]\",\n",
       " \"['commanders']:[3]\",\n",
       " \"['commemorated']:[3]\",\n",
       " \"['commissions']:[3]\",\n",
       " \"['committal']:[3]\",\n",
       " \"['communal']:[3]\",\n",
       " \"['communicative']:[3]\",\n",
       " \"['commutes']:[3]\",\n",
       " \"['companeros']:[3]\",\n",
       " \"['comparably']:[3]\",\n",
       " \"['complacency']:[3]\",\n",
       " \"['compleat']:[3]\",\n",
       " \"['completionists']:[3]\",\n",
       " \"['completley']:[3]\",\n",
       " \"['compliant']:[3]\",\n",
       " \"['complying']:[3]\",\n",
       " \"['compositing']:[3]\",\n",
       " \"['compositional']:[3]\",\n",
       " \"['compost']:[3]\",\n",
       " \"['comprehended']:[3]\",\n",
       " \"['compute']:[3]\",\n",
       " \"['conceives']:[3]\",\n",
       " \"['conceptually']:[3]\",\n",
       " \"['concerto']:[3]\",\n",
       " \"['concieved']:[3]\",\n",
       " \"['concocting']:[3]\",\n",
       " \"['concubines']:[3]\",\n",
       " \"['condieff']:[3]\",\n",
       " \"['conditioner']:[3]\",\n",
       " \"['condolences']:[3]\",\n",
       " \"['condoms']:[3]\",\n",
       " \"['condoning']:[3]\",\n",
       " \"['condos']:[3]\",\n",
       " \"['conducive']:[3]\",\n",
       " \"['configured']:[3]\",\n",
       " \"['conforms']:[3]\",\n",
       " \"['confounds']:[3]\",\n",
       " \"['confusions']:[3]\",\n",
       " \"['cong']:[3]\",\n",
       " \"['congorilla']:[3]\",\n",
       " \"['congresswoman']:[3]\",\n",
       " \"['congruent']:[3]\",\n",
       " \"['conjoined']:[3]\",\n",
       " \"['conlin']:[3]\",\n",
       " \"['connotation']:[3]\",\n",
       " \"['conscripted']:[3]\",\n",
       " \"['conscripts']:[3]\",\n",
       " \"['consecutively']:[3]\",\n",
       " \"['conservation']:[3]\",\n",
       " \"['conserved']:[3]\",\n",
       " \"['conspiratorial']:[3]\",\n",
       " \"['constabulary']:[3]\",\n",
       " \"['constellations']:[3]\",\n",
       " \"['constipation']:[3]\",\n",
       " \"['constrains']:[3]\",\n",
       " \"['constructively']:[3]\",\n",
       " \"['consuelo']:[3]\",\n",
       " \"['cont']:[3]\",\n",
       " \"['containment']:[3]\",\n",
       " \"['contaminating']:[3]\",\n",
       " \"['contemptuous']:[3]\",\n",
       " \"['contends']:[3]\",\n",
       " \"['contraband']:[3]\",\n",
       " \"['contracting']:[3]\",\n",
       " \"['contractually']:[3]\",\n",
       " \"['contradictive']:[3]\",\n",
       " \"['conveniences']:[3]\",\n",
       " \"['convergence']:[3]\",\n",
       " \"['converging']:[3]\",\n",
       " \"['converts']:[3]\",\n",
       " \"['convoy']:[3]\",\n",
       " \"['convoyeurs']:[3]\",\n",
       " \"['convoys']:[3]\",\n",
       " \"['cooled']:[3]\",\n",
       " \"['cooley']:[3]\",\n",
       " \"['coolneß']:[3]\",\n",
       " \"['coombs']:[3]\",\n",
       " \"['coordination']:[3]\",\n",
       " \"['copulation']:[3]\",\n",
       " \"['coquettish']:[3]\",\n",
       " \"['corbetts']:[3]\",\n",
       " \"['corcoran']:[3]\",\n",
       " \"['cordially']:[3]\",\n",
       " \"['corker']:[3]\",\n",
       " \"['cornelius']:[3]\",\n",
       " \"['cornette']:[3]\",\n",
       " \"['cornfields']:[3]\",\n",
       " \"['cornflakes']:[3]\",\n",
       " \"['corns']:[3]\",\n",
       " \"['cornucopia']:[3]\",\n",
       " \"['cornwell']:[3]\",\n",
       " \"['coronary']:[3]\",\n",
       " \"['corporeal']:[3]\",\n",
       " \"['corrections']:[3]\",\n",
       " \"['correlating']:[3]\",\n",
       " \"['corroborated']:[3]\",\n",
       " \"['corsaire']:[3]\",\n",
       " \"['cosas']:[3]\",\n",
       " \"['coscarelli']:[3]\",\n",
       " \"['cosmetics']:[3]\",\n",
       " \"['cosy']:[3]\",\n",
       " \"['cottages']:[3]\",\n",
       " ...]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argwhere(counts==3)\n",
    "[\"{}:{}\".format(w,c) for c,w in zip(counts[idx], np.array(words)[idx])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features 74638 mean 76.08121868217262 median 3.0\n",
      "features 1201 mean 1071.6511240632806 median 783.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Frequency of filtered words. (bottom=400,top=4000)')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "# figure 1\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(counts)\n",
    "plt.xlabel(\"word\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Frequency of words\")\n",
    "print(\"features\", len(counts), \"mean\", counts.mean(), \"median\", np.median(counts))\n",
    "\n",
    "# figure 2\n",
    "plt.subplot(1, 2, 2)\n",
    "top = 4000\n",
    "bottom = 400\n",
    "counts_filtered_top = counts[counts<top]\n",
    "counts_filtered = counts_filtered_top[counts_filtered_top>bottom]\n",
    "print(\"features\", len(counts_filtered), \"mean\", counts_filtered.mean(), \"median\", np.median(counts_filtered))\n",
    "plt.plot(counts_filtered)\n",
    "plt.xlabel(\"word\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Frequency of filtered words. (bottom={},top={})\".format(bottom, top))\n",
    "\n",
    "# possible values for min 3, 50, 100, 400\n",
    "# possible values for max 400, 4000, 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1a26256c50>,\n",
       "  <matplotlib.lines.Line2D at 0x1a26256f98>,\n",
       "  <matplotlib.lines.Line2D at 0x1a261fc080>,\n",
       "  <matplotlib.lines.Line2D at 0x1a261fc3c8>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x1a26247320>,\n",
       "  <matplotlib.lines.Line2D at 0x1a26247668>,\n",
       "  <matplotlib.lines.Line2D at 0x1a261fc710>,\n",
       "  <matplotlib.lines.Line2D at 0x1a261fca58>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1a26256b00>,\n",
       "  <matplotlib.lines.Line2D at 0x1a26247cf8>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x1a262479b0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a261fcda0>],\n",
       " 'fliers': [],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [counts, counts_filtered_top]\n",
    "plt.boxplot(data, showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,6))  # follows a normal distribution? \n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "sns.distplot(counts_filtered_top, fit=norm) \n",
    "plt.subplot(1,2,2)\n",
    "res = stats.probplot(counts_filtered_top, plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'f1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering considering TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176.392740726471,\n",
       " {'vec__stem': False,\n",
       "  'vec__ngram_range': (1, 2),\n",
       "  'vec__min_df': 100,\n",
       "  'vec__max_df': 4000,\n",
       "  'tfidf__smooth_idf': False,\n",
       "  'tfidf__norm': 'l2',\n",
       "  'clf__fit_intercept': False,\n",
       "  'clf__C': 2.5},\n",
       " 0.8953022668864954)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_regression_tfidf = {\n",
    "    'vec__min_df': [3, 50, 100, 400, 1],\n",
    "    'vec__max_df': [4000, 40000, 1.0],\n",
    "    'vec__stem': [True, False],\n",
    "    'vec__ngram_range':[(1, 1), (1, 2), (2, 2)],\n",
    "    'tfidf__norm': ['l1', 'l2'],\n",
    "    'tfidf__smooth_idf': [True, False],\n",
    "    'clf__fit_intercept': [True, False], \n",
    "    'clf__C': [.5, 1, 2, 2.5, 3], \n",
    "}\n",
    "\n",
    "pipeline_regression_tfidf = Pipeline([\n",
    "    ('vec', LemmaCountVectorizer(strip_accents='unicode', stop_words=None, binary=False)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression(solver='saga', penalty='l2'))\n",
    "])\n",
    "                  \n",
    "rs_regression_tfidf = RandomizedSearchCV(pipeline_regression_tfidf, parameters_regression_tfidf, \n",
    "                                   cv=10, scoring=score, n_jobs=-1, verbose=0, random_state=62, n_iter=20, \n",
    "                                         return_train_score=True)\n",
    "start = time.time()\n",
    "rs_regression_tfidf.fit(X_train, y)\n",
    "time.time() - start, rs_regression_tfidf.best_params_, rs_regression_tfidf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_vec__stem</th>\n",
       "      <th>param_vec__ngram_range</th>\n",
       "      <th>param_vec__min_df</th>\n",
       "      <th>param_vec__max_df</th>\n",
       "      <th>param_tfidf__smooth_idf</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>param_clf__fit_intercept</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34.001173</td>\n",
       "      <td>0.347224</td>\n",
       "      <td>2.256553</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.901186</td>\n",
       "      <td>0.906613</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.892320</td>\n",
       "      <td>0.894548</td>\n",
       "      <td>0.885635</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.903251</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.898643</td>\n",
       "      <td>0.895302</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948263</td>\n",
       "      <td>0.949046</td>\n",
       "      <td>0.948518</td>\n",
       "      <td>0.948519</td>\n",
       "      <td>0.948216</td>\n",
       "      <td>0.948183</td>\n",
       "      <td>0.949060</td>\n",
       "      <td>0.947243</td>\n",
       "      <td>0.948262</td>\n",
       "      <td>0.948207</td>\n",
       "      <td>0.948352</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33.525362</td>\n",
       "      <td>0.398965</td>\n",
       "      <td>2.126110</td>\n",
       "      <td>0.059528</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (2, 2)...</td>\n",
       "      <td>0.889770</td>\n",
       "      <td>0.896989</td>\n",
       "      <td>0.883412</td>\n",
       "      <td>0.889415</td>\n",
       "      <td>0.886156</td>\n",
       "      <td>0.890563</td>\n",
       "      <td>0.880345</td>\n",
       "      <td>0.891710</td>\n",
       "      <td>0.888713</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.889181</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988579</td>\n",
       "      <td>0.989285</td>\n",
       "      <td>0.988321</td>\n",
       "      <td>0.988706</td>\n",
       "      <td>0.988219</td>\n",
       "      <td>0.989070</td>\n",
       "      <td>0.989072</td>\n",
       "      <td>0.988301</td>\n",
       "      <td>0.988888</td>\n",
       "      <td>0.987948</td>\n",
       "      <td>0.988639</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.347431</td>\n",
       "      <td>0.297260</td>\n",
       "      <td>1.312915</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>40000</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 1)...</td>\n",
       "      <td>0.898930</td>\n",
       "      <td>0.894127</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.888449</td>\n",
       "      <td>0.887555</td>\n",
       "      <td>0.884144</td>\n",
       "      <td>0.876333</td>\n",
       "      <td>0.886680</td>\n",
       "      <td>0.882797</td>\n",
       "      <td>0.892928</td>\n",
       "      <td>0.888285</td>\n",
       "      <td>0.006076</td>\n",
       "      <td>3</td>\n",
       "      <td>0.934524</td>\n",
       "      <td>0.933946</td>\n",
       "      <td>0.935421</td>\n",
       "      <td>0.935562</td>\n",
       "      <td>0.934052</td>\n",
       "      <td>0.935190</td>\n",
       "      <td>0.934732</td>\n",
       "      <td>0.935233</td>\n",
       "      <td>0.934743</td>\n",
       "      <td>0.934113</td>\n",
       "      <td>0.934752</td>\n",
       "      <td>0.000559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.752568</td>\n",
       "      <td>0.099664</td>\n",
       "      <td>1.220150</td>\n",
       "      <td>0.030827</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>40000</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 1...</td>\n",
       "      <td>0.898930</td>\n",
       "      <td>0.894042</td>\n",
       "      <td>0.890205</td>\n",
       "      <td>0.888801</td>\n",
       "      <td>0.887645</td>\n",
       "      <td>0.883353</td>\n",
       "      <td>0.877026</td>\n",
       "      <td>0.886680</td>\n",
       "      <td>0.882797</td>\n",
       "      <td>0.893012</td>\n",
       "      <td>0.888249</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>4</td>\n",
       "      <td>0.934394</td>\n",
       "      <td>0.934399</td>\n",
       "      <td>0.935274</td>\n",
       "      <td>0.935267</td>\n",
       "      <td>0.934046</td>\n",
       "      <td>0.935267</td>\n",
       "      <td>0.934826</td>\n",
       "      <td>0.935079</td>\n",
       "      <td>0.935103</td>\n",
       "      <td>0.934095</td>\n",
       "      <td>0.934775</td>\n",
       "      <td>0.000471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34.676632</td>\n",
       "      <td>0.328301</td>\n",
       "      <td>2.292908</td>\n",
       "      <td>0.060326</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.892758</td>\n",
       "      <td>0.896026</td>\n",
       "      <td>0.879086</td>\n",
       "      <td>0.885805</td>\n",
       "      <td>0.887828</td>\n",
       "      <td>0.878416</td>\n",
       "      <td>0.872399</td>\n",
       "      <td>0.888536</td>\n",
       "      <td>0.883241</td>\n",
       "      <td>0.881543</td>\n",
       "      <td>0.884564</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>5</td>\n",
       "      <td>0.909443</td>\n",
       "      <td>0.907971</td>\n",
       "      <td>0.909866</td>\n",
       "      <td>0.909635</td>\n",
       "      <td>0.909555</td>\n",
       "      <td>0.910429</td>\n",
       "      <td>0.909019</td>\n",
       "      <td>0.907810</td>\n",
       "      <td>0.909788</td>\n",
       "      <td>0.908067</td>\n",
       "      <td>0.909158</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>35.884086</td>\n",
       "      <td>0.280849</td>\n",
       "      <td>2.354714</td>\n",
       "      <td>0.066755</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>400</td>\n",
       "      <td>40000</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 2)...</td>\n",
       "      <td>0.875049</td>\n",
       "      <td>0.882283</td>\n",
       "      <td>0.864780</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.871959</td>\n",
       "      <td>0.863492</td>\n",
       "      <td>0.860520</td>\n",
       "      <td>0.873161</td>\n",
       "      <td>0.868390</td>\n",
       "      <td>0.872584</td>\n",
       "      <td>0.870456</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>6</td>\n",
       "      <td>0.888497</td>\n",
       "      <td>0.888184</td>\n",
       "      <td>0.891045</td>\n",
       "      <td>0.888987</td>\n",
       "      <td>0.888487</td>\n",
       "      <td>0.890123</td>\n",
       "      <td>0.890104</td>\n",
       "      <td>0.887723</td>\n",
       "      <td>0.889859</td>\n",
       "      <td>0.889222</td>\n",
       "      <td>0.889223</td>\n",
       "      <td>0.000988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.438664</td>\n",
       "      <td>0.239512</td>\n",
       "      <td>2.228788</td>\n",
       "      <td>0.062472</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>50</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.873072</td>\n",
       "      <td>0.875693</td>\n",
       "      <td>0.868072</td>\n",
       "      <td>0.868599</td>\n",
       "      <td>0.873317</td>\n",
       "      <td>0.866878</td>\n",
       "      <td>0.857592</td>\n",
       "      <td>0.879365</td>\n",
       "      <td>0.871146</td>\n",
       "      <td>0.868944</td>\n",
       "      <td>0.870268</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>7</td>\n",
       "      <td>0.885394</td>\n",
       "      <td>0.884994</td>\n",
       "      <td>0.885767</td>\n",
       "      <td>0.886080</td>\n",
       "      <td>0.885455</td>\n",
       "      <td>0.884855</td>\n",
       "      <td>0.885861</td>\n",
       "      <td>0.883866</td>\n",
       "      <td>0.884769</td>\n",
       "      <td>0.884162</td>\n",
       "      <td>0.885120</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.353863</td>\n",
       "      <td>0.519734</td>\n",
       "      <td>2.546016</td>\n",
       "      <td>0.075919</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>4000</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.872629</td>\n",
       "      <td>0.874660</td>\n",
       "      <td>0.864452</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.862822</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.876702</td>\n",
       "      <td>0.870869</td>\n",
       "      <td>0.868145</td>\n",
       "      <td>0.869013</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>8</td>\n",
       "      <td>0.892297</td>\n",
       "      <td>0.893846</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.893723</td>\n",
       "      <td>0.893114</td>\n",
       "      <td>0.893915</td>\n",
       "      <td>0.893051</td>\n",
       "      <td>0.891529</td>\n",
       "      <td>0.890405</td>\n",
       "      <td>0.892837</td>\n",
       "      <td>0.892816</td>\n",
       "      <td>0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27.558163</td>\n",
       "      <td>0.123206</td>\n",
       "      <td>1.684262</td>\n",
       "      <td>0.075913</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.867460</td>\n",
       "      <td>0.873453</td>\n",
       "      <td>0.859144</td>\n",
       "      <td>0.860649</td>\n",
       "      <td>0.860567</td>\n",
       "      <td>0.867894</td>\n",
       "      <td>0.861961</td>\n",
       "      <td>0.876898</td>\n",
       "      <td>0.859635</td>\n",
       "      <td>0.869148</td>\n",
       "      <td>0.865681</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>9</td>\n",
       "      <td>0.938434</td>\n",
       "      <td>0.936569</td>\n",
       "      <td>0.937459</td>\n",
       "      <td>0.937939</td>\n",
       "      <td>0.937975</td>\n",
       "      <td>0.936563</td>\n",
       "      <td>0.937149</td>\n",
       "      <td>0.937276</td>\n",
       "      <td>0.938098</td>\n",
       "      <td>0.937840</td>\n",
       "      <td>0.937530</td>\n",
       "      <td>0.000606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>34.963263</td>\n",
       "      <td>0.295805</td>\n",
       "      <td>2.379652</td>\n",
       "      <td>0.093930</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>400</td>\n",
       "      <td>4000</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 2)...</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.872121</td>\n",
       "      <td>0.865392</td>\n",
       "      <td>0.869874</td>\n",
       "      <td>0.869877</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.846825</td>\n",
       "      <td>0.875947</td>\n",
       "      <td>0.864158</td>\n",
       "      <td>0.861320</td>\n",
       "      <td>0.865392</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>10</td>\n",
       "      <td>0.887517</td>\n",
       "      <td>0.886804</td>\n",
       "      <td>0.887078</td>\n",
       "      <td>0.888341</td>\n",
       "      <td>0.887196</td>\n",
       "      <td>0.888106</td>\n",
       "      <td>0.889985</td>\n",
       "      <td>0.887079</td>\n",
       "      <td>0.888301</td>\n",
       "      <td>0.886987</td>\n",
       "      <td>0.887739</td>\n",
       "      <td>0.000923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.390305</td>\n",
       "      <td>0.104361</td>\n",
       "      <td>1.178566</td>\n",
       "      <td>0.025611</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>4000</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 1...</td>\n",
       "      <td>0.870283</td>\n",
       "      <td>0.868400</td>\n",
       "      <td>0.860907</td>\n",
       "      <td>0.851618</td>\n",
       "      <td>0.866745</td>\n",
       "      <td>0.852317</td>\n",
       "      <td>0.846245</td>\n",
       "      <td>0.864886</td>\n",
       "      <td>0.866247</td>\n",
       "      <td>0.867687</td>\n",
       "      <td>0.861534</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>11</td>\n",
       "      <td>0.873321</td>\n",
       "      <td>0.874133</td>\n",
       "      <td>0.874776</td>\n",
       "      <td>0.875486</td>\n",
       "      <td>0.874580</td>\n",
       "      <td>0.875437</td>\n",
       "      <td>0.876675</td>\n",
       "      <td>0.873629</td>\n",
       "      <td>0.872422</td>\n",
       "      <td>0.873142</td>\n",
       "      <td>0.874360</td>\n",
       "      <td>0.001221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.257767</td>\n",
       "      <td>0.364041</td>\n",
       "      <td>2.738645</td>\n",
       "      <td>0.077813</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>4000</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 2)...</td>\n",
       "      <td>0.866555</td>\n",
       "      <td>0.869746</td>\n",
       "      <td>0.868345</td>\n",
       "      <td>0.851946</td>\n",
       "      <td>0.867360</td>\n",
       "      <td>0.854149</td>\n",
       "      <td>0.839301</td>\n",
       "      <td>0.857383</td>\n",
       "      <td>0.858337</td>\n",
       "      <td>0.857263</td>\n",
       "      <td>0.859039</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>12</td>\n",
       "      <td>0.883811</td>\n",
       "      <td>0.885092</td>\n",
       "      <td>0.884603</td>\n",
       "      <td>0.884711</td>\n",
       "      <td>0.884612</td>\n",
       "      <td>0.883419</td>\n",
       "      <td>0.885444</td>\n",
       "      <td>0.883214</td>\n",
       "      <td>0.883527</td>\n",
       "      <td>0.882700</td>\n",
       "      <td>0.884113</td>\n",
       "      <td>0.000854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.125927</td>\n",
       "      <td>0.187590</td>\n",
       "      <td>1.195229</td>\n",
       "      <td>0.046524</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 1)...</td>\n",
       "      <td>0.867386</td>\n",
       "      <td>0.862202</td>\n",
       "      <td>0.856708</td>\n",
       "      <td>0.850769</td>\n",
       "      <td>0.863810</td>\n",
       "      <td>0.849885</td>\n",
       "      <td>0.845006</td>\n",
       "      <td>0.859915</td>\n",
       "      <td>0.863514</td>\n",
       "      <td>0.857694</td>\n",
       "      <td>0.857689</td>\n",
       "      <td>0.006792</td>\n",
       "      <td>13</td>\n",
       "      <td>0.871935</td>\n",
       "      <td>0.872073</td>\n",
       "      <td>0.873632</td>\n",
       "      <td>0.874215</td>\n",
       "      <td>0.873957</td>\n",
       "      <td>0.872640</td>\n",
       "      <td>0.875251</td>\n",
       "      <td>0.872176</td>\n",
       "      <td>0.871236</td>\n",
       "      <td>0.872132</td>\n",
       "      <td>0.872925</td>\n",
       "      <td>0.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30.937289</td>\n",
       "      <td>0.191621</td>\n",
       "      <td>1.873563</td>\n",
       "      <td>0.043493</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>4000</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.851047</td>\n",
       "      <td>0.866432</td>\n",
       "      <td>0.848672</td>\n",
       "      <td>0.852701</td>\n",
       "      <td>0.855361</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.844615</td>\n",
       "      <td>0.865055</td>\n",
       "      <td>0.856143</td>\n",
       "      <td>0.852701</td>\n",
       "      <td>0.855142</td>\n",
       "      <td>0.006487</td>\n",
       "      <td>14</td>\n",
       "      <td>0.894628</td>\n",
       "      <td>0.893775</td>\n",
       "      <td>0.895467</td>\n",
       "      <td>0.894914</td>\n",
       "      <td>0.894117</td>\n",
       "      <td>0.893848</td>\n",
       "      <td>0.893120</td>\n",
       "      <td>0.892503</td>\n",
       "      <td>0.895033</td>\n",
       "      <td>0.894037</td>\n",
       "      <td>0.894144</td>\n",
       "      <td>0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.770579</td>\n",
       "      <td>0.186903</td>\n",
       "      <td>1.208471</td>\n",
       "      <td>0.044788</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 1...</td>\n",
       "      <td>0.856481</td>\n",
       "      <td>0.851080</td>\n",
       "      <td>0.848992</td>\n",
       "      <td>0.846569</td>\n",
       "      <td>0.852221</td>\n",
       "      <td>0.838411</td>\n",
       "      <td>0.834549</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.857364</td>\n",
       "      <td>0.848345</td>\n",
       "      <td>0.848794</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>15</td>\n",
       "      <td>0.857118</td>\n",
       "      <td>0.858047</td>\n",
       "      <td>0.858389</td>\n",
       "      <td>0.859163</td>\n",
       "      <td>0.860379</td>\n",
       "      <td>0.858145</td>\n",
       "      <td>0.861147</td>\n",
       "      <td>0.857742</td>\n",
       "      <td>0.856213</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.858396</td>\n",
       "      <td>0.001404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27.099254</td>\n",
       "      <td>0.225939</td>\n",
       "      <td>1.639080</td>\n",
       "      <td>0.080797</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>40000</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.850475</td>\n",
       "      <td>0.858167</td>\n",
       "      <td>0.848057</td>\n",
       "      <td>0.844869</td>\n",
       "      <td>0.836422</td>\n",
       "      <td>0.845229</td>\n",
       "      <td>0.843383</td>\n",
       "      <td>0.858404</td>\n",
       "      <td>0.850337</td>\n",
       "      <td>0.844374</td>\n",
       "      <td>0.847972</td>\n",
       "      <td>0.006397</td>\n",
       "      <td>16</td>\n",
       "      <td>0.907902</td>\n",
       "      <td>0.906138</td>\n",
       "      <td>0.907497</td>\n",
       "      <td>0.908488</td>\n",
       "      <td>0.907711</td>\n",
       "      <td>0.906573</td>\n",
       "      <td>0.906986</td>\n",
       "      <td>0.906607</td>\n",
       "      <td>0.907550</td>\n",
       "      <td>0.905504</td>\n",
       "      <td>0.907095</td>\n",
       "      <td>0.000855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12.321424</td>\n",
       "      <td>0.503082</td>\n",
       "      <td>1.163370</td>\n",
       "      <td>0.127748</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 1...</td>\n",
       "      <td>0.840062</td>\n",
       "      <td>0.845732</td>\n",
       "      <td>0.825952</td>\n",
       "      <td>0.841449</td>\n",
       "      <td>0.834877</td>\n",
       "      <td>0.825816</td>\n",
       "      <td>0.824750</td>\n",
       "      <td>0.830975</td>\n",
       "      <td>0.832241</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.833946</td>\n",
       "      <td>0.006879</td>\n",
       "      <td>17</td>\n",
       "      <td>0.843728</td>\n",
       "      <td>0.844757</td>\n",
       "      <td>0.846277</td>\n",
       "      <td>0.844794</td>\n",
       "      <td>0.845107</td>\n",
       "      <td>0.845415</td>\n",
       "      <td>0.845085</td>\n",
       "      <td>0.844892</td>\n",
       "      <td>0.845258</td>\n",
       "      <td>0.844321</td>\n",
       "      <td>0.844963</td>\n",
       "      <td>0.000638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.978740</td>\n",
       "      <td>0.264913</td>\n",
       "      <td>1.620520</td>\n",
       "      <td>0.057826</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>4000</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.819620</td>\n",
       "      <td>0.839731</td>\n",
       "      <td>0.823894</td>\n",
       "      <td>0.821724</td>\n",
       "      <td>0.820695</td>\n",
       "      <td>0.829423</td>\n",
       "      <td>0.815882</td>\n",
       "      <td>0.832278</td>\n",
       "      <td>0.822319</td>\n",
       "      <td>0.816456</td>\n",
       "      <td>0.824202</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>18</td>\n",
       "      <td>0.838763</td>\n",
       "      <td>0.836914</td>\n",
       "      <td>0.838167</td>\n",
       "      <td>0.837890</td>\n",
       "      <td>0.838345</td>\n",
       "      <td>0.837175</td>\n",
       "      <td>0.838348</td>\n",
       "      <td>0.837169</td>\n",
       "      <td>0.837787</td>\n",
       "      <td>0.839128</td>\n",
       "      <td>0.837969</td>\n",
       "      <td>0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.148460</td>\n",
       "      <td>1.570939</td>\n",
       "      <td>2.826835</td>\n",
       "      <td>0.096634</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.810580</td>\n",
       "      <td>0.830528</td>\n",
       "      <td>0.803891</td>\n",
       "      <td>0.823068</td>\n",
       "      <td>0.809432</td>\n",
       "      <td>0.811482</td>\n",
       "      <td>0.800618</td>\n",
       "      <td>0.814903</td>\n",
       "      <td>0.808910</td>\n",
       "      <td>0.807553</td>\n",
       "      <td>0.812096</td>\n",
       "      <td>0.008412</td>\n",
       "      <td>19</td>\n",
       "      <td>0.834226</td>\n",
       "      <td>0.833454</td>\n",
       "      <td>0.833525</td>\n",
       "      <td>0.834742</td>\n",
       "      <td>0.834884</td>\n",
       "      <td>0.834158</td>\n",
       "      <td>0.832617</td>\n",
       "      <td>0.833041</td>\n",
       "      <td>0.834855</td>\n",
       "      <td>0.834941</td>\n",
       "      <td>0.834044</td>\n",
       "      <td>0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.532494</td>\n",
       "      <td>0.134648</td>\n",
       "      <td>1.466608</td>\n",
       "      <td>0.044021</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>40000</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 1)...</td>\n",
       "      <td>0.808829</td>\n",
       "      <td>0.822689</td>\n",
       "      <td>0.796992</td>\n",
       "      <td>0.819153</td>\n",
       "      <td>0.801883</td>\n",
       "      <td>0.804399</td>\n",
       "      <td>0.791994</td>\n",
       "      <td>0.805477</td>\n",
       "      <td>0.803621</td>\n",
       "      <td>0.802059</td>\n",
       "      <td>0.805710</td>\n",
       "      <td>0.008815</td>\n",
       "      <td>20</td>\n",
       "      <td>0.814276</td>\n",
       "      <td>0.812848</td>\n",
       "      <td>0.813604</td>\n",
       "      <td>0.813952</td>\n",
       "      <td>0.815007</td>\n",
       "      <td>0.813868</td>\n",
       "      <td>0.813988</td>\n",
       "      <td>0.813181</td>\n",
       "      <td>0.814353</td>\n",
       "      <td>0.813662</td>\n",
       "      <td>0.813874</td>\n",
       "      <td>0.000578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "14      34.001173      0.347224         2.256553        0.041265   \n",
       "8       33.525362      0.398965         2.126110        0.059528   \n",
       "1       13.347431      0.297260         1.312915        0.020497   \n",
       "13      12.752568      0.099664         1.220150        0.030827   \n",
       "15      34.676632      0.328301         2.292908        0.060326   \n",
       "18      35.884086      0.280849         2.354714        0.066755   \n",
       "4       33.438664      0.239512         2.228788        0.062472   \n",
       "3       39.353863      0.519734         2.546016        0.075919   \n",
       "12      27.558163      0.123206         1.684262        0.075913   \n",
       "16      34.963263      0.295805         2.379652        0.093930   \n",
       "6       11.390305      0.104361         1.178566        0.025611   \n",
       "5       39.257767      0.364041         2.738645        0.077813   \n",
       "0       12.125927      0.187590         1.195229        0.046524   \n",
       "10      30.937289      0.191621         1.873563        0.043493   \n",
       "11      11.770579      0.186903         1.208471        0.044788   \n",
       "17      27.099254      0.225939         1.639080        0.080797   \n",
       "19      12.321424      0.503082         1.163370        0.127748   \n",
       "7       26.978740      0.264913         1.620520        0.057826   \n",
       "2       49.148460      1.570939         2.826835        0.096634   \n",
       "9       14.532494      0.134648         1.466608        0.044021   \n",
       "\n",
       "   param_vec__stem param_vec__ngram_range param_vec__min_df param_vec__max_df  \\\n",
       "14           False                 (1, 2)               100              4000   \n",
       "8             True                 (2, 2)                 3                 1   \n",
       "1             True                 (1, 1)                50             40000   \n",
       "13           False                 (1, 1)                50             40000   \n",
       "15           False                 (1, 2)               100                 1   \n",
       "18            True                 (1, 2)               400             40000   \n",
       "4            False                 (1, 2)                50              4000   \n",
       "3            False                 (1, 2)                 3              4000   \n",
       "12           False                 (2, 2)                50                 1   \n",
       "16            True                 (1, 2)               400              4000   \n",
       "6            False                 (1, 1)               100              4000   \n",
       "5             True                 (1, 2)                 3              4000   \n",
       "0             True                 (1, 1)                 1              4000   \n",
       "10           False                 (2, 2)                 3              4000   \n",
       "11           False                 (1, 1)                50              4000   \n",
       "17           False                 (2, 2)               100             40000   \n",
       "19           False                 (1, 1)                 3                 1   \n",
       "7            False                 (2, 2)               100              4000   \n",
       "2            False                 (1, 2)                 1                 1   \n",
       "9             True                 (1, 1)                 1             40000   \n",
       "\n",
       "   param_tfidf__smooth_idf param_tfidf__norm param_clf__fit_intercept  \\\n",
       "14                   False                l2                    False   \n",
       "8                     True                l2                     True   \n",
       "1                     True                l2                     True   \n",
       "13                   False                l2                     True   \n",
       "15                   False                l2                    False   \n",
       "18                    True                l2                    False   \n",
       "4                    False                l1                    False   \n",
       "3                     True                l1                     True   \n",
       "12                   False                l2                    False   \n",
       "16                    True                l2                    False   \n",
       "6                     True                l1                    False   \n",
       "5                     True                l1                    False   \n",
       "0                    False                l1                     True   \n",
       "10                    True                l1                     True   \n",
       "11                   False                l1                     True   \n",
       "17                    True                l2                     True   \n",
       "19                    True                l1                    False   \n",
       "7                     True                l1                     True   \n",
       "2                    False                l1                     True   \n",
       "9                     True                l1                    False   \n",
       "\n",
       "   param_clf__C                                             params  \\\n",
       "14          2.5  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "8           2.5  {'vec__stem': True, 'vec__ngram_range': (2, 2)...   \n",
       "1             3  {'vec__stem': True, 'vec__ngram_range': (1, 1)...   \n",
       "13            3  {'vec__stem': False, 'vec__ngram_range': (1, 1...   \n",
       "15          0.5  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "18            1  {'vec__stem': True, 'vec__ngram_range': (1, 2)...   \n",
       "4             3  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "3           2.5  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "12            2  {'vec__stem': False, 'vec__ngram_range': (2, 2...   \n",
       "16            1  {'vec__stem': True, 'vec__ngram_range': (1, 2)...   \n",
       "6             3  {'vec__stem': False, 'vec__ngram_range': (1, 1...   \n",
       "5             1  {'vec__stem': True, 'vec__ngram_range': (1, 2)...   \n",
       "0             2  {'vec__stem': True, 'vec__ngram_range': (1, 1)...   \n",
       "10            2  {'vec__stem': False, 'vec__ngram_range': (2, 2...   \n",
       "11          0.5  {'vec__stem': False, 'vec__ngram_range': (1, 1...   \n",
       "17          2.5  {'vec__stem': False, 'vec__ngram_range': (2, 2...   \n",
       "19          2.5  {'vec__stem': False, 'vec__ngram_range': (1, 1...   \n",
       "7           0.5  {'vec__stem': False, 'vec__ngram_range': (2, 2...   \n",
       "2             2  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "9           0.5  {'vec__stem': True, 'vec__ngram_range': (1, 1)...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "14           0.901186           0.906613           0.895817   \n",
       "8            0.889770           0.896989           0.883412   \n",
       "1            0.898930           0.894127           0.890909   \n",
       "13           0.898930           0.894042           0.890205   \n",
       "15           0.892758           0.896026           0.879086   \n",
       "18           0.875049           0.882283           0.864780   \n",
       "4            0.873072           0.875693           0.868072   \n",
       "3            0.872629           0.874660           0.864452   \n",
       "12           0.867460           0.873453           0.859144   \n",
       "16           0.870588           0.872121           0.865392   \n",
       "6            0.870283           0.868400           0.860907   \n",
       "5            0.866555           0.869746           0.868345   \n",
       "0            0.867386           0.862202           0.856708   \n",
       "10           0.851047           0.866432           0.848672   \n",
       "11           0.856481           0.851080           0.848992   \n",
       "17           0.850475           0.858167           0.848057   \n",
       "19           0.840062           0.845732           0.825952   \n",
       "7            0.819620           0.839731           0.823894   \n",
       "2            0.810580           0.830528           0.803891   \n",
       "9            0.808829           0.822689           0.796992   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "14           0.892320           0.894548           0.885635   \n",
       "8            0.889415           0.886156           0.890563   \n",
       "1            0.888449           0.887555           0.884144   \n",
       "13           0.888801           0.887645           0.883353   \n",
       "15           0.885805           0.887828           0.878416   \n",
       "18           0.872340           0.871959           0.863492   \n",
       "4            0.868599           0.873317           0.866878   \n",
       "3            0.868421           0.876596           0.862822   \n",
       "12           0.860649           0.860567           0.867894   \n",
       "16           0.869874           0.869877           0.857820   \n",
       "6            0.851618           0.866745           0.852317   \n",
       "5            0.851946           0.867360           0.854149   \n",
       "0            0.850769           0.863810           0.849885   \n",
       "10           0.852701           0.855361           0.858696   \n",
       "11           0.846569           0.852221           0.838411   \n",
       "17           0.844869           0.836422           0.845229   \n",
       "19           0.841449           0.834877           0.825816   \n",
       "7            0.821724           0.820695           0.829423   \n",
       "2            0.823068           0.809432           0.811482   \n",
       "9            0.819153           0.801883           0.804399   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "14           0.883117           0.903251           0.891892   \n",
       "8            0.880345           0.891710           0.888713   \n",
       "1            0.876333           0.886680           0.882797   \n",
       "13           0.877026           0.886680           0.882797   \n",
       "15           0.872399           0.888536           0.883241   \n",
       "18           0.860520           0.873161           0.868390   \n",
       "4            0.857592           0.879365           0.871146   \n",
       "3            0.854839           0.876702           0.870869   \n",
       "12           0.861961           0.876898           0.859635   \n",
       "16           0.846825           0.875947           0.864158   \n",
       "6            0.846245           0.864886           0.866247   \n",
       "5            0.839301           0.857383           0.858337   \n",
       "0            0.845006           0.859915           0.863514   \n",
       "10           0.844615           0.865055           0.856143   \n",
       "11           0.834549           0.853933           0.857364   \n",
       "17           0.843383           0.858404           0.850337   \n",
       "19           0.824750           0.830975           0.832241   \n",
       "7            0.815882           0.832278           0.822319   \n",
       "2            0.800618           0.814903           0.808910   \n",
       "9            0.791994           0.805477           0.803621   \n",
       "\n",
       "    split9_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "14           0.898643         0.895302        0.007072                1   \n",
       "8            0.894737         0.889181        0.004704                2   \n",
       "1            0.892928         0.888285        0.006076                3   \n",
       "13           0.893012         0.888249        0.005974                4   \n",
       "15           0.881543         0.884564        0.006732                5   \n",
       "18           0.872584         0.870456        0.006019                6   \n",
       "4            0.868944         0.870268        0.005583                7   \n",
       "3            0.868145         0.869013        0.006528                8   \n",
       "12           0.869148         0.865681        0.005924                9   \n",
       "16           0.861320         0.865392        0.008025               10   \n",
       "6            0.867687         0.861534        0.007997               11   \n",
       "5            0.857263         0.859039        0.008929               12   \n",
       "0            0.857694         0.857689        0.006792               13   \n",
       "10           0.852701         0.855142        0.006487               14   \n",
       "11           0.848345         0.848794        0.007013               15   \n",
       "17           0.844374         0.847972        0.006397               16   \n",
       "19           0.837607         0.833946        0.006879               17   \n",
       "7            0.816456         0.824202        0.007113               18   \n",
       "2            0.807553         0.812096        0.008412               19   \n",
       "9            0.802059         0.805710        0.008815               20   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "14            0.948263            0.949046            0.948518   \n",
       "8             0.988579            0.989285            0.988321   \n",
       "1             0.934524            0.933946            0.935421   \n",
       "13            0.934394            0.934399            0.935274   \n",
       "15            0.909443            0.907971            0.909866   \n",
       "18            0.888497            0.888184            0.891045   \n",
       "4             0.885394            0.884994            0.885767   \n",
       "3             0.892297            0.893846            0.893443   \n",
       "12            0.938434            0.936569            0.937459   \n",
       "16            0.887517            0.886804            0.887078   \n",
       "6             0.873321            0.874133            0.874776   \n",
       "5             0.883811            0.885092            0.884603   \n",
       "0             0.871935            0.872073            0.873632   \n",
       "10            0.894628            0.893775            0.895467   \n",
       "11            0.857118            0.858047            0.858389   \n",
       "17            0.907902            0.906138            0.907497   \n",
       "19            0.843728            0.844757            0.846277   \n",
       "7             0.838763            0.836914            0.838167   \n",
       "2             0.834226            0.833454            0.833525   \n",
       "9             0.814276            0.812848            0.813604   \n",
       "\n",
       "    split3_train_score  split4_train_score  split5_train_score  \\\n",
       "14            0.948519            0.948216            0.948183   \n",
       "8             0.988706            0.988219            0.989070   \n",
       "1             0.935562            0.934052            0.935190   \n",
       "13            0.935267            0.934046            0.935267   \n",
       "15            0.909635            0.909555            0.910429   \n",
       "18            0.888987            0.888487            0.890123   \n",
       "4             0.886080            0.885455            0.884855   \n",
       "3             0.893723            0.893114            0.893915   \n",
       "12            0.937939            0.937975            0.936563   \n",
       "16            0.888341            0.887196            0.888106   \n",
       "6             0.875486            0.874580            0.875437   \n",
       "5             0.884711            0.884612            0.883419   \n",
       "0             0.874215            0.873957            0.872640   \n",
       "10            0.894914            0.894117            0.893848   \n",
       "11            0.859163            0.860379            0.858145   \n",
       "17            0.908488            0.907711            0.906573   \n",
       "19            0.844794            0.845107            0.845415   \n",
       "7             0.837890            0.838345            0.837175   \n",
       "2             0.834742            0.834884            0.834158   \n",
       "9             0.813952            0.815007            0.813868   \n",
       "\n",
       "    split6_train_score  split7_train_score  split8_train_score  \\\n",
       "14            0.949060            0.947243            0.948262   \n",
       "8             0.989072            0.988301            0.988888   \n",
       "1             0.934732            0.935233            0.934743   \n",
       "13            0.934826            0.935079            0.935103   \n",
       "15            0.909019            0.907810            0.909788   \n",
       "18            0.890104            0.887723            0.889859   \n",
       "4             0.885861            0.883866            0.884769   \n",
       "3             0.893051            0.891529            0.890405   \n",
       "12            0.937149            0.937276            0.938098   \n",
       "16            0.889985            0.887079            0.888301   \n",
       "6             0.876675            0.873629            0.872422   \n",
       "5             0.885444            0.883214            0.883527   \n",
       "0             0.875251            0.872176            0.871236   \n",
       "10            0.893120            0.892503            0.895033   \n",
       "11            0.861147            0.857742            0.856213   \n",
       "17            0.906986            0.906607            0.907550   \n",
       "19            0.845085            0.844892            0.845258   \n",
       "7             0.838348            0.837169            0.837787   \n",
       "2             0.832617            0.833041            0.834855   \n",
       "9             0.813988            0.813181            0.814353   \n",
       "\n",
       "    split9_train_score  mean_train_score  std_train_score  \n",
       "14            0.948207          0.948352         0.000485  \n",
       "8             0.987948          0.988639         0.000416  \n",
       "1             0.934113          0.934752         0.000559  \n",
       "13            0.934095          0.934775         0.000471  \n",
       "15            0.908067          0.909158         0.000861  \n",
       "18            0.889222          0.889223         0.000988  \n",
       "4             0.884162          0.885120         0.000691  \n",
       "3             0.892837          0.892816         0.001066  \n",
       "12            0.937840          0.937530         0.000606  \n",
       "16            0.886987          0.887739         0.000923  \n",
       "6             0.873142          0.874360         0.001221  \n",
       "5             0.882700          0.884113         0.000854  \n",
       "0             0.872132          0.872925         0.001203  \n",
       "10            0.894037          0.894144         0.000857  \n",
       "11            0.857620          0.858396         0.001404  \n",
       "17            0.905504          0.907095         0.000855  \n",
       "19            0.844321          0.844963         0.000638  \n",
       "7             0.839128          0.837969         0.000687  \n",
       "2             0.834941          0.834044         0.000797  \n",
       "9             0.813662          0.813874         0.000578  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.DataFrame(rs_regression_tfidf.cv_results_).sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cuent/anaconda/envs/comp551-proj2/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2778.6028349399567,\n",
       " {'vec__stem': False,\n",
       "  'vec__ngram_range': (1, 2),\n",
       "  'vec__min_df': 1,\n",
       "  'vec__max_df': 400,\n",
       "  'clf__fit_intercept': False,\n",
       "  'clf__C': 0.5},\n",
       " 0.9039370019841981)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_regression_bow = {\n",
    "    'vec__min_df': [3, 50, 100, 400, 1],\n",
    "    'vec__max_df': [400, 4000, 40000, 1.0],\n",
    "    'vec__stem': [True, False],\n",
    "    'vec__ngram_range':[(1, 1), (1, 2), (2, 2)],\n",
    "    'clf__fit_intercept': [True, False], \n",
    "    'clf__C': [.5, 1, 2, 2.5, 3], \n",
    "}\n",
    "\n",
    "pipeline_regression_bow = Pipeline([\n",
    "    ('vec', LemmaCountVectorizer(strip_accents='unicode', stop_words=None)),\n",
    "    ('clf', LogisticRegression(solver='saga', penalty='l2', max_iter=200))\n",
    "])\n",
    "                  \n",
    "rs_regression_bow = RandomizedSearchCV(pipeline_regression_bow, parameters_regression_bow, \n",
    "                                   cv=15, scoring=score, n_jobs=-1, verbose=0, random_state=62, n_iter=20,\n",
    "                                      return_train_score=True)\n",
    "start = time.time()\n",
    "rs_regression_bow.fit(X_train, y)\n",
    "time.time() - start, rs_regression_bow.best_params_, rs_regression_bow.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_vec__stem</th>\n",
       "      <th>param_vec__ngram_range</th>\n",
       "      <th>param_vec__min_df</th>\n",
       "      <th>param_vec__max_df</th>\n",
       "      <th>param_clf__fit_intercept</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>split10_train_score</th>\n",
       "      <th>split11_train_score</th>\n",
       "      <th>split12_train_score</th>\n",
       "      <th>split13_train_score</th>\n",
       "      <th>split14_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>166.226714</td>\n",
       "      <td>6.424254</td>\n",
       "      <td>1.725971</td>\n",
       "      <td>0.043466</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.908218</td>\n",
       "      <td>0.906195</td>\n",
       "      <td>0.904061</td>\n",
       "      <td>0.906509</td>\n",
       "      <td>0.889810</td>\n",
       "      <td>0.918404</td>\n",
       "      <td>0.902728</td>\n",
       "      <td>0.905592</td>\n",
       "      <td>0.902527</td>\n",
       "      <td>0.896469</td>\n",
       "      <td>0.888758</td>\n",
       "      <td>0.904474</td>\n",
       "      <td>0.914591</td>\n",
       "      <td>0.895307</td>\n",
       "      <td>0.915417</td>\n",
       "      <td>0.903937</td>\n",
       "      <td>0.008371</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998199</td>\n",
       "      <td>0.998328</td>\n",
       "      <td>0.999614</td>\n",
       "      <td>0.998114</td>\n",
       "      <td>0.998113</td>\n",
       "      <td>0.997942</td>\n",
       "      <td>0.998027</td>\n",
       "      <td>0.998199</td>\n",
       "      <td>0.997942</td>\n",
       "      <td>0.998242</td>\n",
       "      <td>0.998199</td>\n",
       "      <td>0.998157</td>\n",
       "      <td>0.998242</td>\n",
       "      <td>0.998242</td>\n",
       "      <td>0.998156</td>\n",
       "      <td>0.998248</td>\n",
       "      <td>0.000380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85.847759</td>\n",
       "      <td>2.369713</td>\n",
       "      <td>1.767123</td>\n",
       "      <td>0.067447</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 2)...</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.906509</td>\n",
       "      <td>0.901659</td>\n",
       "      <td>0.903149</td>\n",
       "      <td>0.889680</td>\n",
       "      <td>0.917114</td>\n",
       "      <td>0.901008</td>\n",
       "      <td>0.905162</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.894202</td>\n",
       "      <td>0.887581</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.915033</td>\n",
       "      <td>0.897467</td>\n",
       "      <td>0.914217</td>\n",
       "      <td>0.902796</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996741</td>\n",
       "      <td>0.996484</td>\n",
       "      <td>0.999057</td>\n",
       "      <td>0.996398</td>\n",
       "      <td>0.996141</td>\n",
       "      <td>0.996269</td>\n",
       "      <td>0.996097</td>\n",
       "      <td>0.996313</td>\n",
       "      <td>0.996055</td>\n",
       "      <td>0.996485</td>\n",
       "      <td>0.996228</td>\n",
       "      <td>0.996527</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.996612</td>\n",
       "      <td>0.996483</td>\n",
       "      <td>0.996541</td>\n",
       "      <td>0.000699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>116.111517</td>\n",
       "      <td>10.599349</td>\n",
       "      <td>1.678619</td>\n",
       "      <td>0.393742</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 2)...</td>\n",
       "      <td>0.897815</td>\n",
       "      <td>0.895328</td>\n",
       "      <td>0.903766</td>\n",
       "      <td>0.883749</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.892454</td>\n",
       "      <td>0.895895</td>\n",
       "      <td>0.891030</td>\n",
       "      <td>0.872162</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.884863</td>\n",
       "      <td>0.897862</td>\n",
       "      <td>0.887299</td>\n",
       "      <td>0.883086</td>\n",
       "      <td>0.898032</td>\n",
       "      <td>0.890610</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>3</td>\n",
       "      <td>0.938972</td>\n",
       "      <td>0.939002</td>\n",
       "      <td>0.945826</td>\n",
       "      <td>0.940518</td>\n",
       "      <td>0.939615</td>\n",
       "      <td>0.941166</td>\n",
       "      <td>0.940021</td>\n",
       "      <td>0.940007</td>\n",
       "      <td>0.940474</td>\n",
       "      <td>0.940583</td>\n",
       "      <td>0.939478</td>\n",
       "      <td>0.939239</td>\n",
       "      <td>0.939503</td>\n",
       "      <td>0.940318</td>\n",
       "      <td>0.940017</td>\n",
       "      <td>0.940316</td>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.697148</td>\n",
       "      <td>0.588273</td>\n",
       "      <td>0.937507</td>\n",
       "      <td>0.059456</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 1)...</td>\n",
       "      <td>0.886759</td>\n",
       "      <td>0.893238</td>\n",
       "      <td>0.892963</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.873604</td>\n",
       "      <td>0.897119</td>\n",
       "      <td>0.894484</td>\n",
       "      <td>0.882107</td>\n",
       "      <td>0.874180</td>\n",
       "      <td>0.883553</td>\n",
       "      <td>0.864897</td>\n",
       "      <td>0.875075</td>\n",
       "      <td>0.891136</td>\n",
       "      <td>0.876270</td>\n",
       "      <td>0.894075</td>\n",
       "      <td>0.884873</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>4</td>\n",
       "      <td>0.955329</td>\n",
       "      <td>0.955374</td>\n",
       "      <td>0.975572</td>\n",
       "      <td>0.954711</td>\n",
       "      <td>0.956336</td>\n",
       "      <td>0.955931</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.955330</td>\n",
       "      <td>0.955436</td>\n",
       "      <td>0.956715</td>\n",
       "      <td>0.956240</td>\n",
       "      <td>0.955293</td>\n",
       "      <td>0.955144</td>\n",
       "      <td>0.955939</td>\n",
       "      <td>0.955043</td>\n",
       "      <td>0.956882</td>\n",
       "      <td>0.005026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>78.177809</td>\n",
       "      <td>1.397992</td>\n",
       "      <td>1.453143</td>\n",
       "      <td>0.033601</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>40000</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (2, 2)...</td>\n",
       "      <td>0.883225</td>\n",
       "      <td>0.884410</td>\n",
       "      <td>0.898154</td>\n",
       "      <td>0.872619</td>\n",
       "      <td>0.879391</td>\n",
       "      <td>0.883472</td>\n",
       "      <td>0.875904</td>\n",
       "      <td>0.880337</td>\n",
       "      <td>0.884110</td>\n",
       "      <td>0.880668</td>\n",
       "      <td>0.873455</td>\n",
       "      <td>0.890354</td>\n",
       "      <td>0.880712</td>\n",
       "      <td>0.874552</td>\n",
       "      <td>0.891843</td>\n",
       "      <td>0.882214</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>5</td>\n",
       "      <td>0.997558</td>\n",
       "      <td>0.997343</td>\n",
       "      <td>0.997515</td>\n",
       "      <td>0.997258</td>\n",
       "      <td>0.998286</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.997429</td>\n",
       "      <td>0.997386</td>\n",
       "      <td>0.997558</td>\n",
       "      <td>0.997343</td>\n",
       "      <td>0.997344</td>\n",
       "      <td>0.997686</td>\n",
       "      <td>0.997343</td>\n",
       "      <td>0.997386</td>\n",
       "      <td>0.997471</td>\n",
       "      <td>0.997480</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>136.557156</td>\n",
       "      <td>7.096105</td>\n",
       "      <td>1.332794</td>\n",
       "      <td>0.102322</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.877732</td>\n",
       "      <td>0.882840</td>\n",
       "      <td>0.894988</td>\n",
       "      <td>0.869668</td>\n",
       "      <td>0.881633</td>\n",
       "      <td>0.884638</td>\n",
       "      <td>0.880526</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.877025</td>\n",
       "      <td>0.880995</td>\n",
       "      <td>0.879250</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.879717</td>\n",
       "      <td>0.875895</td>\n",
       "      <td>0.891173</td>\n",
       "      <td>0.882212</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999100</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.999100</td>\n",
       "      <td>0.999057</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.999057</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.999272</td>\n",
       "      <td>0.999229</td>\n",
       "      <td>0.999229</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38.767830</td>\n",
       "      <td>1.489086</td>\n",
       "      <td>0.998825</td>\n",
       "      <td>0.037903</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 1)...</td>\n",
       "      <td>0.885850</td>\n",
       "      <td>0.895080</td>\n",
       "      <td>0.886486</td>\n",
       "      <td>0.877297</td>\n",
       "      <td>0.883529</td>\n",
       "      <td>0.882423</td>\n",
       "      <td>0.894454</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.859534</td>\n",
       "      <td>0.883164</td>\n",
       "      <td>0.865882</td>\n",
       "      <td>0.884661</td>\n",
       "      <td>0.877732</td>\n",
       "      <td>0.876043</td>\n",
       "      <td>0.893921</td>\n",
       "      <td>0.881669</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>7</td>\n",
       "      <td>0.908704</td>\n",
       "      <td>0.908016</td>\n",
       "      <td>0.913006</td>\n",
       "      <td>0.909037</td>\n",
       "      <td>0.908727</td>\n",
       "      <td>0.909215</td>\n",
       "      <td>0.908364</td>\n",
       "      <td>0.907776</td>\n",
       "      <td>0.910304</td>\n",
       "      <td>0.908310</td>\n",
       "      <td>0.908820</td>\n",
       "      <td>0.907522</td>\n",
       "      <td>0.907938</td>\n",
       "      <td>0.907839</td>\n",
       "      <td>0.906688</td>\n",
       "      <td>0.908684</td>\n",
       "      <td>0.001411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.442591</td>\n",
       "      <td>1.433217</td>\n",
       "      <td>0.997873</td>\n",
       "      <td>0.037938</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>40000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 1)...</td>\n",
       "      <td>0.882701</td>\n",
       "      <td>0.887307</td>\n",
       "      <td>0.879042</td>\n",
       "      <td>0.871674</td>\n",
       "      <td>0.875222</td>\n",
       "      <td>0.877817</td>\n",
       "      <td>0.892729</td>\n",
       "      <td>0.872315</td>\n",
       "      <td>0.858845</td>\n",
       "      <td>0.876418</td>\n",
       "      <td>0.861846</td>\n",
       "      <td>0.881759</td>\n",
       "      <td>0.875369</td>\n",
       "      <td>0.867024</td>\n",
       "      <td>0.891266</td>\n",
       "      <td>0.876757</td>\n",
       "      <td>0.009421</td>\n",
       "      <td>8</td>\n",
       "      <td>0.896084</td>\n",
       "      <td>0.895635</td>\n",
       "      <td>0.898769</td>\n",
       "      <td>0.896722</td>\n",
       "      <td>0.896748</td>\n",
       "      <td>0.895849</td>\n",
       "      <td>0.894996</td>\n",
       "      <td>0.895307</td>\n",
       "      <td>0.897935</td>\n",
       "      <td>0.896274</td>\n",
       "      <td>0.897226</td>\n",
       "      <td>0.896496</td>\n",
       "      <td>0.896496</td>\n",
       "      <td>0.896124</td>\n",
       "      <td>0.894710</td>\n",
       "      <td>0.896358</td>\n",
       "      <td>0.001032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28.550558</td>\n",
       "      <td>0.460815</td>\n",
       "      <td>0.824389</td>\n",
       "      <td>0.030064</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>40000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 1...</td>\n",
       "      <td>0.882562</td>\n",
       "      <td>0.887307</td>\n",
       "      <td>0.880240</td>\n",
       "      <td>0.871674</td>\n",
       "      <td>0.875222</td>\n",
       "      <td>0.876631</td>\n",
       "      <td>0.892069</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.859012</td>\n",
       "      <td>0.876418</td>\n",
       "      <td>0.861340</td>\n",
       "      <td>0.881759</td>\n",
       "      <td>0.875887</td>\n",
       "      <td>0.867024</td>\n",
       "      <td>0.891136</td>\n",
       "      <td>0.876673</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>9</td>\n",
       "      <td>0.896019</td>\n",
       "      <td>0.895541</td>\n",
       "      <td>0.898650</td>\n",
       "      <td>0.897023</td>\n",
       "      <td>0.896874</td>\n",
       "      <td>0.895925</td>\n",
       "      <td>0.894949</td>\n",
       "      <td>0.895401</td>\n",
       "      <td>0.898084</td>\n",
       "      <td>0.896660</td>\n",
       "      <td>0.897076</td>\n",
       "      <td>0.896458</td>\n",
       "      <td>0.897011</td>\n",
       "      <td>0.895954</td>\n",
       "      <td>0.895003</td>\n",
       "      <td>0.896442</td>\n",
       "      <td>0.001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>52.183430</td>\n",
       "      <td>0.340524</td>\n",
       "      <td>1.499557</td>\n",
       "      <td>0.038864</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.871765</td>\n",
       "      <td>0.872216</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.856637</td>\n",
       "      <td>0.869667</td>\n",
       "      <td>0.869668</td>\n",
       "      <td>0.877527</td>\n",
       "      <td>0.866387</td>\n",
       "      <td>0.853906</td>\n",
       "      <td>0.863284</td>\n",
       "      <td>0.853428</td>\n",
       "      <td>0.873960</td>\n",
       "      <td>0.869410</td>\n",
       "      <td>0.859356</td>\n",
       "      <td>0.874479</td>\n",
       "      <td>0.867377</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>10</td>\n",
       "      <td>0.885271</td>\n",
       "      <td>0.886155</td>\n",
       "      <td>0.887126</td>\n",
       "      <td>0.886655</td>\n",
       "      <td>0.886681</td>\n",
       "      <td>0.885637</td>\n",
       "      <td>0.885035</td>\n",
       "      <td>0.885546</td>\n",
       "      <td>0.886759</td>\n",
       "      <td>0.887418</td>\n",
       "      <td>0.886439</td>\n",
       "      <td>0.886289</td>\n",
       "      <td>0.887277</td>\n",
       "      <td>0.886938</td>\n",
       "      <td>0.885311</td>\n",
       "      <td>0.886303</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>42.239456</td>\n",
       "      <td>0.391517</td>\n",
       "      <td>1.155246</td>\n",
       "      <td>0.043761</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>50</td>\n",
       "      <td>40000</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.869462</td>\n",
       "      <td>0.849821</td>\n",
       "      <td>0.874552</td>\n",
       "      <td>0.853746</td>\n",
       "      <td>0.849412</td>\n",
       "      <td>0.863258</td>\n",
       "      <td>0.853012</td>\n",
       "      <td>0.858348</td>\n",
       "      <td>0.856284</td>\n",
       "      <td>0.855450</td>\n",
       "      <td>0.856471</td>\n",
       "      <td>0.875983</td>\n",
       "      <td>0.854599</td>\n",
       "      <td>0.851652</td>\n",
       "      <td>0.864897</td>\n",
       "      <td>0.859130</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>11</td>\n",
       "      <td>0.959251</td>\n",
       "      <td>0.959536</td>\n",
       "      <td>0.958971</td>\n",
       "      <td>0.959904</td>\n",
       "      <td>0.967712</td>\n",
       "      <td>0.959191</td>\n",
       "      <td>0.959532</td>\n",
       "      <td>0.958681</td>\n",
       "      <td>0.958851</td>\n",
       "      <td>0.960089</td>\n",
       "      <td>0.959313</td>\n",
       "      <td>0.958565</td>\n",
       "      <td>0.958495</td>\n",
       "      <td>0.959055</td>\n",
       "      <td>0.957576</td>\n",
       "      <td>0.959648</td>\n",
       "      <td>0.002236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43.572259</td>\n",
       "      <td>0.360757</td>\n",
       "      <td>1.301411</td>\n",
       "      <td>0.034867</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>50</td>\n",
       "      <td>4000</td>\n",
       "      <td>True</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (2, 2)...</td>\n",
       "      <td>0.860685</td>\n",
       "      <td>0.838517</td>\n",
       "      <td>0.862651</td>\n",
       "      <td>0.851697</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.853381</td>\n",
       "      <td>0.843431</td>\n",
       "      <td>0.853703</td>\n",
       "      <td>0.847172</td>\n",
       "      <td>0.855286</td>\n",
       "      <td>0.851264</td>\n",
       "      <td>0.867718</td>\n",
       "      <td>0.847981</td>\n",
       "      <td>0.840703</td>\n",
       "      <td>0.864183</td>\n",
       "      <td>0.852031</td>\n",
       "      <td>0.008644</td>\n",
       "      <td>12</td>\n",
       "      <td>0.975758</td>\n",
       "      <td>0.975545</td>\n",
       "      <td>0.985224</td>\n",
       "      <td>0.976453</td>\n",
       "      <td>0.975725</td>\n",
       "      <td>0.976354</td>\n",
       "      <td>0.975432</td>\n",
       "      <td>0.975088</td>\n",
       "      <td>0.975491</td>\n",
       "      <td>0.975852</td>\n",
       "      <td>0.974552</td>\n",
       "      <td>0.975401</td>\n",
       "      <td>0.974589</td>\n",
       "      <td>0.975180</td>\n",
       "      <td>0.975019</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.002491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38.978681</td>\n",
       "      <td>0.286063</td>\n",
       "      <td>1.139982</td>\n",
       "      <td>0.033416</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>40000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.847378</td>\n",
       "      <td>0.833432</td>\n",
       "      <td>0.853206</td>\n",
       "      <td>0.834928</td>\n",
       "      <td>0.833726</td>\n",
       "      <td>0.841478</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>0.838942</td>\n",
       "      <td>0.842486</td>\n",
       "      <td>0.833431</td>\n",
       "      <td>0.838366</td>\n",
       "      <td>0.856972</td>\n",
       "      <td>0.838978</td>\n",
       "      <td>0.832838</td>\n",
       "      <td>0.839759</td>\n",
       "      <td>0.840327</td>\n",
       "      <td>0.006987</td>\n",
       "      <td>13</td>\n",
       "      <td>0.917897</td>\n",
       "      <td>0.917089</td>\n",
       "      <td>0.918157</td>\n",
       "      <td>0.917952</td>\n",
       "      <td>0.923871</td>\n",
       "      <td>0.917556</td>\n",
       "      <td>0.917153</td>\n",
       "      <td>0.917945</td>\n",
       "      <td>0.916212</td>\n",
       "      <td>0.917000</td>\n",
       "      <td>0.918857</td>\n",
       "      <td>0.917462</td>\n",
       "      <td>0.916848</td>\n",
       "      <td>0.918769</td>\n",
       "      <td>0.918325</td>\n",
       "      <td>0.918073</td>\n",
       "      <td>0.001701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.733569</td>\n",
       "      <td>0.790618</td>\n",
       "      <td>0.809252</td>\n",
       "      <td>0.051912</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 1...</td>\n",
       "      <td>0.841537</td>\n",
       "      <td>0.854265</td>\n",
       "      <td>0.856119</td>\n",
       "      <td>0.840528</td>\n",
       "      <td>0.819320</td>\n",
       "      <td>0.831826</td>\n",
       "      <td>0.837870</td>\n",
       "      <td>0.842797</td>\n",
       "      <td>0.841346</td>\n",
       "      <td>0.834334</td>\n",
       "      <td>0.838520</td>\n",
       "      <td>0.831923</td>\n",
       "      <td>0.845972</td>\n",
       "      <td>0.831837</td>\n",
       "      <td>0.841849</td>\n",
       "      <td>0.839337</td>\n",
       "      <td>0.008846</td>\n",
       "      <td>14</td>\n",
       "      <td>0.938872</td>\n",
       "      <td>0.939495</td>\n",
       "      <td>0.961909</td>\n",
       "      <td>0.940027</td>\n",
       "      <td>0.939736</td>\n",
       "      <td>0.940252</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.940278</td>\n",
       "      <td>0.939505</td>\n",
       "      <td>0.939924</td>\n",
       "      <td>0.940777</td>\n",
       "      <td>0.939510</td>\n",
       "      <td>0.938611</td>\n",
       "      <td>0.941494</td>\n",
       "      <td>0.939939</td>\n",
       "      <td>0.941288</td>\n",
       "      <td>0.005557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20.857726</td>\n",
       "      <td>0.246065</td>\n",
       "      <td>0.805013</td>\n",
       "      <td>0.028264</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 1...</td>\n",
       "      <td>0.838632</td>\n",
       "      <td>0.850711</td>\n",
       "      <td>0.852029</td>\n",
       "      <td>0.840528</td>\n",
       "      <td>0.820299</td>\n",
       "      <td>0.830416</td>\n",
       "      <td>0.838671</td>\n",
       "      <td>0.839832</td>\n",
       "      <td>0.841346</td>\n",
       "      <td>0.835033</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>0.830303</td>\n",
       "      <td>0.843044</td>\n",
       "      <td>0.835428</td>\n",
       "      <td>0.841657</td>\n",
       "      <td>0.838248</td>\n",
       "      <td>0.007611</td>\n",
       "      <td>15</td>\n",
       "      <td>0.935814</td>\n",
       "      <td>0.936347</td>\n",
       "      <td>0.958410</td>\n",
       "      <td>0.937495</td>\n",
       "      <td>0.937768</td>\n",
       "      <td>0.938321</td>\n",
       "      <td>0.935967</td>\n",
       "      <td>0.937666</td>\n",
       "      <td>0.936137</td>\n",
       "      <td>0.936621</td>\n",
       "      <td>0.937019</td>\n",
       "      <td>0.935536</td>\n",
       "      <td>0.935228</td>\n",
       "      <td>0.938781</td>\n",
       "      <td>0.936800</td>\n",
       "      <td>0.938261</td>\n",
       "      <td>0.005476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.495369</td>\n",
       "      <td>0.376383</td>\n",
       "      <td>1.085993</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>4000</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.835803</td>\n",
       "      <td>0.819964</td>\n",
       "      <td>0.824730</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.817595</td>\n",
       "      <td>0.838517</td>\n",
       "      <td>0.820482</td>\n",
       "      <td>0.828041</td>\n",
       "      <td>0.826586</td>\n",
       "      <td>0.821239</td>\n",
       "      <td>0.825753</td>\n",
       "      <td>0.839253</td>\n",
       "      <td>0.843230</td>\n",
       "      <td>0.828690</td>\n",
       "      <td>0.830097</td>\n",
       "      <td>0.828092</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>16</td>\n",
       "      <td>0.928150</td>\n",
       "      <td>0.929126</td>\n",
       "      <td>0.932833</td>\n",
       "      <td>0.932156</td>\n",
       "      <td>0.930294</td>\n",
       "      <td>0.930046</td>\n",
       "      <td>0.930060</td>\n",
       "      <td>0.929681</td>\n",
       "      <td>0.929663</td>\n",
       "      <td>0.929798</td>\n",
       "      <td>0.930050</td>\n",
       "      <td>0.929768</td>\n",
       "      <td>0.928828</td>\n",
       "      <td>0.929750</td>\n",
       "      <td>0.930789</td>\n",
       "      <td>0.930066</td>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19.741537</td>\n",
       "      <td>0.367412</td>\n",
       "      <td>0.946736</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 1)...</td>\n",
       "      <td>0.814277</td>\n",
       "      <td>0.811857</td>\n",
       "      <td>0.810036</td>\n",
       "      <td>0.816010</td>\n",
       "      <td>0.785843</td>\n",
       "      <td>0.796386</td>\n",
       "      <td>0.794360</td>\n",
       "      <td>0.811456</td>\n",
       "      <td>0.797590</td>\n",
       "      <td>0.806042</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.798299</td>\n",
       "      <td>0.805425</td>\n",
       "      <td>0.796375</td>\n",
       "      <td>0.810942</td>\n",
       "      <td>0.804382</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>17</td>\n",
       "      <td>0.886222</td>\n",
       "      <td>0.886988</td>\n",
       "      <td>0.894336</td>\n",
       "      <td>0.888252</td>\n",
       "      <td>0.888175</td>\n",
       "      <td>0.888204</td>\n",
       "      <td>0.888404</td>\n",
       "      <td>0.886843</td>\n",
       "      <td>0.887717</td>\n",
       "      <td>0.887204</td>\n",
       "      <td>0.888213</td>\n",
       "      <td>0.887605</td>\n",
       "      <td>0.887034</td>\n",
       "      <td>0.888479</td>\n",
       "      <td>0.888279</td>\n",
       "      <td>0.888130</td>\n",
       "      <td>0.001786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32.194739</td>\n",
       "      <td>0.571864</td>\n",
       "      <td>1.073095</td>\n",
       "      <td>0.038477</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>400</td>\n",
       "      <td>4000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.780226</td>\n",
       "      <td>0.772137</td>\n",
       "      <td>0.806812</td>\n",
       "      <td>0.768957</td>\n",
       "      <td>0.768696</td>\n",
       "      <td>0.784010</td>\n",
       "      <td>0.774081</td>\n",
       "      <td>0.774155</td>\n",
       "      <td>0.769506</td>\n",
       "      <td>0.768342</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.792697</td>\n",
       "      <td>0.768502</td>\n",
       "      <td>0.754695</td>\n",
       "      <td>0.762802</td>\n",
       "      <td>0.774756</td>\n",
       "      <td>0.012104</td>\n",
       "      <td>18</td>\n",
       "      <td>0.797174</td>\n",
       "      <td>0.796197</td>\n",
       "      <td>0.796685</td>\n",
       "      <td>0.797308</td>\n",
       "      <td>0.797953</td>\n",
       "      <td>0.796368</td>\n",
       "      <td>0.799092</td>\n",
       "      <td>0.798420</td>\n",
       "      <td>0.798117</td>\n",
       "      <td>0.798031</td>\n",
       "      <td>0.798031</td>\n",
       "      <td>0.796422</td>\n",
       "      <td>0.797075</td>\n",
       "      <td>0.798789</td>\n",
       "      <td>0.797576</td>\n",
       "      <td>0.797549</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34.620563</td>\n",
       "      <td>1.074870</td>\n",
       "      <td>1.417534</td>\n",
       "      <td>0.104437</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>0.176166</td>\n",
       "      <td>0.035006</td>\n",
       "      <td>0.126294</td>\n",
       "      <td>0.054115</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.118033</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>0.113413</td>\n",
       "      <td>0.065537</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.162839</td>\n",
       "      <td>0.018824</td>\n",
       "      <td>0.114101</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.084761</td>\n",
       "      <td>0.049486</td>\n",
       "      <td>19</td>\n",
       "      <td>0.112691</td>\n",
       "      <td>0.157634</td>\n",
       "      <td>0.036840</td>\n",
       "      <td>0.144051</td>\n",
       "      <td>0.064626</td>\n",
       "      <td>0.034971</td>\n",
       "      <td>0.117152</td>\n",
       "      <td>0.048243</td>\n",
       "      <td>0.106168</td>\n",
       "      <td>0.075756</td>\n",
       "      <td>0.108521</td>\n",
       "      <td>0.149042</td>\n",
       "      <td>0.034225</td>\n",
       "      <td>0.124117</td>\n",
       "      <td>0.032387</td>\n",
       "      <td>0.089762</td>\n",
       "      <td>0.043876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.318727</td>\n",
       "      <td>0.395037</td>\n",
       "      <td>0.722238</td>\n",
       "      <td>0.034487</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 1...</td>\n",
       "      <td>0.069741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.118033</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>0.048443</td>\n",
       "      <td>0.041812</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>0.043931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031744</td>\n",
       "      <td>0.031111</td>\n",
       "      <td>20</td>\n",
       "      <td>0.083320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034971</td>\n",
       "      <td>0.117152</td>\n",
       "      <td>0.048243</td>\n",
       "      <td>0.034323</td>\n",
       "      <td>0.041435</td>\n",
       "      <td>0.038643</td>\n",
       "      <td>0.035003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033451</td>\n",
       "      <td>0.032046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7      166.226714      6.424254         1.725971        0.043466   \n",
       "4       85.847759      2.369713         1.767123        0.067447   \n",
       "19     116.111517     10.599349         1.678619        0.393742   \n",
       "0       31.697148      0.588273         0.937507        0.059456   \n",
       "9       78.177809      1.397992         1.453143        0.033601   \n",
       "5      136.557156      7.096105         1.332794        0.102322   \n",
       "8       38.767830      1.489086         0.998825        0.037903   \n",
       "1       30.442591      1.433217         0.997873        0.037938   \n",
       "10      28.550558      0.460815         0.824389        0.030064   \n",
       "11      52.183430      0.340524         1.499557        0.038864   \n",
       "12      42.239456      0.391517         1.155246        0.043761   \n",
       "18      43.572259      0.360757         1.301411        0.034867   \n",
       "16      38.978681      0.286063         1.139982        0.033416   \n",
       "2       22.733569      0.790618         0.809252        0.051912   \n",
       "15      20.857726      0.246065         0.805013        0.028264   \n",
       "3       36.495369      0.376383         1.085993        0.016617   \n",
       "13      19.741537      0.367412         0.946736        0.036000   \n",
       "17      32.194739      0.571864         1.073095        0.038477   \n",
       "14      34.620563      1.074870         1.417534        0.104437   \n",
       "6       11.318727      0.395037         0.722238        0.034487   \n",
       "\n",
       "   param_vec__stem param_vec__ngram_range param_vec__min_df param_vec__max_df  \\\n",
       "7            False                 (1, 2)                 1               400   \n",
       "4             True                 (1, 2)                 3               400   \n",
       "19            True                 (1, 2)                 3                 1   \n",
       "0             True                 (1, 1)                 1              4000   \n",
       "9             True                 (2, 2)                 3             40000   \n",
       "5            False                 (2, 2)                 1              4000   \n",
       "8             True                 (1, 1)                 3                 1   \n",
       "1             True                 (1, 1)               100             40000   \n",
       "10           False                 (1, 1)               100             40000   \n",
       "11           False                 (1, 2)               400                 1   \n",
       "12           False                 (2, 2)                50             40000   \n",
       "18            True                 (2, 2)                50              4000   \n",
       "16           False                 (2, 2)               100             40000   \n",
       "2            False                 (1, 1)                 1               400   \n",
       "15           False                 (1, 1)                 3               400   \n",
       "3            False                 (2, 2)               100              4000   \n",
       "13            True                 (1, 1)                50               400   \n",
       "17           False                 (2, 2)               400              4000   \n",
       "14           False                 (1, 2)               400               400   \n",
       "6            False                 (1, 1)               400               400   \n",
       "\n",
       "   param_clf__fit_intercept param_clf__C  \\\n",
       "7                     False          0.5   \n",
       "4                      True          0.5   \n",
       "19                    False          0.5   \n",
       "0                     False            2   \n",
       "9                      True            2   \n",
       "5                      True          0.5   \n",
       "8                      True            3   \n",
       "1                      True          0.5   \n",
       "10                     True            1   \n",
       "11                     True            1   \n",
       "12                    False            1   \n",
       "18                     True          2.5   \n",
       "16                     True            1   \n",
       "2                     False          0.5   \n",
       "15                    False            1   \n",
       "3                      True            3   \n",
       "13                    False            3   \n",
       "17                     True          0.5   \n",
       "14                    False          2.5   \n",
       "6                     False          2.5   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "7   {'vec__stem': False, 'vec__ngram_range': (1, 2...           0.908218   \n",
       "4   {'vec__stem': True, 'vec__ngram_range': (1, 2)...           0.906250   \n",
       "19  {'vec__stem': True, 'vec__ngram_range': (1, 2)...           0.897815   \n",
       "0   {'vec__stem': True, 'vec__ngram_range': (1, 1)...           0.886759   \n",
       "9   {'vec__stem': True, 'vec__ngram_range': (2, 2)...           0.883225   \n",
       "5   {'vec__stem': False, 'vec__ngram_range': (2, 2...           0.877732   \n",
       "8   {'vec__stem': True, 'vec__ngram_range': (1, 1)...           0.885850   \n",
       "1   {'vec__stem': True, 'vec__ngram_range': (1, 1)...           0.882701   \n",
       "10  {'vec__stem': False, 'vec__ngram_range': (1, 1...           0.882562   \n",
       "11  {'vec__stem': False, 'vec__ngram_range': (1, 2...           0.871765   \n",
       "12  {'vec__stem': False, 'vec__ngram_range': (2, 2...           0.869462   \n",
       "18  {'vec__stem': True, 'vec__ngram_range': (2, 2)...           0.860685   \n",
       "16  {'vec__stem': False, 'vec__ngram_range': (2, 2...           0.847378   \n",
       "2   {'vec__stem': False, 'vec__ngram_range': (1, 1...           0.841537   \n",
       "15  {'vec__stem': False, 'vec__ngram_range': (1, 1...           0.838632   \n",
       "3   {'vec__stem': False, 'vec__ngram_range': (2, 2...           0.835803   \n",
       "13  {'vec__stem': True, 'vec__ngram_range': (1, 1)...           0.814277   \n",
       "17  {'vec__stem': False, 'vec__ngram_range': (2, 2...           0.780226   \n",
       "14  {'vec__stem': False, 'vec__ngram_range': (1, 2...           0.092715   \n",
       "6   {'vec__stem': False, 'vec__ngram_range': (1, 1...           0.069741   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7            0.906195           0.904061           0.906509   \n",
       "4            0.906509           0.901659           0.903149   \n",
       "19           0.895328           0.903766           0.883749   \n",
       "0            0.893238           0.892963           0.893617   \n",
       "9            0.884410           0.898154           0.872619   \n",
       "5            0.882840           0.894988           0.869668   \n",
       "8            0.895080           0.886486           0.877297   \n",
       "1            0.887307           0.879042           0.871674   \n",
       "10           0.887307           0.880240           0.871674   \n",
       "11           0.872216           0.878951           0.856637   \n",
       "12           0.849821           0.874552           0.853746   \n",
       "18           0.838517           0.862651           0.851697   \n",
       "16           0.833432           0.853206           0.834928   \n",
       "2            0.854265           0.856119           0.840528   \n",
       "15           0.850711           0.852029           0.840528   \n",
       "3            0.819964           0.824730           0.821429   \n",
       "13           0.811857           0.810036           0.816010   \n",
       "17           0.772137           0.806812           0.768957   \n",
       "14           0.176166           0.035006           0.126294   \n",
       "6            0.000000           0.000000           0.028005   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "7            0.889810           0.918404           0.902728   \n",
       "4            0.889680           0.917114           0.901008   \n",
       "19           0.888889           0.892454           0.895895   \n",
       "0            0.873604           0.897119           0.894484   \n",
       "9            0.879391           0.883472           0.875904   \n",
       "5            0.881633           0.884638           0.880526   \n",
       "8            0.883529           0.882423           0.894454   \n",
       "1            0.875222           0.877817           0.892729   \n",
       "10           0.875222           0.876631           0.892069   \n",
       "11           0.869667           0.869668           0.877527   \n",
       "12           0.849412           0.863258           0.853012   \n",
       "18           0.842105           0.853381           0.843431   \n",
       "16           0.833726           0.841478           0.838983   \n",
       "2            0.819320           0.831826           0.837870   \n",
       "15           0.820299           0.830416           0.838671   \n",
       "3            0.817595           0.838517           0.820482   \n",
       "13           0.785843           0.796386           0.794360   \n",
       "17           0.768696           0.784010           0.774081   \n",
       "14           0.054115           0.028037           0.118033   \n",
       "6            0.000000           0.028037           0.118033   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  \\\n",
       "7            0.905592           0.902527           0.896469   \n",
       "4            0.905162           0.900000           0.894202   \n",
       "19           0.891030           0.872162           0.886905   \n",
       "0            0.882107           0.874180           0.883553   \n",
       "9            0.880337           0.884110           0.880668   \n",
       "5            0.881579           0.877025           0.880995   \n",
       "8            0.878951           0.859534           0.883164   \n",
       "1            0.872315           0.858845           0.876418   \n",
       "10           0.871795           0.859012           0.876418   \n",
       "11           0.866387           0.853906           0.863284   \n",
       "12           0.858348           0.856284           0.855450   \n",
       "18           0.853703           0.847172           0.855286   \n",
       "16           0.838942           0.842486           0.833431   \n",
       "2            0.842797           0.841346           0.834334   \n",
       "15           0.839832           0.841346           0.835033   \n",
       "3            0.828041           0.826586           0.821239   \n",
       "13           0.811456           0.797590           0.806042   \n",
       "17           0.774155           0.769506           0.768342   \n",
       "14           0.035211           0.113413           0.065537   \n",
       "6            0.035211           0.048443           0.041812   \n",
       "\n",
       "    split10_test_score  split11_test_score  split12_test_score  \\\n",
       "7             0.888758            0.904474            0.914591   \n",
       "4             0.887581            0.902913            0.915033   \n",
       "19            0.884863            0.897862            0.887299   \n",
       "0             0.864897            0.875075            0.891136   \n",
       "9             0.873455            0.890354            0.880712   \n",
       "5             0.879250            0.895522            0.879717   \n",
       "8             0.865882            0.884661            0.877732   \n",
       "1             0.861846            0.881759            0.875369   \n",
       "10            0.861340            0.881759            0.875887   \n",
       "11            0.853428            0.873960            0.869410   \n",
       "12            0.856471            0.875983            0.854599   \n",
       "18            0.851264            0.867718            0.847981   \n",
       "16            0.838366            0.856972            0.838978   \n",
       "2             0.838520            0.831923            0.845972   \n",
       "15            0.835786            0.830303            0.843044   \n",
       "3             0.825753            0.839253            0.843230   \n",
       "13            0.810811            0.798299            0.805425   \n",
       "17            0.775701            0.792697            0.768502   \n",
       "14            0.105263            0.162839            0.018824   \n",
       "6             0.034884            0.043931            0.000000   \n",
       "\n",
       "    split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "7             0.895307            0.915417         0.903937        0.008371   \n",
       "4             0.897467            0.914217         0.902796        0.008305   \n",
       "19            0.883086            0.898032         0.890610        0.007708   \n",
       "0             0.876270            0.894075         0.884873        0.009666   \n",
       "9             0.874552            0.891843         0.882214        0.006869   \n",
       "5             0.875895            0.891173         0.882212        0.006789   \n",
       "8             0.876043            0.893921         0.881669        0.009529   \n",
       "1             0.867024            0.891266         0.876757        0.009421   \n",
       "10            0.867024            0.891136         0.876673        0.009395   \n",
       "11            0.859356            0.874479         0.867377        0.008006   \n",
       "12            0.851652            0.864897         0.859130        0.008296   \n",
       "18            0.840703            0.864183         0.852031        0.008644   \n",
       "16            0.832838            0.839759         0.840327        0.006987   \n",
       "2             0.831837            0.841849         0.839337        0.008846   \n",
       "15            0.835428            0.841657         0.838248        0.007611   \n",
       "3             0.828690            0.830097         0.828092        0.007619   \n",
       "13            0.796375            0.810942         0.804382        0.008621   \n",
       "17            0.754695            0.762802         0.774756        0.012104   \n",
       "14            0.114101            0.025791         0.084761        0.049486   \n",
       "6             0.028136            0.000000         0.031744        0.031111   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "7                 1            0.998199            0.998328   \n",
       "4                 2            0.996741            0.996484   \n",
       "19                3            0.938972            0.939002   \n",
       "0                 4            0.955329            0.955374   \n",
       "9                 5            0.997558            0.997343   \n",
       "5                 6            0.999100            0.999271   \n",
       "8                 7            0.908704            0.908016   \n",
       "1                 8            0.896084            0.895635   \n",
       "10                9            0.896019            0.895541   \n",
       "11               10            0.885271            0.886155   \n",
       "12               11            0.959251            0.959536   \n",
       "18               12            0.975758            0.975545   \n",
       "16               13            0.917897            0.917089   \n",
       "2                14            0.938872            0.939495   \n",
       "15               15            0.935814            0.936347   \n",
       "3                16            0.928150            0.929126   \n",
       "13               17            0.886222            0.886988   \n",
       "17               18            0.797174            0.796197   \n",
       "14               19            0.112691            0.157634   \n",
       "6                20            0.083320            0.000000   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "7             0.999614            0.998114            0.998113   \n",
       "4             0.999057            0.996398            0.996141   \n",
       "19            0.945826            0.940518            0.939615   \n",
       "0             0.975572            0.954711            0.956336   \n",
       "9             0.997515            0.997258            0.998286   \n",
       "5             0.999657            0.999100            0.999057   \n",
       "8             0.913006            0.909037            0.908727   \n",
       "1             0.898769            0.896722            0.896748   \n",
       "10            0.898650            0.897023            0.896874   \n",
       "11            0.887126            0.886655            0.886681   \n",
       "12            0.958971            0.959904            0.967712   \n",
       "18            0.985224            0.976453            0.975725   \n",
       "16            0.918157            0.917952            0.923871   \n",
       "2             0.961909            0.940027            0.939736   \n",
       "15            0.958410            0.937495            0.937768   \n",
       "3             0.932833            0.932156            0.930294   \n",
       "13            0.894336            0.888252            0.888175   \n",
       "17            0.796685            0.797308            0.797953   \n",
       "14            0.036840            0.144051            0.064626   \n",
       "6             0.000000            0.034337            0.000000   \n",
       "\n",
       "    split5_train_score  split6_train_score  split7_train_score  \\\n",
       "7             0.997942            0.998027            0.998199   \n",
       "4             0.996269            0.996097            0.996313   \n",
       "19            0.941166            0.940021            0.940007   \n",
       "0             0.955931            0.954839            0.955330   \n",
       "9             0.997300            0.997429            0.997386   \n",
       "5             0.999143            0.999271            0.999143   \n",
       "8             0.909215            0.908364            0.907776   \n",
       "1             0.895849            0.894996            0.895307   \n",
       "10            0.895925            0.894949            0.895401   \n",
       "11            0.885637            0.885035            0.885546   \n",
       "12            0.959191            0.959532            0.958681   \n",
       "18            0.976354            0.975432            0.975088   \n",
       "16            0.917556            0.917153            0.917945   \n",
       "2             0.940252            0.938993            0.940278   \n",
       "15            0.938321            0.935967            0.937666   \n",
       "3             0.930046            0.930060            0.929681   \n",
       "13            0.888204            0.888404            0.886843   \n",
       "17            0.796368            0.799092            0.798420   \n",
       "14            0.034971            0.117152            0.048243   \n",
       "6             0.034971            0.117152            0.048243   \n",
       "\n",
       "    split8_train_score  split9_train_score  split10_train_score  \\\n",
       "7             0.997942            0.998242             0.998199   \n",
       "4             0.996055            0.996485             0.996228   \n",
       "19            0.940474            0.940583             0.939478   \n",
       "0             0.955436            0.956715             0.956240   \n",
       "9             0.997558            0.997343             0.997344   \n",
       "5             0.999057            0.999143             0.999143   \n",
       "8             0.910304            0.908310             0.908820   \n",
       "1             0.897935            0.896274             0.897226   \n",
       "10            0.898084            0.896660             0.897076   \n",
       "11            0.886759            0.887418             0.886439   \n",
       "12            0.958851            0.960089             0.959313   \n",
       "18            0.975491            0.975852             0.974552   \n",
       "16            0.916212            0.917000             0.918857   \n",
       "2             0.939505            0.939924             0.940777   \n",
       "15            0.936137            0.936621             0.937019   \n",
       "3             0.929663            0.929798             0.930050   \n",
       "13            0.887717            0.887204             0.888213   \n",
       "17            0.798117            0.798031             0.798031   \n",
       "14            0.106168            0.075756             0.108521   \n",
       "6             0.034323            0.041435             0.038643   \n",
       "\n",
       "    split11_train_score  split12_train_score  split13_train_score  \\\n",
       "7              0.998157             0.998242             0.998242   \n",
       "4              0.996527             0.996226             0.996612   \n",
       "19             0.939239             0.939503             0.940318   \n",
       "0              0.955293             0.955144             0.955939   \n",
       "9              0.997686             0.997343             0.997386   \n",
       "5              0.999143             0.999272             0.999229   \n",
       "8              0.907522             0.907938             0.907839   \n",
       "1              0.896496             0.896496             0.896124   \n",
       "10             0.896458             0.897011             0.895954   \n",
       "11             0.886289             0.887277             0.886938   \n",
       "12             0.958565             0.958495             0.959055   \n",
       "18             0.975401             0.974589             0.975180   \n",
       "16             0.917462             0.916848             0.918769   \n",
       "2              0.939510             0.938611             0.941494   \n",
       "15             0.935536             0.935228             0.938781   \n",
       "3              0.929768             0.928828             0.929750   \n",
       "13             0.887605             0.887034             0.888479   \n",
       "17             0.796422             0.797075             0.798789   \n",
       "14             0.149042             0.034225             0.124117   \n",
       "6              0.035003             0.000000             0.034334   \n",
       "\n",
       "    split14_train_score  mean_train_score  std_train_score  \n",
       "7              0.998156          0.998248         0.000380  \n",
       "4              0.996483          0.996541         0.000699  \n",
       "19             0.940017          0.940316         0.001592  \n",
       "0              0.955043          0.956882         0.005026  \n",
       "9              0.997471          0.997480         0.000242  \n",
       "5              0.999229          0.999197         0.000142  \n",
       "8              0.906688          0.908684         0.001411  \n",
       "1              0.894710          0.896358         0.001032  \n",
       "10             0.895003          0.896442         0.001025  \n",
       "11             0.885311          0.886303         0.000751  \n",
       "12             0.957576          0.959648         0.002236  \n",
       "18             0.975019          0.976111         0.002491  \n",
       "16             0.918325          0.918073         0.001701  \n",
       "2              0.939939          0.941288         0.005557  \n",
       "15             0.936800          0.938261         0.005476  \n",
       "3              0.930789          0.930066         0.001133  \n",
       "13             0.888279          0.888130         0.001786  \n",
       "17             0.797576          0.797549         0.000868  \n",
       "14             0.032387          0.089762         0.043876  \n",
       "6              0.000000          0.033451         0.032046  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rs_regression_bow.cv_results_).sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3130.155014038086, {'clf__C': 0.5}, 0.898628527364711)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_regression_bin = {\n",
    "#     'vec__stem': [True, False],\n",
    "#     'clf__fit_intercept': [True, False], \n",
    "    'clf__C': [.5, 1, 2, 2.5, 3], \n",
    "}\n",
    "\n",
    "pipeline_regression_bin = Pipeline([\n",
    "    ('vec', LemmaCountVectorizer(strip_accents='unicode', stop_words=None, binary=True, max_df=400, min_df=3,\n",
    "                                ngram_range=(1,2), stem=True)),\n",
    "    ('clf', LogisticRegression(solver='saga', penalty='l2', fit_intercept=True, max_iter=1000))\n",
    "])\n",
    "                  \n",
    "rs_regression_bin = GridSearchCV(pipeline_regression_bin, parameters_regression_bin, \n",
    "                                   cv=15, scoring=score, n_jobs=-1, verbose=0, return_train_score=True)\n",
    "                            #, random_state=62, n_iter=20)\n",
    "start = time.time()\n",
    "rs_regression_bin.fit(X_train, y)\n",
    "time.time() - start, rs_regression_bin.best_params_, rs_regression_bin.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>split10_train_score</th>\n",
       "      <th>split11_train_score</th>\n",
       "      <th>split12_train_score</th>\n",
       "      <th>split13_train_score</th>\n",
       "      <th>split14_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133.971525</td>\n",
       "      <td>5.449681</td>\n",
       "      <td>1.785534</td>\n",
       "      <td>0.056230</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__C': 0.5}</td>\n",
       "      <td>0.900417</td>\n",
       "      <td>0.898810</td>\n",
       "      <td>0.896877</td>\n",
       "      <td>0.910059</td>\n",
       "      <td>0.890855</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.894863</td>\n",
       "      <td>0.900599</td>\n",
       "      <td>0.892234</td>\n",
       "      <td>0.890077</td>\n",
       "      <td>0.890330</td>\n",
       "      <td>0.900846</td>\n",
       "      <td>0.903915</td>\n",
       "      <td>0.898032</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.898629</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>318.443131</td>\n",
       "      <td>43.856621</td>\n",
       "      <td>2.851072</td>\n",
       "      <td>0.439883</td>\n",
       "      <td>2</td>\n",
       "      <td>{'clf__C': 2}</td>\n",
       "      <td>0.899881</td>\n",
       "      <td>0.898154</td>\n",
       "      <td>0.898055</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.887316</td>\n",
       "      <td>0.902954</td>\n",
       "      <td>0.894202</td>\n",
       "      <td>0.901138</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.889021</td>\n",
       "      <td>0.890727</td>\n",
       "      <td>0.902009</td>\n",
       "      <td>0.904988</td>\n",
       "      <td>0.897375</td>\n",
       "      <td>0.904847</td>\n",
       "      <td>0.897932</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208.644525</td>\n",
       "      <td>34.345073</td>\n",
       "      <td>1.789688</td>\n",
       "      <td>0.094095</td>\n",
       "      <td>1</td>\n",
       "      <td>{'clf__C': 1}</td>\n",
       "      <td>0.901190</td>\n",
       "      <td>0.899345</td>\n",
       "      <td>0.897527</td>\n",
       "      <td>0.906619</td>\n",
       "      <td>0.890201</td>\n",
       "      <td>0.903070</td>\n",
       "      <td>0.894611</td>\n",
       "      <td>0.899522</td>\n",
       "      <td>0.889958</td>\n",
       "      <td>0.889549</td>\n",
       "      <td>0.889676</td>\n",
       "      <td>0.902365</td>\n",
       "      <td>0.903264</td>\n",
       "      <td>0.896716</td>\n",
       "      <td>0.903535</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>340.501094</td>\n",
       "      <td>59.288024</td>\n",
       "      <td>2.373999</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>3</td>\n",
       "      <td>{'clf__C': 3}</td>\n",
       "      <td>0.898568</td>\n",
       "      <td>0.897619</td>\n",
       "      <td>0.896877</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.886001</td>\n",
       "      <td>0.902410</td>\n",
       "      <td>0.894075</td>\n",
       "      <td>0.900480</td>\n",
       "      <td>0.892621</td>\n",
       "      <td>0.888493</td>\n",
       "      <td>0.890071</td>\n",
       "      <td>0.902795</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>0.898447</td>\n",
       "      <td>0.903535</td>\n",
       "      <td>0.897566</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>381.080221</td>\n",
       "      <td>16.098765</td>\n",
       "      <td>2.960047</td>\n",
       "      <td>0.205324</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'clf__C': 2.5}</td>\n",
       "      <td>0.899881</td>\n",
       "      <td>0.898275</td>\n",
       "      <td>0.898055</td>\n",
       "      <td>0.906509</td>\n",
       "      <td>0.886659</td>\n",
       "      <td>0.902410</td>\n",
       "      <td>0.892879</td>\n",
       "      <td>0.901020</td>\n",
       "      <td>0.891291</td>\n",
       "      <td>0.889680</td>\n",
       "      <td>0.888757</td>\n",
       "      <td>0.901340</td>\n",
       "      <td>0.904451</td>\n",
       "      <td>0.894988</td>\n",
       "      <td>0.904192</td>\n",
       "      <td>0.897359</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_clf__C  \\\n",
       "0     133.971525      5.449681         1.785534        0.056230          0.5   \n",
       "2     318.443131     43.856621         2.851072        0.439883            2   \n",
       "1     208.644525     34.345073         1.789688        0.094095            1   \n",
       "4     340.501094     59.288024         2.373999        0.550459            3   \n",
       "3     381.080221     16.098765         2.960047        0.205324          2.5   \n",
       "\n",
       "            params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'clf__C': 0.5}           0.900417           0.898810           0.896877   \n",
       "2    {'clf__C': 2}           0.899881           0.898154           0.898055   \n",
       "1    {'clf__C': 1}           0.901190           0.899345           0.897527   \n",
       "4    {'clf__C': 3}           0.898568           0.897619           0.896877   \n",
       "3  {'clf__C': 2.5}           0.899881           0.898275           0.898055   \n",
       "\n",
       "   split3_test_score  split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0           0.910059           0.890855           0.903614           0.894863   \n",
       "2           0.907692           0.887316           0.902954           0.894202   \n",
       "1           0.906619           0.890201           0.903070           0.894611   \n",
       "4           0.907692           0.886001           0.902410           0.894075   \n",
       "3           0.906509           0.886659           0.902410           0.892879   \n",
       "\n",
       "   split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0           0.900599           0.892234           0.890077   \n",
       "2           0.901138           0.890625           0.889021   \n",
       "1           0.899522           0.889958           0.889549   \n",
       "4           0.900480           0.892621           0.888493   \n",
       "3           0.901020           0.891291           0.889680   \n",
       "\n",
       "   split10_test_score  split11_test_score  split12_test_score  \\\n",
       "0            0.890330            0.900846            0.903915   \n",
       "2            0.890727            0.902009            0.904988   \n",
       "1            0.889676            0.902365            0.903264   \n",
       "4            0.890071            0.902795            0.903800   \n",
       "3            0.888757            0.901340            0.904451   \n",
       "\n",
       "   split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.898032            0.907895         0.898629        0.006013   \n",
       "2            0.897375            0.904847         0.897932        0.006113   \n",
       "1            0.896716            0.903535         0.897810        0.005602   \n",
       "4            0.898447            0.903535         0.897566        0.006042   \n",
       "3            0.894988            0.904192         0.897359        0.006073   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                1                 1.0                 1.0   \n",
       "2                2                 1.0                 1.0   \n",
       "1                3                 1.0                 1.0   \n",
       "4                4                 1.0                 1.0   \n",
       "3                5                 1.0                 1.0   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0                 1.0                 1.0                 1.0   \n",
       "2                 1.0                 1.0                 1.0   \n",
       "1                 1.0                 1.0                 1.0   \n",
       "4                 1.0                 1.0                 1.0   \n",
       "3                 1.0                 1.0                 1.0   \n",
       "\n",
       "   split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0            0.999957                 1.0                 1.0   \n",
       "2            1.000000                 1.0                 1.0   \n",
       "1            1.000000                 1.0                 1.0   \n",
       "4            1.000000                 1.0                 1.0   \n",
       "3            1.000000                 1.0                 1.0   \n",
       "\n",
       "   split8_train_score  split9_train_score  split10_train_score  \\\n",
       "0                 1.0                 1.0             0.999957   \n",
       "2                 1.0                 1.0             1.000000   \n",
       "1                 1.0                 1.0             1.000000   \n",
       "4                 1.0                 1.0             1.000000   \n",
       "3                 1.0                 1.0             1.000000   \n",
       "\n",
       "   split11_train_score  split12_train_score  split13_train_score  \\\n",
       "0                  1.0                  1.0                  1.0   \n",
       "2                  1.0                  1.0                  1.0   \n",
       "1                  1.0                  1.0                  1.0   \n",
       "4                  1.0                  1.0                  1.0   \n",
       "3                  1.0                  1.0                  1.0   \n",
       "\n",
       "   split14_train_score  mean_train_score  std_train_score  \n",
       "0                  1.0          0.999994         0.000015  \n",
       "2                  1.0          1.000000         0.000000  \n",
       "1                  1.0          1.000000         0.000000  \n",
       "4                  1.0          1.000000         0.000000  \n",
       "3                  1.0          1.000000         0.000000  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rs_regression_bin.cv_results_).sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering considering BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2094.5416519641876,\n",
       " {'vec__stem': False,\n",
       "  'vec__ngram_range': (2, 2),\n",
       "  'vec__min_df': 1,\n",
       "  'vec__max_df': 1.0,\n",
       "  'clf__alpha': 2},\n",
       " 0.8875362305239204)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_mnv_bow = {\n",
    "    'vec__min_df': [3, 50, 100, 400, 1],\n",
    "    'vec__max_df': [4000, 40000, 1.0],\n",
    "    'vec__stem': [True, False],\n",
    "    'vec__ngram_range':[(1, 2), (2, 2)],\n",
    "    'clf__alpha': [.5, .1, 2, 3], \n",
    "}\n",
    "\n",
    "pipeline_mnv_bow = Pipeline([\n",
    "    ('vec', LemmaCountVectorizer(strip_accents='unicode', stop_words=None, binary=False)),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "                  \n",
    "rs_mnv_bow = RandomizedSearchCV(pipeline_mnv_bow, parameters_mnv_bow, \n",
    "                                   cv=15, scoring=score, n_jobs=-1, verbose=0, random_state=62, n_iter=20\n",
    "                               , return_train_score=True)\n",
    "start = time.time()\n",
    "rs_mnv_bow.fit(X_train, y)\n",
    "time.time() - start, rs_mnv_bow.best_params_, rs_mnv_bow.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_vec__stem</th>\n",
       "      <th>param_vec__ngram_range</th>\n",
       "      <th>param_vec__min_df</th>\n",
       "      <th>param_vec__max_df</th>\n",
       "      <th>param_clf__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>split10_train_score</th>\n",
       "      <th>split11_train_score</th>\n",
       "      <th>split12_train_score</th>\n",
       "      <th>split13_train_score</th>\n",
       "      <th>split14_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>34.044776</td>\n",
       "      <td>1.324582</td>\n",
       "      <td>1.451944</td>\n",
       "      <td>0.122455</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.879511</td>\n",
       "      <td>0.900480</td>\n",
       "      <td>0.899094</td>\n",
       "      <td>0.883273</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.888485</td>\n",
       "      <td>0.894231</td>\n",
       "      <td>0.893513</td>\n",
       "      <td>0.874156</td>\n",
       "      <td>0.879569</td>\n",
       "      <td>0.871299</td>\n",
       "      <td>0.889851</td>\n",
       "      <td>0.894417</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.885487</td>\n",
       "      <td>0.887536</td>\n",
       "      <td>0.008322</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994407</td>\n",
       "      <td>0.994103</td>\n",
       "      <td>0.994192</td>\n",
       "      <td>0.993845</td>\n",
       "      <td>0.994320</td>\n",
       "      <td>0.993931</td>\n",
       "      <td>0.993497</td>\n",
       "      <td>0.994017</td>\n",
       "      <td>0.993844</td>\n",
       "      <td>0.993931</td>\n",
       "      <td>0.993844</td>\n",
       "      <td>0.993628</td>\n",
       "      <td>0.993585</td>\n",
       "      <td>0.994105</td>\n",
       "      <td>0.993973</td>\n",
       "      <td>0.993948</td>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.765195</td>\n",
       "      <td>0.591089</td>\n",
       "      <td>1.263353</td>\n",
       "      <td>0.068790</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (2, 2)...</td>\n",
       "      <td>0.878825</td>\n",
       "      <td>0.900480</td>\n",
       "      <td>0.899215</td>\n",
       "      <td>0.883273</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.887136</td>\n",
       "      <td>0.894231</td>\n",
       "      <td>0.892835</td>\n",
       "      <td>0.874156</td>\n",
       "      <td>0.879569</td>\n",
       "      <td>0.871299</td>\n",
       "      <td>0.889851</td>\n",
       "      <td>0.894417</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.885487</td>\n",
       "      <td>0.887364</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994407</td>\n",
       "      <td>0.994103</td>\n",
       "      <td>0.994192</td>\n",
       "      <td>0.993845</td>\n",
       "      <td>0.994277</td>\n",
       "      <td>0.993888</td>\n",
       "      <td>0.993540</td>\n",
       "      <td>0.994060</td>\n",
       "      <td>0.993888</td>\n",
       "      <td>0.993931</td>\n",
       "      <td>0.993931</td>\n",
       "      <td>0.993628</td>\n",
       "      <td>0.993672</td>\n",
       "      <td>0.994148</td>\n",
       "      <td>0.994017</td>\n",
       "      <td>0.993968</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33.520434</td>\n",
       "      <td>0.387535</td>\n",
       "      <td>1.636981</td>\n",
       "      <td>0.050569</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.877724</td>\n",
       "      <td>0.897619</td>\n",
       "      <td>0.898082</td>\n",
       "      <td>0.883582</td>\n",
       "      <td>0.886499</td>\n",
       "      <td>0.882424</td>\n",
       "      <td>0.894358</td>\n",
       "      <td>0.892683</td>\n",
       "      <td>0.872881</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.870813</td>\n",
       "      <td>0.883436</td>\n",
       "      <td>0.893848</td>\n",
       "      <td>0.880866</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.885114</td>\n",
       "      <td>0.009012</td>\n",
       "      <td>3</td>\n",
       "      <td>0.979375</td>\n",
       "      <td>0.979666</td>\n",
       "      <td>0.979627</td>\n",
       "      <td>0.979459</td>\n",
       "      <td>0.979678</td>\n",
       "      <td>0.979325</td>\n",
       "      <td>0.979219</td>\n",
       "      <td>0.979449</td>\n",
       "      <td>0.979458</td>\n",
       "      <td>0.979235</td>\n",
       "      <td>0.979654</td>\n",
       "      <td>0.979410</td>\n",
       "      <td>0.979263</td>\n",
       "      <td>0.979719</td>\n",
       "      <td>0.978902</td>\n",
       "      <td>0.979429</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27.759025</td>\n",
       "      <td>0.492543</td>\n",
       "      <td>1.254746</td>\n",
       "      <td>0.049892</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (2, 2)...</td>\n",
       "      <td>0.874543</td>\n",
       "      <td>0.896305</td>\n",
       "      <td>0.900417</td>\n",
       "      <td>0.873425</td>\n",
       "      <td>0.880854</td>\n",
       "      <td>0.883524</td>\n",
       "      <td>0.881824</td>\n",
       "      <td>0.889024</td>\n",
       "      <td>0.878935</td>\n",
       "      <td>0.873139</td>\n",
       "      <td>0.864702</td>\n",
       "      <td>0.889161</td>\n",
       "      <td>0.893180</td>\n",
       "      <td>0.876729</td>\n",
       "      <td>0.884428</td>\n",
       "      <td>0.882680</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>4</td>\n",
       "      <td>0.983544</td>\n",
       "      <td>0.983585</td>\n",
       "      <td>0.983588</td>\n",
       "      <td>0.983465</td>\n",
       "      <td>0.983501</td>\n",
       "      <td>0.983410</td>\n",
       "      <td>0.982834</td>\n",
       "      <td>0.983195</td>\n",
       "      <td>0.983402</td>\n",
       "      <td>0.983365</td>\n",
       "      <td>0.983182</td>\n",
       "      <td>0.982577</td>\n",
       "      <td>0.982639</td>\n",
       "      <td>0.983153</td>\n",
       "      <td>0.983325</td>\n",
       "      <td>0.983251</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.109603</td>\n",
       "      <td>3.415638</td>\n",
       "      <td>1.886761</td>\n",
       "      <td>0.184386</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.894833</td>\n",
       "      <td>0.879854</td>\n",
       "      <td>0.885662</td>\n",
       "      <td>0.877839</td>\n",
       "      <td>0.888082</td>\n",
       "      <td>0.885609</td>\n",
       "      <td>0.868389</td>\n",
       "      <td>0.863388</td>\n",
       "      <td>0.862674</td>\n",
       "      <td>0.877085</td>\n",
       "      <td>0.891743</td>\n",
       "      <td>0.876144</td>\n",
       "      <td>0.877538</td>\n",
       "      <td>0.879833</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>5</td>\n",
       "      <td>0.995441</td>\n",
       "      <td>0.995743</td>\n",
       "      <td>0.995527</td>\n",
       "      <td>0.995570</td>\n",
       "      <td>0.995571</td>\n",
       "      <td>0.995311</td>\n",
       "      <td>0.995440</td>\n",
       "      <td>0.995527</td>\n",
       "      <td>0.995441</td>\n",
       "      <td>0.995225</td>\n",
       "      <td>0.995829</td>\n",
       "      <td>0.995484</td>\n",
       "      <td>0.995440</td>\n",
       "      <td>0.995528</td>\n",
       "      <td>0.995398</td>\n",
       "      <td>0.995498</td>\n",
       "      <td>0.000145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33.323997</td>\n",
       "      <td>0.202405</td>\n",
       "      <td>1.633830</td>\n",
       "      <td>0.038543</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 2)...</td>\n",
       "      <td>0.868179</td>\n",
       "      <td>0.887145</td>\n",
       "      <td>0.885662</td>\n",
       "      <td>0.876053</td>\n",
       "      <td>0.878752</td>\n",
       "      <td>0.877301</td>\n",
       "      <td>0.885938</td>\n",
       "      <td>0.881377</td>\n",
       "      <td>0.869193</td>\n",
       "      <td>0.859036</td>\n",
       "      <td>0.861631</td>\n",
       "      <td>0.875849</td>\n",
       "      <td>0.887668</td>\n",
       "      <td>0.871420</td>\n",
       "      <td>0.878287</td>\n",
       "      <td>0.876234</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>6</td>\n",
       "      <td>0.956390</td>\n",
       "      <td>0.957618</td>\n",
       "      <td>0.957577</td>\n",
       "      <td>0.957090</td>\n",
       "      <td>0.957008</td>\n",
       "      <td>0.956446</td>\n",
       "      <td>0.956688</td>\n",
       "      <td>0.956729</td>\n",
       "      <td>0.957370</td>\n",
       "      <td>0.955658</td>\n",
       "      <td>0.957842</td>\n",
       "      <td>0.956552</td>\n",
       "      <td>0.956729</td>\n",
       "      <td>0.957932</td>\n",
       "      <td>0.956352</td>\n",
       "      <td>0.956932</td>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34.707736</td>\n",
       "      <td>0.279987</td>\n",
       "      <td>1.727475</td>\n",
       "      <td>0.057689</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1</td>\n",
       "      <td>40000</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 2)...</td>\n",
       "      <td>0.867440</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.888087</td>\n",
       "      <td>0.874850</td>\n",
       "      <td>0.877404</td>\n",
       "      <td>0.875610</td>\n",
       "      <td>0.887688</td>\n",
       "      <td>0.881418</td>\n",
       "      <td>0.861670</td>\n",
       "      <td>0.861244</td>\n",
       "      <td>0.858859</td>\n",
       "      <td>0.877236</td>\n",
       "      <td>0.886045</td>\n",
       "      <td>0.870247</td>\n",
       "      <td>0.876679</td>\n",
       "      <td>0.875237</td>\n",
       "      <td>0.009301</td>\n",
       "      <td>7</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.972731</td>\n",
       "      <td>0.973700</td>\n",
       "      <td>0.972729</td>\n",
       "      <td>0.973046</td>\n",
       "      <td>0.972640</td>\n",
       "      <td>0.972625</td>\n",
       "      <td>0.972555</td>\n",
       "      <td>0.973480</td>\n",
       "      <td>0.973041</td>\n",
       "      <td>0.972818</td>\n",
       "      <td>0.972987</td>\n",
       "      <td>0.972893</td>\n",
       "      <td>0.973219</td>\n",
       "      <td>0.972088</td>\n",
       "      <td>0.972916</td>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>35.665286</td>\n",
       "      <td>1.673867</td>\n",
       "      <td>1.609806</td>\n",
       "      <td>0.091467</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.864167</td>\n",
       "      <td>0.885385</td>\n",
       "      <td>0.881995</td>\n",
       "      <td>0.873341</td>\n",
       "      <td>0.873716</td>\n",
       "      <td>0.874539</td>\n",
       "      <td>0.885784</td>\n",
       "      <td>0.877601</td>\n",
       "      <td>0.861709</td>\n",
       "      <td>0.856451</td>\n",
       "      <td>0.855407</td>\n",
       "      <td>0.868159</td>\n",
       "      <td>0.883037</td>\n",
       "      <td>0.869671</td>\n",
       "      <td>0.877689</td>\n",
       "      <td>0.872578</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>8</td>\n",
       "      <td>0.940639</td>\n",
       "      <td>0.941156</td>\n",
       "      <td>0.942409</td>\n",
       "      <td>0.940951</td>\n",
       "      <td>0.941713</td>\n",
       "      <td>0.940915</td>\n",
       "      <td>0.941279</td>\n",
       "      <td>0.940281</td>\n",
       "      <td>0.941356</td>\n",
       "      <td>0.939967</td>\n",
       "      <td>0.941141</td>\n",
       "      <td>0.941320</td>\n",
       "      <td>0.940695</td>\n",
       "      <td>0.943111</td>\n",
       "      <td>0.940475</td>\n",
       "      <td>0.941161</td>\n",
       "      <td>0.000775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38.199033</td>\n",
       "      <td>3.940846</td>\n",
       "      <td>1.809658</td>\n",
       "      <td>0.134746</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>40000</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 2)...</td>\n",
       "      <td>0.863469</td>\n",
       "      <td>0.885385</td>\n",
       "      <td>0.882675</td>\n",
       "      <td>0.873341</td>\n",
       "      <td>0.873716</td>\n",
       "      <td>0.874539</td>\n",
       "      <td>0.885784</td>\n",
       "      <td>0.877601</td>\n",
       "      <td>0.861709</td>\n",
       "      <td>0.856451</td>\n",
       "      <td>0.855407</td>\n",
       "      <td>0.868159</td>\n",
       "      <td>0.883037</td>\n",
       "      <td>0.869671</td>\n",
       "      <td>0.877689</td>\n",
       "      <td>0.872577</td>\n",
       "      <td>0.009629</td>\n",
       "      <td>9</td>\n",
       "      <td>0.940604</td>\n",
       "      <td>0.941243</td>\n",
       "      <td>0.942455</td>\n",
       "      <td>0.940910</td>\n",
       "      <td>0.941545</td>\n",
       "      <td>0.940869</td>\n",
       "      <td>0.941105</td>\n",
       "      <td>0.940327</td>\n",
       "      <td>0.941361</td>\n",
       "      <td>0.939834</td>\n",
       "      <td>0.941187</td>\n",
       "      <td>0.941320</td>\n",
       "      <td>0.940608</td>\n",
       "      <td>0.943070</td>\n",
       "      <td>0.940516</td>\n",
       "      <td>0.941130</td>\n",
       "      <td>0.000782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.557180</td>\n",
       "      <td>0.344497</td>\n",
       "      <td>1.596003</td>\n",
       "      <td>0.090601</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>50</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 2)...</td>\n",
       "      <td>0.861779</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.879762</td>\n",
       "      <td>0.867299</td>\n",
       "      <td>0.863609</td>\n",
       "      <td>0.862674</td>\n",
       "      <td>0.868171</td>\n",
       "      <td>0.867700</td>\n",
       "      <td>0.858338</td>\n",
       "      <td>0.855115</td>\n",
       "      <td>0.857482</td>\n",
       "      <td>0.879467</td>\n",
       "      <td>0.881477</td>\n",
       "      <td>0.859554</td>\n",
       "      <td>0.870293</td>\n",
       "      <td>0.867421</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>10</td>\n",
       "      <td>0.883942</td>\n",
       "      <td>0.884540</td>\n",
       "      <td>0.884229</td>\n",
       "      <td>0.884013</td>\n",
       "      <td>0.884931</td>\n",
       "      <td>0.884372</td>\n",
       "      <td>0.884722</td>\n",
       "      <td>0.884121</td>\n",
       "      <td>0.883170</td>\n",
       "      <td>0.882690</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.882868</td>\n",
       "      <td>0.883828</td>\n",
       "      <td>0.885435</td>\n",
       "      <td>0.882594</td>\n",
       "      <td>0.884005</td>\n",
       "      <td>0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.327464</td>\n",
       "      <td>1.812771</td>\n",
       "      <td>1.093092</td>\n",
       "      <td>0.184077</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>50</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (2, 2)...</td>\n",
       "      <td>0.848268</td>\n",
       "      <td>0.868949</td>\n",
       "      <td>0.863905</td>\n",
       "      <td>0.854449</td>\n",
       "      <td>0.846604</td>\n",
       "      <td>0.855957</td>\n",
       "      <td>0.856974</td>\n",
       "      <td>0.852205</td>\n",
       "      <td>0.848739</td>\n",
       "      <td>0.844677</td>\n",
       "      <td>0.842723</td>\n",
       "      <td>0.871703</td>\n",
       "      <td>0.865407</td>\n",
       "      <td>0.844550</td>\n",
       "      <td>0.866825</td>\n",
       "      <td>0.855463</td>\n",
       "      <td>0.009424</td>\n",
       "      <td>11</td>\n",
       "      <td>0.878243</td>\n",
       "      <td>0.877923</td>\n",
       "      <td>0.876766</td>\n",
       "      <td>0.877531</td>\n",
       "      <td>0.878551</td>\n",
       "      <td>0.878263</td>\n",
       "      <td>0.877549</td>\n",
       "      <td>0.878456</td>\n",
       "      <td>0.876988</td>\n",
       "      <td>0.876445</td>\n",
       "      <td>0.879234</td>\n",
       "      <td>0.877341</td>\n",
       "      <td>0.876979</td>\n",
       "      <td>0.878552</td>\n",
       "      <td>0.877252</td>\n",
       "      <td>0.877738</td>\n",
       "      <td>0.000769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.809364</td>\n",
       "      <td>2.148055</td>\n",
       "      <td>1.302328</td>\n",
       "      <td>0.137180</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>50</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (2, 2)...</td>\n",
       "      <td>0.850657</td>\n",
       "      <td>0.865122</td>\n",
       "      <td>0.862884</td>\n",
       "      <td>0.850588</td>\n",
       "      <td>0.845385</td>\n",
       "      <td>0.852750</td>\n",
       "      <td>0.854449</td>\n",
       "      <td>0.857313</td>\n",
       "      <td>0.848921</td>\n",
       "      <td>0.843696</td>\n",
       "      <td>0.840306</td>\n",
       "      <td>0.869826</td>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.847981</td>\n",
       "      <td>0.865832</td>\n",
       "      <td>0.854258</td>\n",
       "      <td>0.008465</td>\n",
       "      <td>12</td>\n",
       "      <td>0.874900</td>\n",
       "      <td>0.875423</td>\n",
       "      <td>0.874857</td>\n",
       "      <td>0.875233</td>\n",
       "      <td>0.876912</td>\n",
       "      <td>0.876387</td>\n",
       "      <td>0.875498</td>\n",
       "      <td>0.876508</td>\n",
       "      <td>0.875715</td>\n",
       "      <td>0.874109</td>\n",
       "      <td>0.877200</td>\n",
       "      <td>0.875291</td>\n",
       "      <td>0.875339</td>\n",
       "      <td>0.875920</td>\n",
       "      <td>0.874486</td>\n",
       "      <td>0.875585</td>\n",
       "      <td>0.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.668724</td>\n",
       "      <td>0.318617</td>\n",
       "      <td>1.305245</td>\n",
       "      <td>0.074443</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>50</td>\n",
       "      <td>40000</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (2, 2)...</td>\n",
       "      <td>0.850149</td>\n",
       "      <td>0.863772</td>\n",
       "      <td>0.863556</td>\n",
       "      <td>0.849412</td>\n",
       "      <td>0.844209</td>\n",
       "      <td>0.855115</td>\n",
       "      <td>0.853601</td>\n",
       "      <td>0.855609</td>\n",
       "      <td>0.850809</td>\n",
       "      <td>0.841860</td>\n",
       "      <td>0.838443</td>\n",
       "      <td>0.870348</td>\n",
       "      <td>0.858323</td>\n",
       "      <td>0.846793</td>\n",
       "      <td>0.865832</td>\n",
       "      <td>0.853856</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>13</td>\n",
       "      <td>0.874038</td>\n",
       "      <td>0.874460</td>\n",
       "      <td>0.874043</td>\n",
       "      <td>0.874635</td>\n",
       "      <td>0.875953</td>\n",
       "      <td>0.875011</td>\n",
       "      <td>0.874650</td>\n",
       "      <td>0.875778</td>\n",
       "      <td>0.874635</td>\n",
       "      <td>0.873399</td>\n",
       "      <td>0.876145</td>\n",
       "      <td>0.874598</td>\n",
       "      <td>0.874222</td>\n",
       "      <td>0.875201</td>\n",
       "      <td>0.873677</td>\n",
       "      <td>0.874696</td>\n",
       "      <td>0.000778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.180918</td>\n",
       "      <td>0.569182</td>\n",
       "      <td>1.558733</td>\n",
       "      <td>0.061258</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>50</td>\n",
       "      <td>40000</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 2)...</td>\n",
       "      <td>0.850422</td>\n",
       "      <td>0.871549</td>\n",
       "      <td>0.867384</td>\n",
       "      <td>0.854427</td>\n",
       "      <td>0.854253</td>\n",
       "      <td>0.848596</td>\n",
       "      <td>0.857313</td>\n",
       "      <td>0.852871</td>\n",
       "      <td>0.846803</td>\n",
       "      <td>0.839477</td>\n",
       "      <td>0.840024</td>\n",
       "      <td>0.869142</td>\n",
       "      <td>0.858852</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>0.848338</td>\n",
       "      <td>0.853579</td>\n",
       "      <td>0.009584</td>\n",
       "      <td>14</td>\n",
       "      <td>0.868945</td>\n",
       "      <td>0.870080</td>\n",
       "      <td>0.869960</td>\n",
       "      <td>0.868859</td>\n",
       "      <td>0.870882</td>\n",
       "      <td>0.869472</td>\n",
       "      <td>0.869912</td>\n",
       "      <td>0.870331</td>\n",
       "      <td>0.869367</td>\n",
       "      <td>0.868218</td>\n",
       "      <td>0.871385</td>\n",
       "      <td>0.869729</td>\n",
       "      <td>0.870345</td>\n",
       "      <td>0.870939</td>\n",
       "      <td>0.870494</td>\n",
       "      <td>0.869928</td>\n",
       "      <td>0.000830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30.993453</td>\n",
       "      <td>0.468540</td>\n",
       "      <td>1.381607</td>\n",
       "      <td>0.058078</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.845969</td>\n",
       "      <td>0.866547</td>\n",
       "      <td>0.859206</td>\n",
       "      <td>0.846655</td>\n",
       "      <td>0.850088</td>\n",
       "      <td>0.846013</td>\n",
       "      <td>0.858164</td>\n",
       "      <td>0.842797</td>\n",
       "      <td>0.842676</td>\n",
       "      <td>0.833136</td>\n",
       "      <td>0.835113</td>\n",
       "      <td>0.854015</td>\n",
       "      <td>0.858164</td>\n",
       "      <td>0.836451</td>\n",
       "      <td>0.841471</td>\n",
       "      <td>0.847767</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>15</td>\n",
       "      <td>0.857619</td>\n",
       "      <td>0.858559</td>\n",
       "      <td>0.858155</td>\n",
       "      <td>0.858427</td>\n",
       "      <td>0.859537</td>\n",
       "      <td>0.857558</td>\n",
       "      <td>0.857938</td>\n",
       "      <td>0.858645</td>\n",
       "      <td>0.858109</td>\n",
       "      <td>0.857694</td>\n",
       "      <td>0.859245</td>\n",
       "      <td>0.858657</td>\n",
       "      <td>0.859183</td>\n",
       "      <td>0.859758</td>\n",
       "      <td>0.858097</td>\n",
       "      <td>0.858479</td>\n",
       "      <td>0.000673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29.903446</td>\n",
       "      <td>1.959275</td>\n",
       "      <td>1.168192</td>\n",
       "      <td>0.109816</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.830054</td>\n",
       "      <td>0.854810</td>\n",
       "      <td>0.847017</td>\n",
       "      <td>0.836152</td>\n",
       "      <td>0.835165</td>\n",
       "      <td>0.852246</td>\n",
       "      <td>0.846244</td>\n",
       "      <td>0.836710</td>\n",
       "      <td>0.846933</td>\n",
       "      <td>0.828341</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.860548</td>\n",
       "      <td>0.842290</td>\n",
       "      <td>0.833931</td>\n",
       "      <td>0.841855</td>\n",
       "      <td>0.841793</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>16</td>\n",
       "      <td>0.856001</td>\n",
       "      <td>0.857179</td>\n",
       "      <td>0.857215</td>\n",
       "      <td>0.857396</td>\n",
       "      <td>0.856938</td>\n",
       "      <td>0.855661</td>\n",
       "      <td>0.857299</td>\n",
       "      <td>0.856975</td>\n",
       "      <td>0.856542</td>\n",
       "      <td>0.855541</td>\n",
       "      <td>0.857372</td>\n",
       "      <td>0.855642</td>\n",
       "      <td>0.856409</td>\n",
       "      <td>0.857323</td>\n",
       "      <td>0.856686</td>\n",
       "      <td>0.856678</td>\n",
       "      <td>0.000655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38.629550</td>\n",
       "      <td>0.631100</td>\n",
       "      <td>1.698189</td>\n",
       "      <td>0.109831</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>400</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 2)...</td>\n",
       "      <td>0.811681</td>\n",
       "      <td>0.829532</td>\n",
       "      <td>0.828210</td>\n",
       "      <td>0.805069</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.805386</td>\n",
       "      <td>0.829034</td>\n",
       "      <td>0.806549</td>\n",
       "      <td>0.801944</td>\n",
       "      <td>0.807394</td>\n",
       "      <td>0.803121</td>\n",
       "      <td>0.828135</td>\n",
       "      <td>0.816106</td>\n",
       "      <td>0.796600</td>\n",
       "      <td>0.806610</td>\n",
       "      <td>0.812963</td>\n",
       "      <td>0.010839</td>\n",
       "      <td>17</td>\n",
       "      <td>0.816972</td>\n",
       "      <td>0.816997</td>\n",
       "      <td>0.817677</td>\n",
       "      <td>0.818534</td>\n",
       "      <td>0.817525</td>\n",
       "      <td>0.816952</td>\n",
       "      <td>0.815335</td>\n",
       "      <td>0.818495</td>\n",
       "      <td>0.817155</td>\n",
       "      <td>0.814770</td>\n",
       "      <td>0.818104</td>\n",
       "      <td>0.817420</td>\n",
       "      <td>0.818049</td>\n",
       "      <td>0.818855</td>\n",
       "      <td>0.816596</td>\n",
       "      <td>0.817296</td>\n",
       "      <td>0.001092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33.729636</td>\n",
       "      <td>1.122666</td>\n",
       "      <td>1.553618</td>\n",
       "      <td>0.130470</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 2)...</td>\n",
       "      <td>0.811681</td>\n",
       "      <td>0.829532</td>\n",
       "      <td>0.828210</td>\n",
       "      <td>0.805069</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.805386</td>\n",
       "      <td>0.829034</td>\n",
       "      <td>0.806549</td>\n",
       "      <td>0.801944</td>\n",
       "      <td>0.807394</td>\n",
       "      <td>0.803121</td>\n",
       "      <td>0.828135</td>\n",
       "      <td>0.816106</td>\n",
       "      <td>0.796600</td>\n",
       "      <td>0.806610</td>\n",
       "      <td>0.812963</td>\n",
       "      <td>0.010839</td>\n",
       "      <td>17</td>\n",
       "      <td>0.816972</td>\n",
       "      <td>0.816997</td>\n",
       "      <td>0.817677</td>\n",
       "      <td>0.818534</td>\n",
       "      <td>0.817525</td>\n",
       "      <td>0.816952</td>\n",
       "      <td>0.815335</td>\n",
       "      <td>0.818495</td>\n",
       "      <td>0.817155</td>\n",
       "      <td>0.814770</td>\n",
       "      <td>0.818104</td>\n",
       "      <td>0.817420</td>\n",
       "      <td>0.818049</td>\n",
       "      <td>0.818855</td>\n",
       "      <td>0.816596</td>\n",
       "      <td>0.817296</td>\n",
       "      <td>0.001092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27.199731</td>\n",
       "      <td>1.490145</td>\n",
       "      <td>1.039962</td>\n",
       "      <td>0.088406</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.747889</td>\n",
       "      <td>0.760597</td>\n",
       "      <td>0.774116</td>\n",
       "      <td>0.753500</td>\n",
       "      <td>0.758661</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>0.769772</td>\n",
       "      <td>0.761847</td>\n",
       "      <td>0.757869</td>\n",
       "      <td>0.737656</td>\n",
       "      <td>0.735383</td>\n",
       "      <td>0.764777</td>\n",
       "      <td>0.750754</td>\n",
       "      <td>0.735383</td>\n",
       "      <td>0.750306</td>\n",
       "      <td>0.753496</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>19</td>\n",
       "      <td>0.760726</td>\n",
       "      <td>0.762351</td>\n",
       "      <td>0.760912</td>\n",
       "      <td>0.762780</td>\n",
       "      <td>0.760733</td>\n",
       "      <td>0.762015</td>\n",
       "      <td>0.759861</td>\n",
       "      <td>0.760617</td>\n",
       "      <td>0.761144</td>\n",
       "      <td>0.759998</td>\n",
       "      <td>0.762416</td>\n",
       "      <td>0.760642</td>\n",
       "      <td>0.762583</td>\n",
       "      <td>0.762543</td>\n",
       "      <td>0.760027</td>\n",
       "      <td>0.761290</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26.731971</td>\n",
       "      <td>0.264725</td>\n",
       "      <td>1.082742</td>\n",
       "      <td>0.049006</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (2, 2)...</td>\n",
       "      <td>0.747889</td>\n",
       "      <td>0.759857</td>\n",
       "      <td>0.774116</td>\n",
       "      <td>0.753500</td>\n",
       "      <td>0.759390</td>\n",
       "      <td>0.744668</td>\n",
       "      <td>0.769321</td>\n",
       "      <td>0.761847</td>\n",
       "      <td>0.757869</td>\n",
       "      <td>0.737656</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.764777</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.735383</td>\n",
       "      <td>0.750306</td>\n",
       "      <td>0.753437</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>20</td>\n",
       "      <td>0.760497</td>\n",
       "      <td>0.762432</td>\n",
       "      <td>0.760761</td>\n",
       "      <td>0.762828</td>\n",
       "      <td>0.760487</td>\n",
       "      <td>0.761798</td>\n",
       "      <td>0.759377</td>\n",
       "      <td>0.760850</td>\n",
       "      <td>0.761124</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>0.762212</td>\n",
       "      <td>0.760491</td>\n",
       "      <td>0.762513</td>\n",
       "      <td>0.762477</td>\n",
       "      <td>0.759737</td>\n",
       "      <td>0.761168</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "11      34.044776      1.324582         1.451944        0.122455   \n",
       "0       27.765195      0.591089         1.263353        0.068790   \n",
       "5       33.520434      0.387535         1.636981        0.050569   \n",
       "17      27.759025      0.492543         1.254746        0.049892   \n",
       "1       37.109603      3.415638         1.886761        0.184386   \n",
       "15      33.323997      0.202405         1.633830        0.038543   \n",
       "14      34.707736      0.279987         1.727475        0.057689   \n",
       "13      35.665286      1.673867         1.609806        0.091467   \n",
       "7       38.199033      3.940846         1.809658        0.134746   \n",
       "4       33.557180      0.344497         1.596003        0.090601   \n",
       "19      26.327464      1.812771         1.093092        0.184077   \n",
       "2       30.809364      2.148055         1.302328        0.137180   \n",
       "9       31.668724      0.318617         1.305245        0.074443   \n",
       "3       33.180918      0.569182         1.558733        0.061258   \n",
       "18      30.993453      0.468540         1.381607        0.058078   \n",
       "10      29.903446      1.959275         1.168192        0.109816   \n",
       "8       38.629550      0.631100         1.698189        0.109831   \n",
       "6       33.729636      1.122666         1.553618        0.130470   \n",
       "12      27.199731      1.490145         1.039962        0.088406   \n",
       "16      26.731971      0.264725         1.082742        0.049006   \n",
       "\n",
       "   param_vec__stem param_vec__ngram_range param_vec__min_df param_vec__max_df  \\\n",
       "11           False                 (2, 2)                 1                 1   \n",
       "0             True                 (2, 2)                 1                 1   \n",
       "5            False                 (1, 2)                 1              4000   \n",
       "17            True                 (2, 2)                 3                 1   \n",
       "1            False                 (1, 2)                 1             40000   \n",
       "15            True                 (1, 2)                 3                 1   \n",
       "14            True                 (1, 2)                 1             40000   \n",
       "13           False                 (1, 2)                 3                 1   \n",
       "7             True                 (1, 2)                 3             40000   \n",
       "4             True                 (1, 2)                50              4000   \n",
       "19            True                 (2, 2)                50              4000   \n",
       "2             True                 (2, 2)                50             40000   \n",
       "9             True                 (2, 2)                50             40000   \n",
       "3             True                 (1, 2)                50             40000   \n",
       "18           False                 (1, 2)               100             40000   \n",
       "10           False                 (2, 2)               100              4000   \n",
       "8             True                 (1, 2)               400             40000   \n",
       "6             True                 (1, 2)               400                 1   \n",
       "12           False                 (2, 2)               400                 1   \n",
       "16            True                 (2, 2)               400                 1   \n",
       "\n",
       "   param_clf__alpha                                             params  \\\n",
       "11                2  {'vec__stem': False, 'vec__ngram_range': (2, 2...   \n",
       "0                 2  {'vec__stem': True, 'vec__ngram_range': (2, 2)...   \n",
       "5                 3  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "17              0.1  {'vec__stem': True, 'vec__ngram_range': (2, 2)...   \n",
       "1               0.5  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "15              0.5  {'vec__stem': True, 'vec__ngram_range': (1, 2)...   \n",
       "14                3  {'vec__stem': True, 'vec__ngram_range': (1, 2)...   \n",
       "13                2  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "7                 2  {'vec__stem': True, 'vec__ngram_range': (1, 2)...   \n",
       "4               0.5  {'vec__stem': True, 'vec__ngram_range': (1, 2)...   \n",
       "19                2  {'vec__stem': True, 'vec__ngram_range': (2, 2)...   \n",
       "2               0.5  {'vec__stem': True, 'vec__ngram_range': (2, 2)...   \n",
       "9                 2  {'vec__stem': True, 'vec__ngram_range': (2, 2)...   \n",
       "3                 3  {'vec__stem': True, 'vec__ngram_range': (1, 2)...   \n",
       "18              0.5  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "10              0.1  {'vec__stem': False, 'vec__ngram_range': (2, 2...   \n",
       "8               0.5  {'vec__stem': True, 'vec__ngram_range': (1, 2)...   \n",
       "6               0.5  {'vec__stem': True, 'vec__ngram_range': (1, 2)...   \n",
       "12              0.5  {'vec__stem': False, 'vec__ngram_range': (2, 2...   \n",
       "16                3  {'vec__stem': True, 'vec__ngram_range': (2, 2)...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "11           0.879511           0.900480           0.899094   \n",
       "0            0.878825           0.900480           0.899215   \n",
       "5            0.877724           0.897619           0.898082   \n",
       "17           0.874543           0.896305           0.900417   \n",
       "1            0.875000           0.893617           0.894833   \n",
       "15           0.868179           0.887145           0.885662   \n",
       "14           0.867440           0.884058           0.888087   \n",
       "13           0.864167           0.885385           0.881995   \n",
       "7            0.863469           0.885385           0.882675   \n",
       "4            0.861779           0.878571           0.879762   \n",
       "19           0.848268           0.868949           0.863905   \n",
       "2            0.850657           0.865122           0.862884   \n",
       "9            0.850149           0.863772           0.863556   \n",
       "3            0.850422           0.871549           0.867384   \n",
       "18           0.845969           0.866547           0.859206   \n",
       "10           0.830054           0.854810           0.847017   \n",
       "8            0.811681           0.829532           0.828210   \n",
       "6            0.811681           0.829532           0.828210   \n",
       "12           0.747889           0.760597           0.774116   \n",
       "16           0.747889           0.759857           0.774116   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "11           0.883273           0.889831           0.888485   \n",
       "0            0.883273           0.889831           0.887136   \n",
       "5            0.883582           0.886499           0.882424   \n",
       "17           0.873425           0.880854           0.883524   \n",
       "1            0.879854           0.885662           0.877839   \n",
       "15           0.876053           0.878752           0.877301   \n",
       "14           0.874850           0.877404           0.875610   \n",
       "13           0.873341           0.873716           0.874539   \n",
       "7            0.873341           0.873716           0.874539   \n",
       "4            0.867299           0.863609           0.862674   \n",
       "19           0.854449           0.846604           0.855957   \n",
       "2            0.850588           0.845385           0.852750   \n",
       "9            0.849412           0.844209           0.855115   \n",
       "3            0.854427           0.854253           0.848596   \n",
       "18           0.846655           0.850088           0.846013   \n",
       "10           0.836152           0.835165           0.852246   \n",
       "8            0.805069           0.819048           0.805386   \n",
       "6            0.805069           0.819048           0.805386   \n",
       "12           0.753500           0.758661           0.743902   \n",
       "16           0.753500           0.759390           0.744668   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "11           0.894231           0.893513           0.874156   \n",
       "0            0.894231           0.892835           0.874156   \n",
       "5            0.894358           0.892683           0.872881   \n",
       "17           0.881824           0.889024           0.878935   \n",
       "1            0.888082           0.885609           0.868389   \n",
       "15           0.885938           0.881377           0.869193   \n",
       "14           0.887688           0.881418           0.861670   \n",
       "13           0.885784           0.877601           0.861709   \n",
       "7            0.885784           0.877601           0.861709   \n",
       "4            0.868171           0.867700           0.858338   \n",
       "19           0.856974           0.852205           0.848739   \n",
       "2            0.854449           0.857313           0.848921   \n",
       "9            0.853601           0.855609           0.850809   \n",
       "3            0.857313           0.852871           0.846803   \n",
       "18           0.858164           0.842797           0.842676   \n",
       "10           0.846244           0.836710           0.846933   \n",
       "8            0.829034           0.806549           0.801944   \n",
       "6            0.829034           0.806549           0.801944   \n",
       "12           0.769772           0.761847           0.757869   \n",
       "16           0.769321           0.761847           0.757869   \n",
       "\n",
       "    split9_test_score  split10_test_score  split11_test_score  \\\n",
       "11           0.879569            0.871299            0.889851   \n",
       "0            0.879569            0.871299            0.889851   \n",
       "5            0.870968            0.870813            0.883436   \n",
       "17           0.873139            0.864702            0.889161   \n",
       "1            0.863388            0.862674            0.877085   \n",
       "15           0.859036            0.861631            0.875849   \n",
       "14           0.861244            0.858859            0.877236   \n",
       "13           0.856451            0.855407            0.868159   \n",
       "7            0.856451            0.855407            0.868159   \n",
       "4            0.855115            0.857482            0.879467   \n",
       "19           0.844677            0.842723            0.871703   \n",
       "2            0.843696            0.840306            0.869826   \n",
       "9            0.841860            0.838443            0.870348   \n",
       "3            0.839477            0.840024            0.869142   \n",
       "18           0.833136            0.835113            0.854015   \n",
       "10           0.828341            0.834600            0.860548   \n",
       "8            0.807394            0.803121            0.828135   \n",
       "6            0.807394            0.803121            0.828135   \n",
       "12           0.737656            0.735383            0.764777   \n",
       "16           0.737656            0.734940            0.764777   \n",
       "\n",
       "    split12_test_score  split13_test_score  split14_test_score  \\\n",
       "11            0.894417            0.889831            0.885487   \n",
       "0             0.894417            0.889831            0.885487   \n",
       "5             0.893848            0.880866            0.890909   \n",
       "17            0.893180            0.876729            0.884428   \n",
       "1             0.891743            0.876144            0.877538   \n",
       "15            0.887668            0.871420            0.878287   \n",
       "14            0.886045            0.870247            0.876679   \n",
       "13            0.883037            0.869671            0.877689   \n",
       "7             0.883037            0.869671            0.877689   \n",
       "4             0.881477            0.859554            0.870293   \n",
       "19            0.865407            0.844550            0.866825   \n",
       "2             0.858156            0.847981            0.865832   \n",
       "9             0.858323            0.846793            0.865832   \n",
       "3             0.858852            0.844203            0.848338   \n",
       "18            0.858164            0.836451            0.841471   \n",
       "10            0.842290            0.833931            0.841855   \n",
       "8             0.816106            0.796600            0.806610   \n",
       "6             0.816106            0.796600            0.806610   \n",
       "12            0.750754            0.735383            0.750306   \n",
       "16            0.750000            0.735383            0.750306   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "11         0.887536        0.008322                1            0.994407   \n",
       "0          0.887364        0.008344                2            0.994407   \n",
       "5          0.885114        0.009012                3            0.979375   \n",
       "17         0.882680        0.009368                4            0.983544   \n",
       "1          0.879833        0.009804                5            0.995441   \n",
       "15         0.876234        0.008632                6            0.956390   \n",
       "14         0.875237        0.009301                7            0.973182   \n",
       "13         0.872578        0.009540                8            0.940639   \n",
       "7          0.872577        0.009629                9            0.940604   \n",
       "4          0.867421        0.008531               10            0.883942   \n",
       "19         0.855463        0.009424               11            0.878243   \n",
       "2          0.854258        0.008465               12            0.874900   \n",
       "9          0.853856        0.008943               13            0.874038   \n",
       "3          0.853579        0.009584               14            0.868945   \n",
       "18         0.847767        0.009467               15            0.857619   \n",
       "10         0.841793        0.009085               16            0.856001   \n",
       "8          0.812963        0.010839               17            0.816972   \n",
       "6          0.812963        0.010839               17            0.816972   \n",
       "12         0.753496        0.011637               19            0.760726   \n",
       "16         0.753437        0.011610               20            0.760497   \n",
       "\n",
       "    split1_train_score  split2_train_score  split3_train_score  \\\n",
       "11            0.994103            0.994192            0.993845   \n",
       "0             0.994103            0.994192            0.993845   \n",
       "5             0.979666            0.979627            0.979459   \n",
       "17            0.983585            0.983588            0.983465   \n",
       "1             0.995743            0.995527            0.995570   \n",
       "15            0.957618            0.957577            0.957090   \n",
       "14            0.972731            0.973700            0.972729   \n",
       "13            0.941156            0.942409            0.940951   \n",
       "7             0.941243            0.942455            0.940910   \n",
       "4             0.884540            0.884229            0.884013   \n",
       "19            0.877923            0.876766            0.877531   \n",
       "2             0.875423            0.874857            0.875233   \n",
       "9             0.874460            0.874043            0.874635   \n",
       "3             0.870080            0.869960            0.868859   \n",
       "18            0.858559            0.858155            0.858427   \n",
       "10            0.857179            0.857215            0.857396   \n",
       "8             0.816997            0.817677            0.818534   \n",
       "6             0.816997            0.817677            0.818534   \n",
       "12            0.762351            0.760912            0.762780   \n",
       "16            0.762432            0.760761            0.762828   \n",
       "\n",
       "    split4_train_score  split5_train_score  split6_train_score  \\\n",
       "11            0.994320            0.993931            0.993497   \n",
       "0             0.994277            0.993888            0.993540   \n",
       "5             0.979678            0.979325            0.979219   \n",
       "17            0.983501            0.983410            0.982834   \n",
       "1             0.995571            0.995311            0.995440   \n",
       "15            0.957008            0.956446            0.956688   \n",
       "14            0.973046            0.972640            0.972625   \n",
       "13            0.941713            0.940915            0.941279   \n",
       "7             0.941545            0.940869            0.941105   \n",
       "4             0.884931            0.884372            0.884722   \n",
       "19            0.878551            0.878263            0.877549   \n",
       "2             0.876912            0.876387            0.875498   \n",
       "9             0.875953            0.875011            0.874650   \n",
       "3             0.870882            0.869472            0.869912   \n",
       "18            0.859537            0.857558            0.857938   \n",
       "10            0.856938            0.855661            0.857299   \n",
       "8             0.817525            0.816952            0.815335   \n",
       "6             0.817525            0.816952            0.815335   \n",
       "12            0.760733            0.762015            0.759861   \n",
       "16            0.760487            0.761798            0.759377   \n",
       "\n",
       "    split7_train_score  split8_train_score  split9_train_score  \\\n",
       "11            0.994017            0.993844            0.993931   \n",
       "0             0.994060            0.993888            0.993931   \n",
       "5             0.979449            0.979458            0.979235   \n",
       "17            0.983195            0.983402            0.983365   \n",
       "1             0.995527            0.995441            0.995225   \n",
       "15            0.956729            0.957370            0.955658   \n",
       "14            0.972555            0.973480            0.973041   \n",
       "13            0.940281            0.941356            0.939967   \n",
       "7             0.940327            0.941361            0.939834   \n",
       "4             0.884121            0.883170            0.882690   \n",
       "19            0.878456            0.876988            0.876445   \n",
       "2             0.876508            0.875715            0.874109   \n",
       "9             0.875778            0.874635            0.873399   \n",
       "3             0.870331            0.869367            0.868218   \n",
       "18            0.858645            0.858109            0.857694   \n",
       "10            0.856975            0.856542            0.855541   \n",
       "8             0.818495            0.817155            0.814770   \n",
       "6             0.818495            0.817155            0.814770   \n",
       "12            0.760617            0.761144            0.759998   \n",
       "16            0.760850            0.761124            0.759933   \n",
       "\n",
       "    split10_train_score  split11_train_score  split12_train_score  \\\n",
       "11             0.993844             0.993628             0.993585   \n",
       "0              0.993931             0.993628             0.993672   \n",
       "5              0.979654             0.979410             0.979263   \n",
       "17             0.983182             0.982577             0.982639   \n",
       "1              0.995829             0.995484             0.995440   \n",
       "15             0.957842             0.956552             0.956729   \n",
       "14             0.972818             0.972987             0.972893   \n",
       "13             0.941141             0.941320             0.940695   \n",
       "7              0.941187             0.941320             0.940608   \n",
       "4              0.884615             0.882868             0.883828   \n",
       "19             0.879234             0.877341             0.876979   \n",
       "2              0.877200             0.875291             0.875339   \n",
       "9              0.876145             0.874598             0.874222   \n",
       "3              0.871385             0.869729             0.870345   \n",
       "18             0.859245             0.858657             0.859183   \n",
       "10             0.857372             0.855642             0.856409   \n",
       "8              0.818104             0.817420             0.818049   \n",
       "6              0.818104             0.817420             0.818049   \n",
       "12             0.762416             0.760642             0.762583   \n",
       "16             0.762212             0.760491             0.762513   \n",
       "\n",
       "    split13_train_score  split14_train_score  mean_train_score  \\\n",
       "11             0.994105             0.993973          0.993948   \n",
       "0              0.994148             0.994017          0.993968   \n",
       "5              0.979719             0.978902          0.979429   \n",
       "17             0.983153             0.983325          0.983251   \n",
       "1              0.995528             0.995398          0.995498   \n",
       "15             0.957932             0.956352          0.956932   \n",
       "14             0.973219             0.972088          0.972916   \n",
       "13             0.943111             0.940475          0.941161   \n",
       "7              0.943070             0.940516          0.941130   \n",
       "4              0.885435             0.882594          0.884005   \n",
       "19             0.878552             0.877252          0.877738   \n",
       "2              0.875920             0.874486          0.875585   \n",
       "9              0.875201             0.873677          0.874696   \n",
       "3              0.870939             0.870494          0.869928   \n",
       "18             0.859758             0.858097          0.858479   \n",
       "10             0.857323             0.856686          0.856678   \n",
       "8              0.818855             0.816596          0.817296   \n",
       "6              0.818855             0.816596          0.817296   \n",
       "12             0.762543             0.760027          0.761290   \n",
       "16             0.762477             0.759737          0.761168   \n",
       "\n",
       "    std_train_score  \n",
       "11         0.000249  \n",
       "0          0.000233  \n",
       "5          0.000215  \n",
       "17         0.000317  \n",
       "1          0.000145  \n",
       "15         0.000617  \n",
       "14         0.000382  \n",
       "13         0.000775  \n",
       "7          0.000782  \n",
       "4          0.000817  \n",
       "19         0.000769  \n",
       "2          0.000844  \n",
       "9          0.000778  \n",
       "3          0.000830  \n",
       "18         0.000673  \n",
       "10         0.000655  \n",
       "8          0.001092  \n",
       "6          0.001092  \n",
       "12         0.001012  \n",
       "16         0.001089  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rs_mnv_bow.cv_results_).sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering, binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395.69318199157715, {'clf__smooth': 1}, 0.8506335664239875)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_bnv = {\n",
    "    'clf__smooth': [.01, .1, 1, 2]\n",
    "}\n",
    "\n",
    "bnv = vect = LemmaCountVectorizer(strip_accents='unicode', stop_words=None, binary=True, \n",
    "                                stem=True, ngram_range=(1, 2), min_df=250, max_df=4000)\n",
    "X_train_bnv = bnv.fit_transform(X_train)\n",
    "\n",
    "pipeline_bnv = Pipeline([\n",
    "    ('clf', BernoulliNaiveBayes())\n",
    "])\n",
    "\n",
    "gs_bnv = GridSearchCV(pipeline_bnv, params_bnv, \n",
    "                                   cv=20, scoring=score, verbose=0, return_train_score=True)\n",
    "start = time.time()\n",
    "gs_bnv.fit(X_train_bnv.toarray(), y)\n",
    "\n",
    "# scores = cross_val_score(bnv_clf, X_train_vect.toarray(), y, cv=20, scoring='f1', n_jobs=-1)\n",
    "# time.time() - start, scores, scores.mean(), scores.std()\n",
    "time.time() - start, gs_bnv.best_params_, gs_bnv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__smooth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>split15_test_score</th>\n",
       "      <th>split16_test_score</th>\n",
       "      <th>split17_test_score</th>\n",
       "      <th>split18_test_score</th>\n",
       "      <th>split19_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>split10_train_score</th>\n",
       "      <th>split11_train_score</th>\n",
       "      <th>split12_train_score</th>\n",
       "      <th>split13_train_score</th>\n",
       "      <th>split14_train_score</th>\n",
       "      <th>split15_train_score</th>\n",
       "      <th>split16_train_score</th>\n",
       "      <th>split17_train_score</th>\n",
       "      <th>split18_train_score</th>\n",
       "      <th>split19_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.251473</td>\n",
       "      <td>0.032753</td>\n",
       "      <td>0.040360</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>1</td>\n",
       "      <td>{'clf__smooth': 1}</td>\n",
       "      <td>0.849188</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.856919</td>\n",
       "      <td>0.872841</td>\n",
       "      <td>0.858034</td>\n",
       "      <td>0.856924</td>\n",
       "      <td>0.853563</td>\n",
       "      <td>0.847189</td>\n",
       "      <td>0.858238</td>\n",
       "      <td>0.850158</td>\n",
       "      <td>0.843505</td>\n",
       "      <td>0.843243</td>\n",
       "      <td>0.836814</td>\n",
       "      <td>0.838110</td>\n",
       "      <td>0.847962</td>\n",
       "      <td>0.850898</td>\n",
       "      <td>0.853375</td>\n",
       "      <td>0.855807</td>\n",
       "      <td>0.836335</td>\n",
       "      <td>0.850234</td>\n",
       "      <td>0.850634</td>\n",
       "      <td>0.008409</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857331</td>\n",
       "      <td>0.858079</td>\n",
       "      <td>0.857284</td>\n",
       "      <td>0.857671</td>\n",
       "      <td>0.857283</td>\n",
       "      <td>0.857342</td>\n",
       "      <td>0.858186</td>\n",
       "      <td>0.857330</td>\n",
       "      <td>0.857506</td>\n",
       "      <td>0.857049</td>\n",
       "      <td>0.857178</td>\n",
       "      <td>0.858856</td>\n",
       "      <td>0.857978</td>\n",
       "      <td>0.858714</td>\n",
       "      <td>0.857776</td>\n",
       "      <td>0.858034</td>\n",
       "      <td>0.857753</td>\n",
       "      <td>0.858067</td>\n",
       "      <td>0.859522</td>\n",
       "      <td>0.858151</td>\n",
       "      <td>0.857855</td>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.385002</td>\n",
       "      <td>0.130236</td>\n",
       "      <td>0.044170</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'clf__smooth': 0.01}</td>\n",
       "      <td>0.849188</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.856919</td>\n",
       "      <td>0.872841</td>\n",
       "      <td>0.858704</td>\n",
       "      <td>0.856924</td>\n",
       "      <td>0.852895</td>\n",
       "      <td>0.847189</td>\n",
       "      <td>0.858454</td>\n",
       "      <td>0.850158</td>\n",
       "      <td>0.843505</td>\n",
       "      <td>0.843243</td>\n",
       "      <td>0.835913</td>\n",
       "      <td>0.838110</td>\n",
       "      <td>0.847962</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.853375</td>\n",
       "      <td>0.855807</td>\n",
       "      <td>0.836335</td>\n",
       "      <td>0.850234</td>\n",
       "      <td>0.850555</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>2</td>\n",
       "      <td>0.857413</td>\n",
       "      <td>0.858138</td>\n",
       "      <td>0.857553</td>\n",
       "      <td>0.857682</td>\n",
       "      <td>0.857354</td>\n",
       "      <td>0.857460</td>\n",
       "      <td>0.858327</td>\n",
       "      <td>0.857612</td>\n",
       "      <td>0.857647</td>\n",
       "      <td>0.857026</td>\n",
       "      <td>0.857307</td>\n",
       "      <td>0.859044</td>\n",
       "      <td>0.858061</td>\n",
       "      <td>0.858691</td>\n",
       "      <td>0.857753</td>\n",
       "      <td>0.858011</td>\n",
       "      <td>0.857858</td>\n",
       "      <td>0.858254</td>\n",
       "      <td>0.859394</td>\n",
       "      <td>0.858233</td>\n",
       "      <td>0.857941</td>\n",
       "      <td>0.000585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.338773</td>\n",
       "      <td>0.103808</td>\n",
       "      <td>0.041678</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'clf__smooth': 0.1}</td>\n",
       "      <td>0.849188</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.856919</td>\n",
       "      <td>0.872841</td>\n",
       "      <td>0.858704</td>\n",
       "      <td>0.856924</td>\n",
       "      <td>0.852895</td>\n",
       "      <td>0.847189</td>\n",
       "      <td>0.858454</td>\n",
       "      <td>0.850158</td>\n",
       "      <td>0.843505</td>\n",
       "      <td>0.843243</td>\n",
       "      <td>0.835913</td>\n",
       "      <td>0.838110</td>\n",
       "      <td>0.847962</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.853375</td>\n",
       "      <td>0.855807</td>\n",
       "      <td>0.836335</td>\n",
       "      <td>0.850234</td>\n",
       "      <td>0.850555</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>2</td>\n",
       "      <td>0.857448</td>\n",
       "      <td>0.858138</td>\n",
       "      <td>0.857553</td>\n",
       "      <td>0.857729</td>\n",
       "      <td>0.857354</td>\n",
       "      <td>0.857460</td>\n",
       "      <td>0.858327</td>\n",
       "      <td>0.857541</td>\n",
       "      <td>0.857647</td>\n",
       "      <td>0.857061</td>\n",
       "      <td>0.857272</td>\n",
       "      <td>0.859044</td>\n",
       "      <td>0.858072</td>\n",
       "      <td>0.858726</td>\n",
       "      <td>0.857800</td>\n",
       "      <td>0.858011</td>\n",
       "      <td>0.857823</td>\n",
       "      <td>0.858219</td>\n",
       "      <td>0.859394</td>\n",
       "      <td>0.858198</td>\n",
       "      <td>0.857941</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.230389</td>\n",
       "      <td>0.022408</td>\n",
       "      <td>0.039420</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>2</td>\n",
       "      <td>{'clf__smooth': 2}</td>\n",
       "      <td>0.848532</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.856919</td>\n",
       "      <td>0.872157</td>\n",
       "      <td>0.858034</td>\n",
       "      <td>0.856269</td>\n",
       "      <td>0.853792</td>\n",
       "      <td>0.847189</td>\n",
       "      <td>0.858238</td>\n",
       "      <td>0.849250</td>\n",
       "      <td>0.842846</td>\n",
       "      <td>0.843243</td>\n",
       "      <td>0.836167</td>\n",
       "      <td>0.837461</td>\n",
       "      <td>0.847962</td>\n",
       "      <td>0.850234</td>\n",
       "      <td>0.853375</td>\n",
       "      <td>0.855807</td>\n",
       "      <td>0.836335</td>\n",
       "      <td>0.850234</td>\n",
       "      <td>0.850369</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>4</td>\n",
       "      <td>0.857248</td>\n",
       "      <td>0.858184</td>\n",
       "      <td>0.857213</td>\n",
       "      <td>0.857635</td>\n",
       "      <td>0.857037</td>\n",
       "      <td>0.857319</td>\n",
       "      <td>0.858010</td>\n",
       "      <td>0.857272</td>\n",
       "      <td>0.857448</td>\n",
       "      <td>0.856991</td>\n",
       "      <td>0.857026</td>\n",
       "      <td>0.858950</td>\n",
       "      <td>0.858025</td>\n",
       "      <td>0.858819</td>\n",
       "      <td>0.857682</td>\n",
       "      <td>0.857999</td>\n",
       "      <td>0.857682</td>\n",
       "      <td>0.857938</td>\n",
       "      <td>0.859499</td>\n",
       "      <td>0.858198</td>\n",
       "      <td>0.857809</td>\n",
       "      <td>0.000666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2       3.251473      0.032753         0.040360        0.001908   \n",
       "0       3.385002      0.130236         0.044170        0.009747   \n",
       "1       3.338773      0.103808         0.041678        0.003520   \n",
       "3       3.230389      0.022408         0.039420        0.001757   \n",
       "\n",
       "  param_clf__smooth                 params  split0_test_score  \\\n",
       "2                 1     {'clf__smooth': 1}           0.849188   \n",
       "0              0.01  {'clf__smooth': 0.01}           0.849188   \n",
       "1               0.1   {'clf__smooth': 0.1}           0.849188   \n",
       "3                 2     {'clf__smooth': 2}           0.848532   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "2           0.853333           0.856919           0.872841           0.858034   \n",
       "0           0.853333           0.856919           0.872841           0.858704   \n",
       "1           0.853333           0.856919           0.872841           0.858704   \n",
       "3           0.853333           0.856919           0.872157           0.858034   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "2           0.856924           0.853563           0.847189           0.858238   \n",
       "0           0.856924           0.852895           0.847189           0.858454   \n",
       "1           0.856924           0.852895           0.847189           0.858454   \n",
       "3           0.856269           0.853792           0.847189           0.858238   \n",
       "\n",
       "   split9_test_score  split10_test_score  split11_test_score  \\\n",
       "2           0.850158            0.843505            0.843243   \n",
       "0           0.850158            0.843505            0.843243   \n",
       "1           0.850158            0.843505            0.843243   \n",
       "3           0.849250            0.842846            0.843243   \n",
       "\n",
       "   split12_test_score  split13_test_score  split14_test_score  \\\n",
       "2            0.836814            0.838110            0.847962   \n",
       "0            0.835913            0.838110            0.847962   \n",
       "1            0.835913            0.838110            0.847962   \n",
       "3            0.836167            0.837461            0.847962   \n",
       "\n",
       "   split15_test_score  split16_test_score  split17_test_score  \\\n",
       "2            0.850898            0.853375            0.855807   \n",
       "0            0.850000            0.853375            0.855807   \n",
       "1            0.850000            0.853375            0.855807   \n",
       "3            0.850234            0.853375            0.855807   \n",
       "\n",
       "   split18_test_score  split19_test_score  mean_test_score  std_test_score  \\\n",
       "2            0.836335            0.850234         0.850634        0.008409   \n",
       "0            0.836335            0.850234         0.850555        0.008516   \n",
       "1            0.836335            0.850234         0.850555        0.008516   \n",
       "3            0.836335            0.850234         0.850369        0.008442   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "2                1            0.857331            0.858079   \n",
       "0                2            0.857413            0.858138   \n",
       "1                2            0.857448            0.858138   \n",
       "3                4            0.857248            0.858184   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "2            0.857284            0.857671            0.857283   \n",
       "0            0.857553            0.857682            0.857354   \n",
       "1            0.857553            0.857729            0.857354   \n",
       "3            0.857213            0.857635            0.857037   \n",
       "\n",
       "   split5_train_score  split6_train_score  split7_train_score  \\\n",
       "2            0.857342            0.858186            0.857330   \n",
       "0            0.857460            0.858327            0.857612   \n",
       "1            0.857460            0.858327            0.857541   \n",
       "3            0.857319            0.858010            0.857272   \n",
       "\n",
       "   split8_train_score  split9_train_score  split10_train_score  \\\n",
       "2            0.857506            0.857049             0.857178   \n",
       "0            0.857647            0.857026             0.857307   \n",
       "1            0.857647            0.857061             0.857272   \n",
       "3            0.857448            0.856991             0.857026   \n",
       "\n",
       "   split11_train_score  split12_train_score  split13_train_score  \\\n",
       "2             0.858856             0.857978             0.858714   \n",
       "0             0.859044             0.858061             0.858691   \n",
       "1             0.859044             0.858072             0.858726   \n",
       "3             0.858950             0.858025             0.858819   \n",
       "\n",
       "   split14_train_score  split15_train_score  split16_train_score  \\\n",
       "2             0.857776             0.858034             0.857753   \n",
       "0             0.857753             0.858011             0.857858   \n",
       "1             0.857800             0.858011             0.857823   \n",
       "3             0.857682             0.857999             0.857682   \n",
       "\n",
       "   split17_train_score  split18_train_score  split19_train_score  \\\n",
       "2             0.858067             0.859522             0.858151   \n",
       "0             0.858254             0.859394             0.858233   \n",
       "1             0.858219             0.859394             0.858198   \n",
       "3             0.857938             0.859499             0.858198   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "2          0.857855         0.000617  \n",
       "0          0.857941         0.000585  \n",
       "1          0.857941         0.000584  \n",
       "3          0.857809         0.000666  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs_bnv.cv_results_).sort_values(by=['mean_test_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2105709,
     "status": "ok",
     "timestamp": 1549504031186,
     "user": {
      "displayName": "FRANCISCO XAVIER SUMBA TORAL",
      "photoUrl": "",
      "userId": "11128736706802637809"
     },
     "user_tz": 300
    },
    "id": "FyIB_vuE3ZtA",
    "outputId": "e5e5a82e-7192-45ab-bbda-d548a03689b0"
   },
   "outputs": [],
   "source": [
    "parameters_svm = {\n",
    "    'vec__min_df': [3, 50, 100, 400],\n",
    "    'vec__max_df': [4000, 40000, 1.0],\n",
    "    'vec__stem': [True, False],\n",
    "    'vec__binary': [True, False],\n",
    "    'clf__degree': [2, 3, 4], \n",
    "    'clf__C': [.5, 1.0, 2.5, 3], \n",
    "}\n",
    "\n",
    "pipeline_svm = Pipeline([\n",
    "    ('vec', LemmaCountVectorizer(strip_accents='unicode', stop_words=None, ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm='l2', smooth_idf=True,)),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "                  \n",
    "rs_svm = RandomizedSearchCV(pipeline_svm, parameters_svm, \n",
    "                                   cv=12, scoring=score, n_jobs=-1, verbose=0, random_state=62, n_iter=20, \n",
    "                                         return_train_score=True)\n",
    "start = time.time()\n",
    "rs_svm.fit(X_train, y)\n",
    "time.time() - start, rs_svm.best_params_, rs_svm.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_vec__stem</th>\n",
       "      <th>param_vec__ngram_range</th>\n",
       "      <th>param_vec__min_df</th>\n",
       "      <th>param_vec__max_df</th>\n",
       "      <th>param_tfidf__smooth_idf</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>param_clf__fit_intercept</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>split10_train_score</th>\n",
       "      <th>split11_train_score</th>\n",
       "      <th>split12_train_score</th>\n",
       "      <th>split13_train_score</th>\n",
       "      <th>split14_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>34.898155</td>\n",
       "      <td>2.134065</td>\n",
       "      <td>1.328138</td>\n",
       "      <td>0.145529</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.902728</td>\n",
       "      <td>0.897935</td>\n",
       "      <td>0.895906</td>\n",
       "      <td>0.895047</td>\n",
       "      <td>0.890451</td>\n",
       "      <td>0.900412</td>\n",
       "      <td>0.900177</td>\n",
       "      <td>0.893848</td>\n",
       "      <td>0.881110</td>\n",
       "      <td>0.882318</td>\n",
       "      <td>0.880518</td>\n",
       "      <td>0.907341</td>\n",
       "      <td>0.910272</td>\n",
       "      <td>0.897375</td>\n",
       "      <td>0.913507</td>\n",
       "      <td>0.896596</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>4</td>\n",
       "      <td>0.995325</td>\n",
       "      <td>0.994940</td>\n",
       "      <td>0.994856</td>\n",
       "      <td>0.995027</td>\n",
       "      <td>0.994941</td>\n",
       "      <td>0.994425</td>\n",
       "      <td>0.995153</td>\n",
       "      <td>0.994940</td>\n",
       "      <td>0.995198</td>\n",
       "      <td>0.995370</td>\n",
       "      <td>0.995155</td>\n",
       "      <td>0.994855</td>\n",
       "      <td>0.994899</td>\n",
       "      <td>0.995112</td>\n",
       "      <td>0.994897</td>\n",
       "      <td>0.995006</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.219318</td>\n",
       "      <td>1.924093</td>\n",
       "      <td>1.626187</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.908873</td>\n",
       "      <td>0.907484</td>\n",
       "      <td>0.905350</td>\n",
       "      <td>0.906084</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.919144</td>\n",
       "      <td>0.906526</td>\n",
       "      <td>0.903571</td>\n",
       "      <td>0.903498</td>\n",
       "      <td>0.892836</td>\n",
       "      <td>0.890579</td>\n",
       "      <td>0.906344</td>\n",
       "      <td>0.916963</td>\n",
       "      <td>0.900955</td>\n",
       "      <td>0.922156</td>\n",
       "      <td>0.905764</td>\n",
       "      <td>0.008605</td>\n",
       "      <td>2</td>\n",
       "      <td>0.990487</td>\n",
       "      <td>0.990621</td>\n",
       "      <td>0.991046</td>\n",
       "      <td>0.990488</td>\n",
       "      <td>0.990576</td>\n",
       "      <td>0.990834</td>\n",
       "      <td>0.990743</td>\n",
       "      <td>0.990320</td>\n",
       "      <td>0.990575</td>\n",
       "      <td>0.990873</td>\n",
       "      <td>0.990701</td>\n",
       "      <td>0.990576</td>\n",
       "      <td>0.990744</td>\n",
       "      <td>0.990442</td>\n",
       "      <td>0.990488</td>\n",
       "      <td>0.990634</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49.304093</td>\n",
       "      <td>3.438022</td>\n",
       "      <td>1.897247</td>\n",
       "      <td>0.251407</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>4000</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.909631</td>\n",
       "      <td>0.910598</td>\n",
       "      <td>0.922249</td>\n",
       "      <td>0.910926</td>\n",
       "      <td>0.910159</td>\n",
       "      <td>0.913978</td>\n",
       "      <td>0.916865</td>\n",
       "      <td>0.907887</td>\n",
       "      <td>0.895933</td>\n",
       "      <td>0.901659</td>\n",
       "      <td>0.890451</td>\n",
       "      <td>0.915072</td>\n",
       "      <td>0.914591</td>\n",
       "      <td>0.906176</td>\n",
       "      <td>0.916916</td>\n",
       "      <td>0.909541</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988824</td>\n",
       "      <td>0.989244</td>\n",
       "      <td>0.989289</td>\n",
       "      <td>0.989335</td>\n",
       "      <td>0.989547</td>\n",
       "      <td>0.988942</td>\n",
       "      <td>0.989501</td>\n",
       "      <td>0.989207</td>\n",
       "      <td>0.989421</td>\n",
       "      <td>0.989377</td>\n",
       "      <td>0.989414</td>\n",
       "      <td>0.989288</td>\n",
       "      <td>0.988987</td>\n",
       "      <td>0.989420</td>\n",
       "      <td>0.989414</td>\n",
       "      <td>0.989281</td>\n",
       "      <td>0.000204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.063014</td>\n",
       "      <td>0.897046</td>\n",
       "      <td>1.602535</td>\n",
       "      <td>0.150089</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.897862</td>\n",
       "      <td>0.896919</td>\n",
       "      <td>0.911377</td>\n",
       "      <td>0.890485</td>\n",
       "      <td>0.897694</td>\n",
       "      <td>0.906269</td>\n",
       "      <td>0.898930</td>\n",
       "      <td>0.899215</td>\n",
       "      <td>0.889154</td>\n",
       "      <td>0.891266</td>\n",
       "      <td>0.892145</td>\n",
       "      <td>0.898742</td>\n",
       "      <td>0.898396</td>\n",
       "      <td>0.894454</td>\n",
       "      <td>0.904390</td>\n",
       "      <td>0.897820</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>3</td>\n",
       "      <td>0.955839</td>\n",
       "      <td>0.955723</td>\n",
       "      <td>0.954732</td>\n",
       "      <td>0.956051</td>\n",
       "      <td>0.955337</td>\n",
       "      <td>0.955719</td>\n",
       "      <td>0.956173</td>\n",
       "      <td>0.955757</td>\n",
       "      <td>0.955708</td>\n",
       "      <td>0.956507</td>\n",
       "      <td>0.955515</td>\n",
       "      <td>0.955683</td>\n",
       "      <td>0.955965</td>\n",
       "      <td>0.955159</td>\n",
       "      <td>0.955159</td>\n",
       "      <td>0.955668</td>\n",
       "      <td>0.000429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37.333612</td>\n",
       "      <td>0.401074</td>\n",
       "      <td>1.521686</td>\n",
       "      <td>0.084670</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.894020</td>\n",
       "      <td>0.891408</td>\n",
       "      <td>0.908108</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.885748</td>\n",
       "      <td>0.899345</td>\n",
       "      <td>0.899465</td>\n",
       "      <td>0.890354</td>\n",
       "      <td>0.882179</td>\n",
       "      <td>0.889154</td>\n",
       "      <td>0.882491</td>\n",
       "      <td>0.905301</td>\n",
       "      <td>0.897741</td>\n",
       "      <td>0.890616</td>\n",
       "      <td>0.902644</td>\n",
       "      <td>0.894254</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>5</td>\n",
       "      <td>0.944175</td>\n",
       "      <td>0.945527</td>\n",
       "      <td>0.944201</td>\n",
       "      <td>0.944217</td>\n",
       "      <td>0.944563</td>\n",
       "      <td>0.944378</td>\n",
       "      <td>0.944255</td>\n",
       "      <td>0.943959</td>\n",
       "      <td>0.945344</td>\n",
       "      <td>0.944819</td>\n",
       "      <td>0.943956</td>\n",
       "      <td>0.943836</td>\n",
       "      <td>0.944040</td>\n",
       "      <td>0.943937</td>\n",
       "      <td>0.944141</td>\n",
       "      <td>0.944356</td>\n",
       "      <td>0.000490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31.921545</td>\n",
       "      <td>0.895022</td>\n",
       "      <td>1.410355</td>\n",
       "      <td>0.174645</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (2, 2)...</td>\n",
       "      <td>0.878641</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.879903</td>\n",
       "      <td>0.877698</td>\n",
       "      <td>0.875449</td>\n",
       "      <td>0.885922</td>\n",
       "      <td>0.883413</td>\n",
       "      <td>0.874390</td>\n",
       "      <td>0.861709</td>\n",
       "      <td>0.862110</td>\n",
       "      <td>0.864376</td>\n",
       "      <td>0.878470</td>\n",
       "      <td>0.889556</td>\n",
       "      <td>0.872171</td>\n",
       "      <td>0.886045</td>\n",
       "      <td>0.877002</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>10</td>\n",
       "      <td>0.935994</td>\n",
       "      <td>0.937497</td>\n",
       "      <td>0.937756</td>\n",
       "      <td>0.936483</td>\n",
       "      <td>0.937611</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.935979</td>\n",
       "      <td>0.937335</td>\n",
       "      <td>0.938171</td>\n",
       "      <td>0.937087</td>\n",
       "      <td>0.936651</td>\n",
       "      <td>0.935926</td>\n",
       "      <td>0.936777</td>\n",
       "      <td>0.937224</td>\n",
       "      <td>0.936014</td>\n",
       "      <td>0.936870</td>\n",
       "      <td>0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13.614680</td>\n",
       "      <td>0.741136</td>\n",
       "      <td>0.859229</td>\n",
       "      <td>0.077092</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 1...</td>\n",
       "      <td>0.894831</td>\n",
       "      <td>0.900599</td>\n",
       "      <td>0.897837</td>\n",
       "      <td>0.885850</td>\n",
       "      <td>0.889810</td>\n",
       "      <td>0.894299</td>\n",
       "      <td>0.898810</td>\n",
       "      <td>0.885404</td>\n",
       "      <td>0.878136</td>\n",
       "      <td>0.883832</td>\n",
       "      <td>0.874342</td>\n",
       "      <td>0.883945</td>\n",
       "      <td>0.889020</td>\n",
       "      <td>0.882283</td>\n",
       "      <td>0.902687</td>\n",
       "      <td>0.889447</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>6</td>\n",
       "      <td>0.934618</td>\n",
       "      <td>0.934163</td>\n",
       "      <td>0.934425</td>\n",
       "      <td>0.934529</td>\n",
       "      <td>0.934442</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.934407</td>\n",
       "      <td>0.934493</td>\n",
       "      <td>0.935536</td>\n",
       "      <td>0.935568</td>\n",
       "      <td>0.934603</td>\n",
       "      <td>0.934505</td>\n",
       "      <td>0.934607</td>\n",
       "      <td>0.934272</td>\n",
       "      <td>0.933669</td>\n",
       "      <td>0.934589</td>\n",
       "      <td>0.000466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.990153</td>\n",
       "      <td>0.854093</td>\n",
       "      <td>0.811482</td>\n",
       "      <td>0.057145</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>40000</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 1...</td>\n",
       "      <td>0.893238</td>\n",
       "      <td>0.898863</td>\n",
       "      <td>0.897837</td>\n",
       "      <td>0.885324</td>\n",
       "      <td>0.891381</td>\n",
       "      <td>0.894425</td>\n",
       "      <td>0.899465</td>\n",
       "      <td>0.881397</td>\n",
       "      <td>0.874552</td>\n",
       "      <td>0.882635</td>\n",
       "      <td>0.871855</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.888364</td>\n",
       "      <td>0.879525</td>\n",
       "      <td>0.902148</td>\n",
       "      <td>0.888474</td>\n",
       "      <td>0.009017</td>\n",
       "      <td>7</td>\n",
       "      <td>0.932283</td>\n",
       "      <td>0.931026</td>\n",
       "      <td>0.930669</td>\n",
       "      <td>0.931883</td>\n",
       "      <td>0.932122</td>\n",
       "      <td>0.932117</td>\n",
       "      <td>0.931703</td>\n",
       "      <td>0.931606</td>\n",
       "      <td>0.932417</td>\n",
       "      <td>0.932339</td>\n",
       "      <td>0.931916</td>\n",
       "      <td>0.931395</td>\n",
       "      <td>0.931337</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.931298</td>\n",
       "      <td>0.931708</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.022675</td>\n",
       "      <td>11.498147</td>\n",
       "      <td>2.008635</td>\n",
       "      <td>0.393259</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 2)...</td>\n",
       "      <td>0.886647</td>\n",
       "      <td>0.887332</td>\n",
       "      <td>0.888759</td>\n",
       "      <td>0.877598</td>\n",
       "      <td>0.879210</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>0.882319</td>\n",
       "      <td>0.880510</td>\n",
       "      <td>0.875074</td>\n",
       "      <td>0.868100</td>\n",
       "      <td>0.861610</td>\n",
       "      <td>0.887299</td>\n",
       "      <td>0.893395</td>\n",
       "      <td>0.876391</td>\n",
       "      <td>0.895944</td>\n",
       "      <td>0.882370</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>9</td>\n",
       "      <td>0.927069</td>\n",
       "      <td>0.929022</td>\n",
       "      <td>0.928712</td>\n",
       "      <td>0.928412</td>\n",
       "      <td>0.928017</td>\n",
       "      <td>0.927808</td>\n",
       "      <td>0.926860</td>\n",
       "      <td>0.927777</td>\n",
       "      <td>0.928058</td>\n",
       "      <td>0.927817</td>\n",
       "      <td>0.928323</td>\n",
       "      <td>0.927167</td>\n",
       "      <td>0.927559</td>\n",
       "      <td>0.929018</td>\n",
       "      <td>0.927030</td>\n",
       "      <td>0.927910</td>\n",
       "      <td>0.000676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.424821</td>\n",
       "      <td>1.377802</td>\n",
       "      <td>1.014569</td>\n",
       "      <td>0.127042</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 1)...</td>\n",
       "      <td>0.889150</td>\n",
       "      <td>0.886417</td>\n",
       "      <td>0.900238</td>\n",
       "      <td>0.890323</td>\n",
       "      <td>0.876887</td>\n",
       "      <td>0.887183</td>\n",
       "      <td>0.896471</td>\n",
       "      <td>0.875592</td>\n",
       "      <td>0.868344</td>\n",
       "      <td>0.877817</td>\n",
       "      <td>0.866511</td>\n",
       "      <td>0.891007</td>\n",
       "      <td>0.893067</td>\n",
       "      <td>0.878681</td>\n",
       "      <td>0.895487</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>8</td>\n",
       "      <td>0.922934</td>\n",
       "      <td>0.923513</td>\n",
       "      <td>0.922582</td>\n",
       "      <td>0.923533</td>\n",
       "      <td>0.923526</td>\n",
       "      <td>0.924080</td>\n",
       "      <td>0.922225</td>\n",
       "      <td>0.923571</td>\n",
       "      <td>0.922386</td>\n",
       "      <td>0.924398</td>\n",
       "      <td>0.923812</td>\n",
       "      <td>0.922862</td>\n",
       "      <td>0.922543</td>\n",
       "      <td>0.924360</td>\n",
       "      <td>0.923057</td>\n",
       "      <td>0.923292</td>\n",
       "      <td>0.000678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29.485324</td>\n",
       "      <td>0.472952</td>\n",
       "      <td>1.134452</td>\n",
       "      <td>0.050648</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (2, 2...</td>\n",
       "      <td>0.854265</td>\n",
       "      <td>0.848955</td>\n",
       "      <td>0.862605</td>\n",
       "      <td>0.839976</td>\n",
       "      <td>0.847698</td>\n",
       "      <td>0.846933</td>\n",
       "      <td>0.841662</td>\n",
       "      <td>0.852657</td>\n",
       "      <td>0.840895</td>\n",
       "      <td>0.845836</td>\n",
       "      <td>0.844654</td>\n",
       "      <td>0.866387</td>\n",
       "      <td>0.849882</td>\n",
       "      <td>0.842168</td>\n",
       "      <td>0.853172</td>\n",
       "      <td>0.849184</td>\n",
       "      <td>0.007433</td>\n",
       "      <td>13</td>\n",
       "      <td>0.905504</td>\n",
       "      <td>0.905218</td>\n",
       "      <td>0.903967</td>\n",
       "      <td>0.906061</td>\n",
       "      <td>0.904295</td>\n",
       "      <td>0.905826</td>\n",
       "      <td>0.905394</td>\n",
       "      <td>0.904772</td>\n",
       "      <td>0.904997</td>\n",
       "      <td>0.904644</td>\n",
       "      <td>0.905427</td>\n",
       "      <td>0.905113</td>\n",
       "      <td>0.904205</td>\n",
       "      <td>0.904693</td>\n",
       "      <td>0.904036</td>\n",
       "      <td>0.904944</td>\n",
       "      <td>0.000622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>39.289762</td>\n",
       "      <td>0.763729</td>\n",
       "      <td>1.561486</td>\n",
       "      <td>0.129536</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>400</td>\n",
       "      <td>40000</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.877672</td>\n",
       "      <td>0.870796</td>\n",
       "      <td>0.883832</td>\n",
       "      <td>0.866310</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.874030</td>\n",
       "      <td>0.881759</td>\n",
       "      <td>0.860606</td>\n",
       "      <td>0.856627</td>\n",
       "      <td>0.855271</td>\n",
       "      <td>0.863284</td>\n",
       "      <td>0.877466</td>\n",
       "      <td>0.876499</td>\n",
       "      <td>0.867299</td>\n",
       "      <td>0.874474</td>\n",
       "      <td>0.870367</td>\n",
       "      <td>0.008452</td>\n",
       "      <td>11</td>\n",
       "      <td>0.895320</td>\n",
       "      <td>0.897180</td>\n",
       "      <td>0.894219</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.897202</td>\n",
       "      <td>0.895911</td>\n",
       "      <td>0.895526</td>\n",
       "      <td>0.896291</td>\n",
       "      <td>0.896634</td>\n",
       "      <td>0.896743</td>\n",
       "      <td>0.896402</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>0.896378</td>\n",
       "      <td>0.897439</td>\n",
       "      <td>0.895984</td>\n",
       "      <td>0.896202</td>\n",
       "      <td>0.000878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.760320</td>\n",
       "      <td>1.501021</td>\n",
       "      <td>2.148986</td>\n",
       "      <td>0.204866</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 2...</td>\n",
       "      <td>0.855873</td>\n",
       "      <td>0.866250</td>\n",
       "      <td>0.868471</td>\n",
       "      <td>0.859463</td>\n",
       "      <td>0.863750</td>\n",
       "      <td>0.849262</td>\n",
       "      <td>0.864524</td>\n",
       "      <td>0.854788</td>\n",
       "      <td>0.843511</td>\n",
       "      <td>0.834606</td>\n",
       "      <td>0.836825</td>\n",
       "      <td>0.860051</td>\n",
       "      <td>0.859837</td>\n",
       "      <td>0.844048</td>\n",
       "      <td>0.856961</td>\n",
       "      <td>0.854551</td>\n",
       "      <td>0.010252</td>\n",
       "      <td>12</td>\n",
       "      <td>0.891133</td>\n",
       "      <td>0.891887</td>\n",
       "      <td>0.891421</td>\n",
       "      <td>0.893061</td>\n",
       "      <td>0.892406</td>\n",
       "      <td>0.892894</td>\n",
       "      <td>0.891720</td>\n",
       "      <td>0.891547</td>\n",
       "      <td>0.891047</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.891005</td>\n",
       "      <td>0.891924</td>\n",
       "      <td>0.891581</td>\n",
       "      <td>0.890982</td>\n",
       "      <td>0.891666</td>\n",
       "      <td>0.000646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30.137691</td>\n",
       "      <td>1.141362</td>\n",
       "      <td>1.240850</td>\n",
       "      <td>0.081683</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>4000</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (2, 2)...</td>\n",
       "      <td>0.825568</td>\n",
       "      <td>0.842670</td>\n",
       "      <td>0.846384</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.827667</td>\n",
       "      <td>0.836233</td>\n",
       "      <td>0.829762</td>\n",
       "      <td>0.833732</td>\n",
       "      <td>0.838475</td>\n",
       "      <td>0.828437</td>\n",
       "      <td>0.819905</td>\n",
       "      <td>0.846567</td>\n",
       "      <td>0.836299</td>\n",
       "      <td>0.818776</td>\n",
       "      <td>0.827711</td>\n",
       "      <td>0.832115</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>14</td>\n",
       "      <td>0.850908</td>\n",
       "      <td>0.851223</td>\n",
       "      <td>0.849350</td>\n",
       "      <td>0.850952</td>\n",
       "      <td>0.851669</td>\n",
       "      <td>0.850525</td>\n",
       "      <td>0.851984</td>\n",
       "      <td>0.851872</td>\n",
       "      <td>0.850348</td>\n",
       "      <td>0.851104</td>\n",
       "      <td>0.851210</td>\n",
       "      <td>0.850119</td>\n",
       "      <td>0.851386</td>\n",
       "      <td>0.851650</td>\n",
       "      <td>0.850946</td>\n",
       "      <td>0.851017</td>\n",
       "      <td>0.000684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.744059</td>\n",
       "      <td>3.758286</td>\n",
       "      <td>1.193331</td>\n",
       "      <td>0.311699</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>2.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 1...</td>\n",
       "      <td>0.798802</td>\n",
       "      <td>0.799285</td>\n",
       "      <td>0.794537</td>\n",
       "      <td>0.802608</td>\n",
       "      <td>0.783848</td>\n",
       "      <td>0.790006</td>\n",
       "      <td>0.801402</td>\n",
       "      <td>0.800940</td>\n",
       "      <td>0.792793</td>\n",
       "      <td>0.778308</td>\n",
       "      <td>0.792740</td>\n",
       "      <td>0.798802</td>\n",
       "      <td>0.792033</td>\n",
       "      <td>0.790865</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.795488</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>19</td>\n",
       "      <td>0.844448</td>\n",
       "      <td>0.844326</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.843636</td>\n",
       "      <td>0.845043</td>\n",
       "      <td>0.845769</td>\n",
       "      <td>0.845810</td>\n",
       "      <td>0.845003</td>\n",
       "      <td>0.845243</td>\n",
       "      <td>0.846537</td>\n",
       "      <td>0.846471</td>\n",
       "      <td>0.844639</td>\n",
       "      <td>0.846268</td>\n",
       "      <td>0.846680</td>\n",
       "      <td>0.845165</td>\n",
       "      <td>0.845341</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16.980947</td>\n",
       "      <td>0.756035</td>\n",
       "      <td>1.088873</td>\n",
       "      <td>0.118579</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>40000</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 1)...</td>\n",
       "      <td>0.815421</td>\n",
       "      <td>0.830409</td>\n",
       "      <td>0.832643</td>\n",
       "      <td>0.810335</td>\n",
       "      <td>0.826912</td>\n",
       "      <td>0.822341</td>\n",
       "      <td>0.823121</td>\n",
       "      <td>0.813817</td>\n",
       "      <td>0.809384</td>\n",
       "      <td>0.811561</td>\n",
       "      <td>0.802120</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.819825</td>\n",
       "      <td>0.820394</td>\n",
       "      <td>0.826934</td>\n",
       "      <td>0.819349</td>\n",
       "      <td>0.008384</td>\n",
       "      <td>15</td>\n",
       "      <td>0.825247</td>\n",
       "      <td>0.826222</td>\n",
       "      <td>0.824140</td>\n",
       "      <td>0.824627</td>\n",
       "      <td>0.825492</td>\n",
       "      <td>0.824572</td>\n",
       "      <td>0.824431</td>\n",
       "      <td>0.825657</td>\n",
       "      <td>0.824199</td>\n",
       "      <td>0.824367</td>\n",
       "      <td>0.824843</td>\n",
       "      <td>0.824622</td>\n",
       "      <td>0.825676</td>\n",
       "      <td>0.825422</td>\n",
       "      <td>0.824199</td>\n",
       "      <td>0.824914</td>\n",
       "      <td>0.000632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.505229</td>\n",
       "      <td>2.284908</td>\n",
       "      <td>1.041945</td>\n",
       "      <td>0.239865</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 1)...</td>\n",
       "      <td>0.808187</td>\n",
       "      <td>0.833527</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.805637</td>\n",
       "      <td>0.825962</td>\n",
       "      <td>0.819750</td>\n",
       "      <td>0.818497</td>\n",
       "      <td>0.810465</td>\n",
       "      <td>0.811442</td>\n",
       "      <td>0.807582</td>\n",
       "      <td>0.802353</td>\n",
       "      <td>0.820024</td>\n",
       "      <td>0.812065</td>\n",
       "      <td>0.819026</td>\n",
       "      <td>0.818665</td>\n",
       "      <td>0.815977</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>16</td>\n",
       "      <td>0.823952</td>\n",
       "      <td>0.825661</td>\n",
       "      <td>0.823775</td>\n",
       "      <td>0.824045</td>\n",
       "      <td>0.825403</td>\n",
       "      <td>0.824729</td>\n",
       "      <td>0.824316</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.824380</td>\n",
       "      <td>0.824435</td>\n",
       "      <td>0.824785</td>\n",
       "      <td>0.825189</td>\n",
       "      <td>0.825219</td>\n",
       "      <td>0.825453</td>\n",
       "      <td>0.824197</td>\n",
       "      <td>0.824769</td>\n",
       "      <td>0.000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31.810660</td>\n",
       "      <td>0.514344</td>\n",
       "      <td>1.299832</td>\n",
       "      <td>0.108718</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (2, 2)...</td>\n",
       "      <td>0.790920</td>\n",
       "      <td>0.813357</td>\n",
       "      <td>0.811231</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.802570</td>\n",
       "      <td>0.804805</td>\n",
       "      <td>0.813899</td>\n",
       "      <td>0.801431</td>\n",
       "      <td>0.806239</td>\n",
       "      <td>0.796690</td>\n",
       "      <td>0.782557</td>\n",
       "      <td>0.807669</td>\n",
       "      <td>0.782765</td>\n",
       "      <td>0.796903</td>\n",
       "      <td>0.804584</td>\n",
       "      <td>0.800407</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>18</td>\n",
       "      <td>0.814201</td>\n",
       "      <td>0.814497</td>\n",
       "      <td>0.813326</td>\n",
       "      <td>0.814073</td>\n",
       "      <td>0.816021</td>\n",
       "      <td>0.813699</td>\n",
       "      <td>0.812835</td>\n",
       "      <td>0.813813</td>\n",
       "      <td>0.813409</td>\n",
       "      <td>0.815095</td>\n",
       "      <td>0.814216</td>\n",
       "      <td>0.813317</td>\n",
       "      <td>0.814168</td>\n",
       "      <td>0.815026</td>\n",
       "      <td>0.813542</td>\n",
       "      <td>0.814082</td>\n",
       "      <td>0.000798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.602914</td>\n",
       "      <td>0.681413</td>\n",
       "      <td>0.915290</td>\n",
       "      <td>0.092677</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vec__stem': False, 'vec__ngram_range': (1, 1...</td>\n",
       "      <td>0.797674</td>\n",
       "      <td>0.824214</td>\n",
       "      <td>0.819093</td>\n",
       "      <td>0.799063</td>\n",
       "      <td>0.817352</td>\n",
       "      <td>0.809750</td>\n",
       "      <td>0.806246</td>\n",
       "      <td>0.801166</td>\n",
       "      <td>0.800931</td>\n",
       "      <td>0.799079</td>\n",
       "      <td>0.793446</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.805588</td>\n",
       "      <td>0.805104</td>\n",
       "      <td>0.805687</td>\n",
       "      <td>0.806228</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>17</td>\n",
       "      <td>0.810509</td>\n",
       "      <td>0.812656</td>\n",
       "      <td>0.810480</td>\n",
       "      <td>0.811029</td>\n",
       "      <td>0.812102</td>\n",
       "      <td>0.810935</td>\n",
       "      <td>0.810840</td>\n",
       "      <td>0.812894</td>\n",
       "      <td>0.810847</td>\n",
       "      <td>0.810243</td>\n",
       "      <td>0.811649</td>\n",
       "      <td>0.811151</td>\n",
       "      <td>0.812320</td>\n",
       "      <td>0.812550</td>\n",
       "      <td>0.810890</td>\n",
       "      <td>0.811406</td>\n",
       "      <td>0.000849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.400124</td>\n",
       "      <td>0.383530</td>\n",
       "      <td>0.873422</td>\n",
       "      <td>0.045315</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>{'vec__stem': True, 'vec__ngram_range': (1, 1)...</td>\n",
       "      <td>0.069741</td>\n",
       "      <td>0.663703</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.082774</td>\n",
       "      <td>0.665301</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>0.118033</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.665858</td>\n",
       "      <td>0.041812</td>\n",
       "      <td>0.666936</td>\n",
       "      <td>0.666126</td>\n",
       "      <td>0.654439</td>\n",
       "      <td>0.665583</td>\n",
       "      <td>0.667216</td>\n",
       "      <td>0.508093</td>\n",
       "      <td>0.259742</td>\n",
       "      <td>20</td>\n",
       "      <td>0.084231</td>\n",
       "      <td>0.662928</td>\n",
       "      <td>0.667726</td>\n",
       "      <td>0.078857</td>\n",
       "      <td>0.666589</td>\n",
       "      <td>0.663661</td>\n",
       "      <td>0.117152</td>\n",
       "      <td>0.667726</td>\n",
       "      <td>0.667784</td>\n",
       "      <td>0.041435</td>\n",
       "      <td>0.665067</td>\n",
       "      <td>0.665299</td>\n",
       "      <td>0.660555</td>\n",
       "      <td>0.666628</td>\n",
       "      <td>0.667691</td>\n",
       "      <td>0.509555</td>\n",
       "      <td>0.259158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "16      34.898155      2.134065         1.328138        0.145529   \n",
       "2       41.219318      1.924093         1.626187        0.140625   \n",
       "6       49.304093      3.438022         1.897247        0.251407   \n",
       "3       37.063014      0.897046         1.602535        0.150089   \n",
       "11      37.333612      0.401074         1.521686        0.084670   \n",
       "7       31.921545      0.895022         1.410355        0.174645   \n",
       "18      13.614680      0.741136         0.859229        0.077092   \n",
       "10      13.990153      0.854093         0.811482        0.057145   \n",
       "4       49.022675     11.498147         2.008635        0.393259   \n",
       "8       16.424821      1.377802         1.014569        0.127042   \n",
       "13      29.485324      0.472952         1.134452        0.050648   \n",
       "17      39.289762      0.763729         1.561486        0.129536   \n",
       "1       52.760320      1.501021         2.148986        0.204866   \n",
       "15      30.137691      1.141362         1.240850        0.081683   \n",
       "5       19.744059      3.758286         1.193331        0.311699   \n",
       "19      16.980947      0.756035         1.088873        0.118579   \n",
       "0       16.505229      2.284908         1.041945        0.239865   \n",
       "14      31.810660      0.514344         1.299832        0.108718   \n",
       "9       14.602914      0.681413         0.915290        0.092677   \n",
       "12      13.400124      0.383530         0.873422        0.045315   \n",
       "\n",
       "   param_vec__stem param_vec__ngram_range param_vec__min_df param_vec__max_df  \\\n",
       "16           False                 (2, 2)                 3               400   \n",
       "2            False                 (1, 2)                 3               400   \n",
       "6            False                 (1, 2)                 3              4000   \n",
       "3            False                 (1, 2)                50                 1   \n",
       "11           False                 (1, 2)               100              4000   \n",
       "7             True                 (2, 2)                 3               400   \n",
       "18           False                 (1, 1)                50                 1   \n",
       "10           False                 (1, 1)                50             40000   \n",
       "4             True                 (1, 2)                 3               400   \n",
       "8             True                 (1, 1)                 1              4000   \n",
       "13           False                 (2, 2)               100                 1   \n",
       "17           False                 (1, 2)               400             40000   \n",
       "1            False                 (1, 2)                 1              4000   \n",
       "15            True                 (2, 2)               100              4000   \n",
       "5            False                 (1, 1)               100               400   \n",
       "19            True                 (1, 1)                50             40000   \n",
       "0             True                 (1, 1)                 1                 1   \n",
       "14            True                 (2, 2)               100                 1   \n",
       "9            False                 (1, 1)                50                 1   \n",
       "12            True                 (1, 1)               400               400   \n",
       "\n",
       "   param_tfidf__smooth_idf param_tfidf__norm param_clf__fit_intercept  \\\n",
       "16                   False                l2                    False   \n",
       "2                     True                l2                     True   \n",
       "6                     True                l2                     True   \n",
       "3                    False                l2                     True   \n",
       "11                   False                l2                    False   \n",
       "7                     True                l1                    False   \n",
       "18                    True                l2                     True   \n",
       "10                    True                l2                     True   \n",
       "4                    False                l1                     True   \n",
       "8                    False                l2                     True   \n",
       "13                   False                l2                     True   \n",
       "17                    True                l2                     True   \n",
       "1                    False                l1                    False   \n",
       "15                    True                l1                    False   \n",
       "5                    False                l2                     True   \n",
       "19                   False                l1                     True   \n",
       "0                     True                l1                    False   \n",
       "14                    True                l1                     True   \n",
       "9                     True                l1                     True   \n",
       "12                   False                l1                     True   \n",
       "\n",
       "   param_clf__C                                             params  \\\n",
       "16          2.5  {'vec__stem': False, 'vec__ngram_range': (2, 2...   \n",
       "2             2  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "6             3  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "3           2.5  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "11            2  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "7             2  {'vec__stem': True, 'vec__ngram_range': (2, 2)...   \n",
       "18            3  {'vec__stem': False, 'vec__ngram_range': (1, 1...   \n",
       "10          2.5  {'vec__stem': False, 'vec__ngram_range': (1, 1...   \n",
       "4             1  {'vec__stem': True, 'vec__ngram_range': (1, 2)...   \n",
       "8           0.5  {'vec__stem': True, 'vec__ngram_range': (1, 1)...   \n",
       "13            2  {'vec__stem': False, 'vec__ngram_range': (2, 2...   \n",
       "17          2.5  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "1             1  {'vec__stem': False, 'vec__ngram_range': (1, 2...   \n",
       "15          2.5  {'vec__stem': True, 'vec__ngram_range': (2, 2)...   \n",
       "5           2.5  {'vec__stem': False, 'vec__ngram_range': (1, 1...   \n",
       "19            1  {'vec__stem': True, 'vec__ngram_range': (1, 1)...   \n",
       "0             1  {'vec__stem': True, 'vec__ngram_range': (1, 1)...   \n",
       "14          0.5  {'vec__stem': True, 'vec__ngram_range': (2, 2)...   \n",
       "9           0.5  {'vec__stem': False, 'vec__ngram_range': (1, 1...   \n",
       "12            3  {'vec__stem': True, 'vec__ngram_range': (1, 1)...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "16           0.902728           0.897935           0.895906   \n",
       "2            0.908873           0.907484           0.905350   \n",
       "6            0.909631           0.910598           0.922249   \n",
       "3            0.897862           0.896919           0.911377   \n",
       "11           0.894020           0.891408           0.908108   \n",
       "7            0.878641           0.885167           0.879903   \n",
       "18           0.894831           0.900599           0.897837   \n",
       "10           0.893238           0.898863           0.897837   \n",
       "4            0.886647           0.887332           0.888759   \n",
       "8            0.889150           0.886417           0.900238   \n",
       "13           0.854265           0.848955           0.862605   \n",
       "17           0.877672           0.870796           0.883832   \n",
       "1            0.855873           0.866250           0.868471   \n",
       "15           0.825568           0.842670           0.846384   \n",
       "5            0.798802           0.799285           0.794537   \n",
       "19           0.815421           0.830409           0.832643   \n",
       "0            0.808187           0.833527           0.826446   \n",
       "14           0.790920           0.813357           0.811231   \n",
       "9            0.797674           0.824214           0.819093   \n",
       "12           0.069741           0.663703           0.666667   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "16           0.895047           0.890451           0.900412   \n",
       "2            0.906084           0.896104           0.919144   \n",
       "6            0.910926           0.910159           0.913978   \n",
       "3            0.890485           0.897694           0.906269   \n",
       "11           0.895238           0.885748           0.899345   \n",
       "7            0.877698           0.875449           0.885922   \n",
       "18           0.885850           0.889810           0.894299   \n",
       "10           0.885324           0.891381           0.894425   \n",
       "4            0.877598           0.879210           0.895349   \n",
       "8            0.890323           0.876887           0.887183   \n",
       "13           0.839976           0.847698           0.846933   \n",
       "17           0.866310           0.869565           0.874030   \n",
       "1            0.859463           0.863750           0.849262   \n",
       "15           0.823529           0.827667           0.836233   \n",
       "5            0.802608           0.783848           0.790006   \n",
       "19           0.810335           0.826912           0.822341   \n",
       "0            0.805637           0.825962           0.819750   \n",
       "14           0.790476           0.802570           0.804805   \n",
       "9            0.799063           0.817352           0.809750   \n",
       "12           0.082774           0.665301           0.661017   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "16           0.900177           0.893848           0.881110   \n",
       "2            0.906526           0.903571           0.903498   \n",
       "6            0.916865           0.907887           0.895933   \n",
       "3            0.898930           0.899215           0.889154   \n",
       "11           0.899465           0.890354           0.882179   \n",
       "7            0.883413           0.874390           0.861709   \n",
       "18           0.898810           0.885404           0.878136   \n",
       "10           0.899465           0.881397           0.874552   \n",
       "4            0.882319           0.880510           0.875074   \n",
       "8            0.896471           0.875592           0.868344   \n",
       "13           0.841662           0.852657           0.840895   \n",
       "17           0.881759           0.860606           0.856627   \n",
       "1            0.864524           0.854788           0.843511   \n",
       "15           0.829762           0.833732           0.838475   \n",
       "5            0.801402           0.800940           0.792793   \n",
       "19           0.823121           0.813817           0.809384   \n",
       "0            0.818497           0.810465           0.811442   \n",
       "14           0.813899           0.801431           0.806239   \n",
       "9            0.806246           0.801166           0.800931   \n",
       "12           0.118033           0.666667           0.665858   \n",
       "\n",
       "    split9_test_score  split10_test_score  split11_test_score  \\\n",
       "16           0.882318            0.880518            0.907341   \n",
       "2            0.892836            0.890579            0.906344   \n",
       "6            0.901659            0.890451            0.915072   \n",
       "3            0.891266            0.892145            0.898742   \n",
       "11           0.889154            0.882491            0.905301   \n",
       "7            0.862110            0.864376            0.878470   \n",
       "18           0.883832            0.874342            0.883945   \n",
       "10           0.882635            0.871855            0.886076   \n",
       "4            0.868100            0.861610            0.887299   \n",
       "8            0.877817            0.866511            0.891007   \n",
       "13           0.845836            0.844654            0.866387   \n",
       "17           0.855271            0.863284            0.877466   \n",
       "1            0.834606            0.836825            0.860051   \n",
       "15           0.828437            0.819905            0.846567   \n",
       "5            0.778308            0.792740            0.798802   \n",
       "19           0.811561            0.802120            0.825000   \n",
       "0            0.807582            0.802353            0.820024   \n",
       "14           0.796690            0.782557            0.807669   \n",
       "9            0.799079            0.793446            0.808989   \n",
       "12           0.041812            0.666936            0.666126   \n",
       "\n",
       "    split12_test_score  split13_test_score  split14_test_score  \\\n",
       "16            0.910272            0.897375            0.913507   \n",
       "2             0.916963            0.900955            0.922156   \n",
       "6             0.914591            0.906176            0.916916   \n",
       "3             0.898396            0.894454            0.904390   \n",
       "11            0.897741            0.890616            0.902644   \n",
       "7             0.889556            0.872171            0.886045   \n",
       "18            0.889020            0.882283            0.902687   \n",
       "10            0.888364            0.879525            0.902148   \n",
       "4             0.893395            0.876391            0.895944   \n",
       "8             0.893067            0.878681            0.895487   \n",
       "13            0.849882            0.842168            0.853172   \n",
       "17            0.876499            0.867299            0.874474   \n",
       "1             0.859837            0.844048            0.856961   \n",
       "15            0.836299            0.818776            0.827711   \n",
       "5             0.792033            0.790865            0.815348   \n",
       "19            0.819825            0.820394            0.826934   \n",
       "0             0.812065            0.819026            0.818665   \n",
       "14            0.782765            0.796903            0.804584   \n",
       "9             0.805588            0.805104            0.805687   \n",
       "12            0.654439            0.665583            0.667216   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "16         0.896596        0.009681                4            0.995325   \n",
       "2          0.905764        0.008605                2            0.990487   \n",
       "6          0.909541        0.008059                1            0.988824   \n",
       "3          0.897820        0.005882                3            0.955839   \n",
       "11         0.894254        0.007614                5            0.944175   \n",
       "7          0.877002        0.008516               10            0.935994   \n",
       "18         0.889447        0.008201                6            0.934618   \n",
       "10         0.888474        0.009017                7            0.932283   \n",
       "4          0.882370        0.009458                9            0.927069   \n",
       "8          0.884880        0.009973                8            0.922934   \n",
       "13         0.849184        0.007433               13            0.905504   \n",
       "17         0.870367        0.008452               11            0.895320   \n",
       "1          0.854551        0.010252               12            0.891133   \n",
       "15         0.832115        0.008576               14            0.850908   \n",
       "5          0.795488        0.008390               19            0.844448   \n",
       "19         0.819349        0.008384               15            0.825247   \n",
       "0          0.815977        0.008411               16            0.823952   \n",
       "14         0.800407        0.009800               18            0.814201   \n",
       "9          0.806228        0.008278               17            0.810509   \n",
       "12         0.508093        0.259742               20            0.084231   \n",
       "\n",
       "    split1_train_score  split2_train_score  split3_train_score  \\\n",
       "16            0.994940            0.994856            0.995027   \n",
       "2             0.990621            0.991046            0.990488   \n",
       "6             0.989244            0.989289            0.989335   \n",
       "3             0.955723            0.954732            0.956051   \n",
       "11            0.945527            0.944201            0.944217   \n",
       "7             0.937497            0.937756            0.936483   \n",
       "18            0.934163            0.934425            0.934529   \n",
       "10            0.931026            0.930669            0.931883   \n",
       "4             0.929022            0.928712            0.928412   \n",
       "8             0.923513            0.922582            0.923533   \n",
       "13            0.905218            0.903967            0.906061   \n",
       "17            0.897180            0.894219            0.896907   \n",
       "1             0.891887            0.891421            0.893061   \n",
       "15            0.851223            0.849350            0.850952   \n",
       "5             0.844326            0.845070            0.843636   \n",
       "19            0.826222            0.824140            0.824627   \n",
       "0             0.825661            0.823775            0.824045   \n",
       "14            0.814497            0.813326            0.814073   \n",
       "9             0.812656            0.810480            0.811029   \n",
       "12            0.662928            0.667726            0.078857   \n",
       "\n",
       "    split4_train_score  split5_train_score  split6_train_score  \\\n",
       "16            0.994941            0.994425            0.995153   \n",
       "2             0.990576            0.990834            0.990743   \n",
       "6             0.989547            0.988942            0.989501   \n",
       "3             0.955337            0.955719            0.956173   \n",
       "11            0.944563            0.944378            0.944255   \n",
       "7             0.937611            0.936544            0.935979   \n",
       "18            0.934442            0.935000            0.934407   \n",
       "10            0.932122            0.932117            0.931703   \n",
       "4             0.928017            0.927808            0.926860   \n",
       "8             0.923526            0.924080            0.922225   \n",
       "13            0.904295            0.905826            0.905394   \n",
       "17            0.897202            0.895911            0.895526   \n",
       "1             0.892406            0.892894            0.891720   \n",
       "15            0.851669            0.850525            0.851984   \n",
       "5             0.845043            0.845769            0.845810   \n",
       "19            0.825492            0.824572            0.824431   \n",
       "0             0.825403            0.824729            0.824316   \n",
       "14            0.816021            0.813699            0.812835   \n",
       "9             0.812102            0.810935            0.810840   \n",
       "12            0.666589            0.663661            0.117152   \n",
       "\n",
       "    split7_train_score  split8_train_score  split9_train_score  \\\n",
       "16            0.994940            0.995198            0.995370   \n",
       "2             0.990320            0.990575            0.990873   \n",
       "6             0.989207            0.989421            0.989377   \n",
       "3             0.955757            0.955708            0.956507   \n",
       "11            0.943959            0.945344            0.944819   \n",
       "7             0.937335            0.938171            0.937087   \n",
       "18            0.934493            0.935536            0.935568   \n",
       "10            0.931606            0.932417            0.932339   \n",
       "4             0.927777            0.928058            0.927817   \n",
       "8             0.923571            0.922386            0.924398   \n",
       "13            0.904772            0.904997            0.904644   \n",
       "17            0.896291            0.896634            0.896743   \n",
       "1             0.891547            0.891047            0.891071   \n",
       "15            0.851872            0.850348            0.851104   \n",
       "5             0.845003            0.845243            0.846537   \n",
       "19            0.825657            0.824199            0.824367   \n",
       "0             0.826000            0.824380            0.824435   \n",
       "14            0.813813            0.813409            0.815095   \n",
       "9             0.812894            0.810847            0.810243   \n",
       "12            0.667726            0.667784            0.041435   \n",
       "\n",
       "    split10_train_score  split11_train_score  split12_train_score  \\\n",
       "16             0.995155             0.994855             0.994899   \n",
       "2              0.990701             0.990576             0.990744   \n",
       "6              0.989414             0.989288             0.988987   \n",
       "3              0.955515             0.955683             0.955965   \n",
       "11             0.943956             0.943836             0.944040   \n",
       "7              0.936651             0.935926             0.936777   \n",
       "18             0.934603             0.934505             0.934607   \n",
       "10             0.931916             0.931395             0.931337   \n",
       "4              0.928323             0.927167             0.927559   \n",
       "8              0.923812             0.922862             0.922543   \n",
       "13             0.905427             0.905113             0.904205   \n",
       "17             0.896402             0.894892             0.896378   \n",
       "1              0.891304             0.891005             0.891924   \n",
       "15             0.851210             0.850119             0.851386   \n",
       "5              0.846471             0.844639             0.846268   \n",
       "19             0.824843             0.824622             0.825676   \n",
       "0              0.824785             0.825189             0.825219   \n",
       "14             0.814216             0.813317             0.814168   \n",
       "9              0.811649             0.811151             0.812320   \n",
       "12             0.665067             0.665299             0.660555   \n",
       "\n",
       "    split13_train_score  split14_train_score  mean_train_score  \\\n",
       "16             0.995112             0.994897          0.995006   \n",
       "2              0.990442             0.990488          0.990634   \n",
       "6              0.989420             0.989414          0.989281   \n",
       "3              0.955159             0.955159          0.955668   \n",
       "11             0.943937             0.944141          0.944356   \n",
       "7              0.937224             0.936014          0.936870   \n",
       "18             0.934272             0.933669          0.934589   \n",
       "10             0.931507             0.931298          0.931708   \n",
       "4              0.929018             0.927030          0.927910   \n",
       "8              0.924360             0.923057          0.923292   \n",
       "13             0.904693             0.904036          0.904944   \n",
       "17             0.897439             0.895984          0.896202   \n",
       "1              0.891581             0.890982          0.891666   \n",
       "15             0.851650             0.850946          0.851017   \n",
       "5              0.846680             0.845165          0.845341   \n",
       "19             0.825422             0.824199          0.824914   \n",
       "0              0.825453             0.824197          0.824769   \n",
       "14             0.815026             0.813542          0.814082   \n",
       "9              0.812550             0.810890          0.811406   \n",
       "12             0.666628             0.667691          0.509555   \n",
       "\n",
       "    std_train_score  \n",
       "16         0.000223  \n",
       "2          0.000183  \n",
       "6          0.000204  \n",
       "3          0.000429  \n",
       "11         0.000490  \n",
       "7          0.000698  \n",
       "18         0.000466  \n",
       "10         0.000493  \n",
       "4          0.000676  \n",
       "8          0.000678  \n",
       "13         0.000622  \n",
       "17         0.000878  \n",
       "1          0.000646  \n",
       "15         0.000684  \n",
       "5          0.000868  \n",
       "19         0.000632  \n",
       "0          0.000660  \n",
       "14         0.000798  \n",
       "9          0.000849  \n",
       "12         0.259158  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1 = pd.DataFrame(rs_regression_bin.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,1].values\n",
    "X_test = test.iloc[:,1].values\n",
    "y = train.iloc[:,2].values.astype(int)\n",
    "# select best model\n",
    "model = rs_mnv_bow.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "R2qgOsTYBJbD"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ve3cstNGDKIv"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "test['Category'] = y_pred\n",
    "\n",
    "# submission results\n",
    "submission = test.drop(columns='Text')\n",
    "submission.to_csv('../data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CtDlCzOhQ4Xo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "comp551_proj2.ipynb",
   "provenance": [
    {
     "file_id": "1PiolizwBetCCjzPZQudwPMiUv9EnnM0U",
     "timestamp": 1549490375052
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
