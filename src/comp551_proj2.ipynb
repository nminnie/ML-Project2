{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nr_pRkcIco0T"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from data_loader import load_data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from nlp_processing import LemmaCountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from naive_bayes import BernoulliNaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nh7ku4LNwl5-"
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# # taken from https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184\n",
    "# REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\")\n",
    "# REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "# def preprocess_reviews(reviews):\n",
    "#     reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "#     reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "#     return \"\".join(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1549494432579,
     "user": {
      "displayName": "FRANCISCO XAVIER SUMBA TORAL",
      "photoUrl": "",
      "userId": "11128736706802637809"
     },
     "user_tz": 300
    },
    "id": "rKbl5m-gLme3",
    "outputId": "fa417ed1-ac49-41c6-9c1c-801dae469916"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train(X-(25000,), y-(25000,)), Test(X-(25000,))'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "train, test = load_data()\n",
    "full_text = list(train.iloc[:, 1].values) + list(test.iloc[:, 1].values)\n",
    "# raw training and test data\n",
    "X_train = train.iloc[:,1].values\n",
    "X_test = test.iloc[:,1].values\n",
    "y = train.iloc[:,2].values.astype(int)\n",
    "\n",
    "\"Train(X-%s, y-%s), Test(X-%s)\"%(X_train.shape, y.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'f1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering considering TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_regression_tfidf = {\n",
    "    'vec__min_df': (1, .3, .4, .5),\n",
    "    'vec__stem': (True, False),\n",
    "    'vec__ngram_range':((1, 1), (1, 2), (2, 2)),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'tfidf__smooth_idf': (True, False),\n",
    "    'clf__fit_intercept': (True, False), \n",
    "    'clf__C': (1,2,3, 0.05, 0.1, 1.5), \n",
    "}\n",
    "\n",
    "pipeline_regression_tfidf = Pipeline([\n",
    "    ('vec', LemmaCountVectorizer(strip_accents='unicode', stop_words=None, binary=False)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression(solver='saga', penalty='l2'))\n",
    "])\n",
    "                  \n",
    "rs_regression_tfidf = RandomizedSearchCV(pipeline_regression_tfidf, parameters_regression_tfidf, \n",
    "                                   cv=15, scoring=score, n_jobs=-1, verbose=0, random_state=62)\n",
    "start = time.time()\n",
    "rs_regression_tfidf.fit(X_train, y)\n",
    "time.time() - start, rs_regression_tfidf.best_params_, rs_regression_tfidf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_regression_bow = {\n",
    "    'vec__min_df': (1, .3, .4, .5),\n",
    "    'vec__stem': (True, False),\n",
    "    'vec__ngram_range':((1, 1), (1, 2), (2, 2)),\n",
    "    'vec__binary': (True, False)\n",
    "    'clf__fit_intercept': (True, False), \n",
    "    'clf__C': (1,2,3, 0.05, 0.1, 1.5), \n",
    "}\n",
    "\n",
    "pipeline_regression_bow = Pipeline([\n",
    "    ('vec', LemmaCountVectorizer(strip_accents='unicode', stop_words=None)),\n",
    "    ('clf', LogisticRegression(solver='saga', penalty='l2'))\n",
    "])\n",
    "                  \n",
    "rs_regression_bow = RandomizedSearchCV(pipeline_regression_bow, parameters_regression_bow, \n",
    "                                   cv=15, scoring=score, n_jobs=-1, verbose=0, random_state=62)\n",
    "start = time.time()\n",
    "rs_regression_bow.fit(X_train, y)\n",
    "time.time() - start, rs_regression_bow.best_params_, rs_regression_bow.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering considering BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mnv_bow = {\n",
    "    'vec__min_df': (1, .3, .4, .5),\n",
    "    'vec__stem': (True, False),\n",
    "    'vec__ngram_range':((1, 1), (1, 2), (2, 2)),\n",
    "    'clf__alpha': (0, 1, 1.5, 2, 2.5, 3)\n",
    "}\n",
    "\n",
    "pipeline_mnv_bow = Pipeline([\n",
    "    ('vec', LemmaCountVectorizer(strip_accents='unicode', stop_words=None, binary=False)),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "                  \n",
    "rs_mnv_bow = RandomizedSearchCV(pipeline_mnv_bow, parameters_mnv_bow, \n",
    "                                   cv=15, scoring=score, n_jobs=-1, verbose=0, random_state=62)\n",
    "start = time.time()\n",
    "rs_mnv_bow.fit(X_train, y)\n",
    "time.time() - start, rs_mnv_bow.best_params_, rs_mnv_bow.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2105709,
     "status": "ok",
     "timestamp": 1549504031186,
     "user": {
      "displayName": "FRANCISCO XAVIER SUMBA TORAL",
      "photoUrl": "",
      "userId": "11128736706802637809"
     },
     "user_tz": 300
    },
    "id": "FyIB_vuE3ZtA",
    "outputId": "e5e5a82e-7192-45ab-bbda-d548a03689b0"
   },
   "outputs": [],
   "source": [
    "parameters_svm = {'C':[1], 'kernel': ['linear', 'rbf']}\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,1].values\n",
    "X_test = test.iloc[:,1].values\n",
    "y = train.iloc[:,2].values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "R2qgOsTYBJbD"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ve3cstNGDKIv"
   },
   "outputs": [],
   "source": [
    "# select best model\n",
    "model = random_search.best_estimator_\n",
    "y_pred = model.predict(X_test)\n",
    "test['Category'] = y_pred\n",
    "\n",
    "# submission results\n",
    "submission = test.drop(columns='Text')\n",
    "submission.to_csv('../data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CtDlCzOhQ4Xo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "comp551_proj2.ipynb",
   "provenance": [
    {
     "file_id": "1PiolizwBetCCjzPZQudwPMiUv9EnnM0U",
     "timestamp": 1549490375052
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
